{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Layer Equalization and Bias Correction\n",
    "\n",
    "This notebook contains an example of how to use AIMET to apply Cross-Layer Equalization (CLE) and Bias Correction (BC). CLE and BC are post-training quantization techniques for improving the quantized accuracy of a model. These techniques help recover quantized accuracy when the model quantization is sensitive to parameter quantization as opposed to activation quantization.\n",
    "\n",
    "CLE does not need any data samples. BC may optionally need unlabeled data samples. \n",
    "\n",
    "## Techniques\n",
    "\n",
    "**Cross-layer equalization**\n",
    "\n",
    "AIMET performs the following steps when running CLE:\n",
    "\n",
    "1. Batch norm (BN) Folding: Folds BN layers into convolution (Conv) layers immediate before or after the Conv layers.\n",
    "2. Cross-layer scaling: For a set of consecutive Conv layers, equalizes the range of tensor values per-channel by scaling their weight tensor values.\n",
    "3. High bias folding: Cross-layer scaling may result in high bias parameter values for some layers. This technique folds some of a layer's\n",
    "\n",
    "**Bias Correction**  \n",
    "\n",
    "Quantization sometimes leads to a shift in layer outputs. Bias correction helps correct this shift by adjusting the bias parameters of that layer. This step is optional, and is applied after CLE.\n",
    "\n",
    "## Overall flow\n",
    "\n",
    "This example performs the following steps:\n",
    "\n",
    "1. Instantiate the example evaluation and training pipeline\n",
    "2. Load the FP32 model and evaluate the model to find the baseline FP32 accuracy\n",
    "3. Create a quantization simulation model (with fake quantization ops inserted) and evaluate the quantized simuation model\n",
    "4. Apply CLE, BC, and high-bias folding and evaluate the simulation model\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Note\n",
    "\n",
    "This notebook does not show state-of-the-art results. For example, it uses a relatively quantization-friendly model (Resnet18). Also, some optimization parameters like number of fine-tuning epochs are chosen to improve execution speed in the notebook.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Dataset\n",
    "\n",
    "This example does image classification on the ImageNet dataset. If you already have a version of the data set, use that. Otherwise download the data set, for example from https://image-net.org/challenges/LSVRC/2012/index .\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Note\n",
    "\n",
    "The dataloader provided in this example relies on these features of the ImageNet data set:\n",
    "\n",
    "- Subfolders `train` for the training samples and `val` for the validation samples. See the [pytorch dataset description](https://pytorch.org/vision/0.8/_modules/torchvision/datasets/imagenet.html) for more details.\n",
    "- One subdirectory per class, and one file per image sample.\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Note\n",
    "\n",
    "To speed up the execution of this notebook, you can use a reduced subset of the ImageNet dataset. For example: The entire ILSVRC2012 dataset has 1000 classes, 1000 training samples per class and 50 validation samples per class. However, for the purpose of running this notebook, you can reduce the dataset to, say, two samples per class.\n",
    "\n",
    "</div>\n",
    "\n",
    "Edit the cell below to specify the directory where the downloaded ImageNet dataset is saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = '/home/shayan/Desktop/aimet/Examples/torch/quantization/'         # Replace this path with a real directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Instantiate the example training and validation pipeline\n",
    "\n",
    "**Use the following training and validation loop for the image classification task.**\n",
    "\n",
    "Things to note:\n",
    "\n",
    "- AIMET does not put limitations on how the training and validation pipeline is written. AIMET modifies the user's model to create a QuantizationSim model, which is still a PyTorch model. The QuantizationSim model can be used in place of the original model when doing inference or training.\n",
    "- AIMET doesn not put limitations on the interface of the `evaluate()` or `train()` methods. You should be able to use your existing evaluate and train routines as-is.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install git+https://github.com/modestyachts/ImageNetV2_pytorch\n",
    "\n",
    "\n",
    "# from imagenetv2_pytorch import ImageNetV2Dataset\n",
    "\n",
    "\n",
    "# images = ImageNetV2Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/shayan/Desktop/aimet/\")\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from Examples.common import image_net_config\n",
    "from Examples.torch.utils.image_net_evaluator import ImageNetEvaluator\n",
    "from Examples.torch.utils.image_net_trainer import ImageNetTrainer\n",
    "from Examples.torch.utils.image_net_data_loader import ImageNetDataLoader\n",
    "\n",
    "sys.path.remove(\"/home/shayan/Desktop/aimet/\")\n",
    "\n",
    "class ImageNetDataPipeline:\n",
    "\n",
    "    @staticmethod\n",
    "    def get_val_dataloader() -> torch.utils.data.DataLoader:\n",
    "        \"\"\"\n",
    "        Instantiates a validation dataloader for ImageNet dataset and returns it\n",
    "        \"\"\"\n",
    "        data_loader = ImageNetDataLoader(DATASET_DIR,\n",
    "                                         image_size=image_net_config.dataset['image_size'],\n",
    "                                         batch_size=image_net_config.evaluation['batch_size'],\n",
    "                                         is_training=False,\n",
    "                                         num_workers=image_net_config.evaluation['num_workers']).data_loader\n",
    "        return data_loader\n",
    "\n",
    "    @staticmethod\n",
    "    def evaluate(model: torch.nn.Module, use_cuda: bool) -> float:\n",
    "        \"\"\"\n",
    "        Given a torch model, evaluates its Top-1 accuracy on the dataset\n",
    "        :param model: the model to evaluate\n",
    "        :param iterations: the number of batches to be used to evaluate the model. A value of 'None' means the model will be\n",
    "                           evaluated on the entire dataset once.\n",
    "        :param use_cuda: whether or not the GPU should be used.\n",
    "        \"\"\"\n",
    "        evaluator = ImageNetEvaluator(DATASET_DIR, image_size=image_net_config.dataset['image_size'],\n",
    "                                      batch_size=image_net_config.evaluation['batch_size'],\n",
    "                                      num_workers=image_net_config.evaluation['num_workers'])\n",
    "\n",
    "        return evaluator.evaluate(model, iterations=None, use_cuda=use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Load the model and evaluate to get a baseline FP32 accuracy score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1 Load a pretrained resnet18 model from torchvision.** \n",
    "\n",
    "You can load any pretrained PyTorch model instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:02<00:00, 20.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet18\n",
    "\n",
    "model = resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AIMET quantization simulation requires the model definition to follow certain guidelines. For example, functionals defined in the forward pass should be changed to the equivalent **torch.nn.Module**.\n",
    "The [AIMET user guide](https://quic.github.io/aimet-pages/releases/latest/user_guide/index.html) lists all these guidelines.\n",
    "\n",
    "**2.2 Use the following ModelPreparer API call to automate the model definition changes required to comply with the AIMET guidelines.** \n",
    "\n",
    "The call uses the graph transformation feature available in PyTorch 1.9+."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-20 10:41:42,890 - root - INFO - AIMET\n",
      "2024-12-20 10:41:42,953 - ModelPreparer - INFO - Functional         : Adding new module for node: {layer1.0.module_add} \n",
      "2024-12-20 10:41:42,954 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {layer1.0.module_relu_1} \n",
      "2024-12-20 10:41:42,955 - ModelPreparer - INFO - Functional         : Adding new module for node: {layer1.1.module_add_1} \n",
      "2024-12-20 10:41:42,955 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {layer1.1.module_relu_1} \n",
      "2024-12-20 10:41:42,956 - ModelPreparer - INFO - Functional         : Adding new module for node: {layer2.0.module_add_2} \n",
      "2024-12-20 10:41:42,956 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {layer2.0.module_relu_1} \n",
      "2024-12-20 10:41:42,956 - ModelPreparer - INFO - Functional         : Adding new module for node: {layer2.1.module_add_3} \n",
      "2024-12-20 10:41:42,957 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {layer2.1.module_relu_1} \n",
      "2024-12-20 10:41:42,957 - ModelPreparer - INFO - Functional         : Adding new module for node: {layer3.0.module_add_4} \n",
      "2024-12-20 10:41:42,958 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {layer3.0.module_relu_1} \n",
      "2024-12-20 10:41:42,958 - ModelPreparer - INFO - Functional         : Adding new module for node: {layer3.1.module_add_5} \n",
      "2024-12-20 10:41:42,958 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {layer3.1.module_relu_1} \n",
      "2024-12-20 10:41:42,959 - ModelPreparer - INFO - Functional         : Adding new module for node: {layer4.0.module_add_6} \n",
      "2024-12-20 10:41:42,959 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {layer4.0.module_relu_1} \n",
      "2024-12-20 10:41:42,959 - ModelPreparer - INFO - Functional         : Adding new module for node: {layer4.1.module_add_7} \n",
      "2024-12-20 10:41:42,960 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {layer4.1.module_relu_1} \n"
     ]
    }
   ],
   "source": [
    "from aimet_torch.model_preparer import prepare_model\n",
    "\n",
    "model = prepare_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**2.3 Decide whether to place the model on a CPU or CUDA device.** \n",
    "\n",
    "This example uses CUDA if it is available. You can change this logic and force a device placement if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda = False\n",
    "if torch.cuda.is_available():\n",
    "    use_cuda = True\n",
    "    model.to(torch.device('cuda'))\n",
    "use_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-20 10:42:57,506 - Dataloader - INFO - Dataset consists of 3 images in 1 classes\n"
     ]
    }
   ],
   "source": [
    "dataloader = ImageNetDataPipeline.get_val_dataloader()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('/home/shayan/Desktop/aimet/Examples/torch/quantization/val/9/cf135f199d8c7a9d0dce9aa35acfb4c70c14e0aa.jpeg',)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def forward(model, dataloader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for path, batch, _ in dataloader:\n",
    "            print(path)\n",
    "            output = model(batch)\n",
    "            break\n",
    "    return output\n",
    "\n",
    "fp32_output = forward(model, dataloader)\n",
    "fp32_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**2.4 Compute the floating point 32-bit (FP32) accuracy of this model using the evaluate() routine.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-17 07:59:23,709 - Dataloader - INFO - Dataset consists of 3 images in 1 classes\n",
      "2024-12-17 07:59:23,710 - Eval - INFO - No value of iteration is provided, running evaluation on complete dataset.\n",
      "2024-12-17 07:59:23,712 - Eval - INFO - Evaluating nn.Module for 3 iterations with batch_size 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:00<00:00, 12.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.2675e+00, -2.7024e+00, -2.2966e+00, -2.4265e+00, -5.4076e-01,\n",
      "          2.0593e+00,  9.8437e-01,  2.8421e-01,  2.5248e+00,  1.0226e+01,\n",
      "         -7.4343e-01,  9.3748e-01, -8.5360e-01, -1.7097e+00, -4.3297e+00,\n",
      "         -2.3667e+00, -1.3821e+00, -4.5345e+00, -2.3896e+00, -2.4849e+00,\n",
      "         -4.5818e+00, -1.4923e+00, -1.0502e+00,  1.9651e+00, -8.0901e-01,\n",
      "         -2.8727e+00, -7.8400e-01, -1.8091e+00, -2.0265e+00, -2.6331e-01,\n",
      "         -1.1333e+00, -9.2206e-01,  5.5013e-01, -9.7816e-01, -3.1677e-01,\n",
      "         -4.0287e+00, -1.3225e+00, -4.2696e+00,  7.1298e-01, -7.3434e-01,\n",
      "         -2.6860e+00, -2.9846e+00, -3.1025e+00,  1.4333e+00, -1.7502e+00,\n",
      "          7.9281e-01, -3.0649e+00, -1.2510e+00, -6.4412e-02,  2.2988e+00,\n",
      "          2.0278e+00,  9.0849e-01, -2.5991e+00, -3.1488e+00, -1.6250e+00,\n",
      "         -4.0862e+00, -2.5259e+00, -2.9284e+00, -3.3110e+00, -2.8427e+00,\n",
      "          4.5466e-01,  5.4950e-01, -1.6668e+00,  3.2066e+00, -2.4826e+00,\n",
      "         -6.8117e-01,  4.7195e-01,  2.1732e+00, -1.1084e+00,  1.3873e+00,\n",
      "         -1.8281e+00,  2.0604e+00, -2.9093e+00,  1.8062e+00, -4.7320e-01,\n",
      "         -2.1459e+00,  5.5117e+00,  3.4923e+00,  1.0771e+00,  1.5398e+00,\n",
      "         -2.3606e+00, -2.3686e+00, -8.0120e-01,  9.7639e-01,  6.0732e-01,\n",
      "         -1.7637e-01, -6.3785e-01, -1.9035e+00, -2.4610e+00, -5.1628e+00,\n",
      "         -2.2162e+00, -3.3535e+00, -3.6218e+00, -4.8457e-01, -2.2435e-01,\n",
      "         -4.4266e+00, -3.5524e+00,  3.3114e-01,  2.4663e+00,  1.0161e+00,\n",
      "          2.3914e+00, -1.8892e+00,  8.1052e+00,  5.3127e+00,  7.0273e+00,\n",
      "          7.5413e+00,  2.6609e+00, -2.1054e+00,  2.2517e+00, -3.3763e+00,\n",
      "          2.1688e+00, -7.7505e-01,  1.2537e-01, -5.7957e-01, -1.7892e+00,\n",
      "          8.3523e-01,  1.9412e+00, -5.3581e-01,  1.7679e+00,  6.3801e-01,\n",
      "         -2.7795e-01,  2.6644e+00,  1.3357e+00,  2.7852e+00,  2.8733e+00,\n",
      "         -8.4961e-01,  1.1467e+00,  1.0321e-01, -6.9663e-01,  1.3344e+00,\n",
      "         -3.7688e-01, -2.7996e+00, -1.4328e+00, -1.1255e+00,  1.2765e+00,\n",
      "          3.1829e+00, -2.1026e+00,  4.0650e-01,  2.1868e+00, -2.8341e-01,\n",
      "          1.5518e-01,  2.0826e+00,  3.9935e+00, -1.3583e+00,  3.4196e+00,\n",
      "          4.9860e+00,  1.0730e+00, -2.8904e+00, -1.3393e+00, -1.8491e+00,\n",
      "          1.9392e+00,  1.6106e+00, -3.1223e+00, -3.7257e+00, -1.2965e+00,\n",
      "         -1.6193e+00, -2.2862e+00, -1.5220e+00,  6.9512e-02, -2.3355e+00,\n",
      "         -5.2706e-01, -2.9343e+00, -1.6526e+00, -1.7697e+00, -7.3893e-01,\n",
      "         -1.5848e+00, -1.8936e+00, -8.3526e-01, -3.5225e-01,  2.8511e+00,\n",
      "          1.7557e+00, -1.4094e-01, -8.5713e-01, -1.9326e+00,  9.4880e-01,\n",
      "          2.3810e+00, -2.0441e+00,  5.6142e+00, -4.4558e-01, -4.3158e+00,\n",
      "         -4.6506e+00,  3.5519e+00,  2.2944e+00,  1.4373e+00,  1.1274e+00,\n",
      "          8.0569e-01,  2.3226e+00, -1.1193e+00,  6.2762e-01,  2.4759e+00,\n",
      "         -3.7436e+00,  2.4602e+00, -9.7936e-03, -4.3102e-02,  1.2951e+00,\n",
      "         -7.4128e-01, -3.2635e+00, -2.0521e+00, -3.0467e+00, -2.4487e+00,\n",
      "         -2.4217e+00,  4.5652e-01, -1.4667e+00, -2.3379e+00, -3.7967e+00,\n",
      "         -1.7296e+00,  3.4884e+00, -3.0352e-01, -3.5325e-01,  1.6397e+00,\n",
      "         -5.2150e-01, -8.8680e-01,  2.3518e-01, -9.2031e-01, -2.7596e+00,\n",
      "         -2.2238e+00, -3.1003e+00, -2.7426e+00, -3.0240e+00, -3.3012e+00,\n",
      "         -4.1185e-01,  6.9946e+00,  3.1686e+00,  4.3018e-01,  2.1024e+00,\n",
      "         -7.1440e-01, -4.7168e-01,  1.6482e+00,  3.7872e+00,  3.1610e+00,\n",
      "          1.7166e-01,  1.3347e+00,  1.6038e-01,  2.2216e+00, -5.0442e-01,\n",
      "          1.9938e+00, -9.9591e-01, -6.8237e-01, -1.5482e+00,  1.4159e-01,\n",
      "         -1.2461e-01, -2.0958e+00, -3.5342e+00, -3.2787e+00,  4.7001e+00,\n",
      "         -1.7098e+00, -1.6160e+00, -3.8520e-01,  1.3432e+00,  2.1328e+00,\n",
      "          1.9219e+00, -9.5549e-01,  1.5560e+00, -1.1975e+00, -1.1440e-01,\n",
      "         -1.5565e-01,  2.0860e+00,  1.2957e+00,  1.1643e+00,  1.4206e+00,\n",
      "          1.5993e+00,  2.5978e-02, -8.2818e-01, -1.8292e+00, -6.4479e-01,\n",
      "          3.8964e+00,  3.2495e+00,  4.7867e+00, -1.0785e-01,  4.5906e+00,\n",
      "          2.0684e+00,  4.9950e+00,  5.3699e+00,  2.3988e+00,  5.6057e-01,\n",
      "          3.2203e-01,  4.4027e+00,  4.5507e+00,  3.8017e+00,  2.4229e+00,\n",
      "          6.0182e+00,  3.4414e+00,  4.2294e-01,  8.6794e-01,  1.2992e+00,\n",
      "          3.6681e+00, -4.5272e-01,  2.2689e-01,  1.7091e-01,  1.6655e-01,\n",
      "         -1.6425e+00, -7.3812e-01, -2.2466e+00,  4.0757e+00,  2.6308e+00,\n",
      "         -1.3959e+00, -1.6902e+00,  8.1049e-01,  6.5013e+00,  8.1885e+00,\n",
      "         -3.6340e+00, -2.8690e+00, -2.5249e+00,  1.1417e+00, -3.5947e+00,\n",
      "          7.7709e-01, -1.6715e+00,  1.3156e+00, -3.4259e+00,  1.1289e+00,\n",
      "          7.9293e-01, -3.6323e+00, -2.5942e+00, -1.0156e+00, -9.2355e-01,\n",
      "         -4.3363e+00, -4.8087e+00, -6.3187e+00, -3.0306e+00, -1.8797e+00,\n",
      "         -3.4469e+00, -3.7007e-01,  1.0106e+00, -3.8571e+00, -4.7371e-01,\n",
      "         -5.7186e-01, -3.2219e+00,  4.5956e-01,  6.1324e+00,  3.2498e+00,\n",
      "          6.2232e+00,  7.7416e+00,  1.3985e+00, -5.6599e-01,  1.2228e+01,\n",
      "          1.9481e+00,  9.0187e-01,  5.9624e+00,  1.8996e+00, -1.7202e+00,\n",
      "          8.5065e-01,  2.7942e+00,  4.6284e+00,  6.3721e-01,  2.6951e+00,\n",
      "          3.7942e+00,  9.4250e-01,  3.6188e+00,  3.6382e+00,  1.3759e+00,\n",
      "          1.6496e+00, -1.9825e+00,  1.5813e+00,  3.3870e+00,  6.1206e+00,\n",
      "          8.9506e+00,  3.0565e+00,  3.4495e+00,  7.6306e-01,  1.1760e+00,\n",
      "          5.4357e+00,  3.1480e+00,  5.9884e+00,  1.0140e+00,  9.2857e-01,\n",
      "         -1.3941e+00, -1.9357e+00, -2.3664e+00,  1.2491e+00, -1.1611e+00,\n",
      "          9.5609e-01,  8.0988e-01,  4.9830e+00,  8.5722e-01,  3.2131e-01,\n",
      "         -3.2520e+00, -2.1860e+00,  1.6592e+00,  5.7804e-01, -1.2440e+00,\n",
      "          5.1800e+00,  1.9276e+00,  2.8455e+00,  3.5473e+00,  3.2580e+00,\n",
      "          4.5302e-01, -3.1682e+00, -7.9912e-01,  9.2364e-01, -1.8772e+00,\n",
      "         -6.6823e-01, -1.9484e+00, -2.7915e+00,  5.2936e-01, -2.8036e+00,\n",
      "         -6.4118e-01,  1.1571e-01,  2.3942e+00, -2.2101e+00, -1.3468e+00,\n",
      "         -8.6154e-01, -4.2722e-01, -1.0709e+00, -3.3641e+00, -4.6208e+00,\n",
      "         -5.2523e+00,  2.7978e+00, -2.5248e+00, -2.5668e+00, -8.3101e-01,\n",
      "         -1.3064e-02,  1.2767e-01,  3.6248e+00, -8.0448e-01, -1.9102e+00,\n",
      "          4.3074e+00, -1.1321e+00, -4.9881e-02, -1.7012e+00, -1.8932e+00,\n",
      "          7.2688e-01, -1.6728e+00, -2.9643e-02,  2.5999e+00,  3.1107e+00,\n",
      "         -1.3430e+00,  1.5795e+00,  3.7921e+00,  4.5477e+00,  5.5100e-02,\n",
      "         -6.5895e-01, -2.3225e+00,  1.7522e+00, -9.0911e-01,  7.5009e-01,\n",
      "          7.8906e-01, -1.2216e+00, -9.5175e-01,  6.4284e-01,  3.5704e+00,\n",
      "          2.6802e-01,  2.5286e+00, -1.0705e+00, -1.3291e+00, -4.4601e+00,\n",
      "         -1.6025e+00, -1.6859e+00,  1.3561e+00, -5.1992e-01, -1.7267e+00,\n",
      "         -1.0237e+00, -4.2256e+00, -8.9961e-01, -7.4917e-01, -4.7541e-03,\n",
      "         -1.2997e+00,  9.0109e-01, -9.2460e-01, -2.3656e+00, -2.4511e-01,\n",
      "         -1.4760e+00,  2.7879e-01,  3.8973e+00,  2.6545e+00, -2.6309e+00,\n",
      "         -2.0029e+00, -2.6691e+00,  5.7428e+00, -2.5078e+00,  3.9125e+00,\n",
      "          3.3802e+00, -1.8976e+00,  4.0215e-01, -5.7656e-01, -1.9560e+00,\n",
      "         -2.7507e+00, -9.5992e-01,  3.0569e-01, -2.0387e-01, -1.7515e+00,\n",
      "         -1.8059e+00, -1.9214e-01, -1.6085e+00, -1.2414e+00, -3.2165e+00,\n",
      "         -2.3762e+00,  2.1229e+00, -8.6113e-01, -6.9082e-02, -9.3344e-02,\n",
      "          1.2373e+00, -1.6683e+00,  1.4061e+00, -2.2035e+00, -2.5980e+00,\n",
      "         -5.4727e-01, -3.6967e-01,  1.0839e-01,  1.7182e+00,  3.1103e+00,\n",
      "         -3.4148e-01,  4.8361e-01,  7.1774e-01,  1.2359e+00,  3.5575e+00,\n",
      "          2.2130e+00, -8.1976e-01, -3.7366e+00,  1.8638e+00,  3.8459e+00,\n",
      "         -4.6864e+00, -3.1367e+00,  1.9979e+00, -1.4765e+00, -3.5434e+00,\n",
      "          2.7147e-01,  1.5758e-01, -2.2203e+00, -8.8584e-01,  9.1016e-01,\n",
      "         -3.8714e+00,  2.0115e+00, -2.2711e+00,  1.2933e+00, -1.3080e-01,\n",
      "         -1.3954e+00,  1.0590e+00, -1.3786e+00, -1.0495e+00, -1.6592e+00,\n",
      "          3.6007e-01, -1.4405e+00,  4.0051e+00, -3.6748e+00,  1.0545e+00,\n",
      "         -1.9257e+00, -2.3484e+00,  9.7999e-02, -2.3633e+00,  5.8473e+00,\n",
      "         -3.1767e+00,  1.6821e+00, -2.1487e-01,  2.0134e+00,  9.9751e-01,\n",
      "         -9.1700e-01,  1.0329e+00, -2.1288e+00, -8.0071e-01, -3.1810e+00,\n",
      "          1.4990e-01,  3.4161e+00,  1.0617e+00, -1.5990e+00, -3.7944e+00,\n",
      "         -2.0737e+00,  2.6701e+00, -1.3637e+00,  2.7590e+00,  2.6499e+00,\n",
      "         -1.2798e+00, -1.2114e+00,  1.8079e+00, -1.2769e+00,  1.1949e+00,\n",
      "         -2.9049e+00, -2.1163e-01,  1.0747e+00,  4.2173e+00, -1.1117e+00,\n",
      "          2.4034e-01,  7.7024e-02,  2.6814e+00, -2.3674e-01, -1.5051e+00,\n",
      "         -3.5194e-01, -1.7955e+00,  1.8221e+00,  7.5486e-01,  3.4942e+00,\n",
      "          1.7548e+00, -3.8180e+00,  3.2284e+00,  2.5090e+00, -1.9807e+00,\n",
      "          1.2731e+00, -1.2485e+00,  1.5575e+00,  2.2556e+00,  2.0983e+00,\n",
      "         -1.2511e+00, -2.9627e+00, -3.2703e+00, -1.3629e+00,  2.3469e+00,\n",
      "         -1.8782e+00,  9.8141e-01, -4.7438e+00, -1.2810e-01,  3.0213e+00,\n",
      "          3.0131e-01, -7.9693e-01, -9.0057e-01, -4.3237e-01, -7.3408e-02,\n",
      "         -1.2558e+00, -3.6215e-01,  6.0335e-01, -3.5107e+00, -6.3647e-02,\n",
      "         -1.9427e+00,  4.1328e+00, -2.3632e+00,  1.9489e+00, -1.6020e+00,\n",
      "         -1.9738e+00, -2.6581e+00,  6.3486e-01,  3.2593e+00,  9.5388e-01,\n",
      "          1.1132e+00, -1.6052e+00, -1.6145e+00,  1.5187e+00,  5.4706e-01,\n",
      "         -5.2444e+00,  2.8325e+00,  1.3545e-01, -2.1629e+00,  1.5062e+00,\n",
      "         -2.7758e+00,  1.0099e+00, -1.0977e+00,  2.9688e-01,  2.7338e+00,\n",
      "         -1.8961e+00, -1.8674e+00, -5.2760e-01,  6.2060e-01,  1.9744e+00,\n",
      "         -2.4547e+00,  2.3910e+00,  4.0051e-01,  3.7005e+00,  2.9669e+00,\n",
      "          4.2288e-01,  3.4529e+00,  6.3890e-01, -1.3558e+00, -2.3161e+00,\n",
      "          2.1552e+00, -8.1856e-01, -2.3334e+00,  6.5089e-01, -3.1030e-01,\n",
      "         -1.0995e+00, -1.8311e+00, -2.6605e+00,  2.6094e-02,  6.1690e-01,\n",
      "         -2.2041e-01, -3.6245e+00, -3.2617e+00, -1.7824e-01, -9.2142e-01,\n",
      "         -1.6884e-01,  3.6516e+00,  8.8068e-01, -5.0189e-01, -2.9687e+00,\n",
      "          1.4394e+00, -1.9882e+00, -1.2298e+00,  5.0944e-01,  3.0090e+00,\n",
      "         -1.8490e+00,  3.6793e-01,  1.8976e+00,  4.4494e-01, -3.1736e+00,\n",
      "         -2.3354e+00,  1.8554e-01, -1.5413e+00,  1.9353e+00, -1.0357e+00,\n",
      "         -1.7763e+00, -1.5498e+00,  1.2115e+00, -1.6087e+00, -2.3283e+00,\n",
      "          1.8781e+00, -2.0936e+00,  8.9267e-01, -8.3320e-01, -1.9185e+00,\n",
      "         -1.4630e+00,  4.7133e+00, -5.1350e-02,  1.0988e+00,  6.1271e-01,\n",
      "          1.0701e+00, -2.9078e+00,  1.0655e-01,  2.2384e+00, -1.6070e-01,\n",
      "         -1.8381e+00,  2.3976e+00, -1.5609e+00, -1.6789e+00, -3.1135e+00,\n",
      "          2.8952e+00,  1.6973e+00,  2.0998e+00, -2.2147e+00, -7.7449e-01,\n",
      "         -1.0614e+00, -1.1546e+00,  2.5202e-01, -2.7782e+00,  5.5105e-01,\n",
      "          8.1182e-02, -2.6441e+00,  2.5673e+00, -1.9286e+00, -3.9313e+00,\n",
      "          4.1574e-01,  8.8109e-01, -6.2036e-01, -1.7874e+00, -1.1296e+00,\n",
      "          2.9429e-01,  2.2622e+00, -1.3537e+00,  2.1665e+00, -2.5070e+00,\n",
      "          3.8441e-01,  1.8388e+00, -2.3804e+00,  3.9858e+00,  1.4895e+00,\n",
      "          1.2673e-01,  2.0359e+00, -1.9407e+00,  2.1154e-02, -1.3332e+00,\n",
      "         -8.7482e-01,  2.7858e-01, -3.1180e-01, -2.7410e+00,  6.6596e+00,\n",
      "          8.5551e-02, -8.4650e-01, -4.2622e-02, -2.0881e-01, -1.3148e+00,\n",
      "         -1.1971e+00,  1.4254e-01, -9.5049e-01, -9.0741e-01,  2.0536e-01,\n",
      "         -1.4577e+00, -1.7371e+00,  4.9616e+00, -3.0682e+00,  1.3456e+00,\n",
      "          3.1616e+00, -9.9715e-01,  1.5503e+00, -2.5169e+00,  3.5428e-01,\n",
      "         -3.0346e+00, -2.1998e+00, -2.1323e-01,  2.5798e+00,  1.0855e+00,\n",
      "         -4.5728e-01,  8.0531e-01, -9.2590e-03,  4.1299e+00, -3.6178e+00,\n",
      "         -4.0347e+00, -2.4523e+00, -1.6364e+00, -1.7646e-01,  1.9532e+00,\n",
      "         -3.9809e+00, -6.5336e-01,  2.2434e+00,  1.0989e+00,  9.2112e-01,\n",
      "         -8.9039e-01, -1.5373e+00,  2.5675e+00,  4.4224e-01, -1.2758e-01,\n",
      "         -3.1385e+00, -1.4726e-01, -6.2899e-01, -2.6167e+00,  6.9405e-01,\n",
      "         -1.7604e+00, -2.2777e-01, -3.8626e+00, -2.8184e+00,  4.7400e-01,\n",
      "         -2.0895e+00, -1.4464e+00,  1.1917e+00, -4.1274e-02,  1.7565e+00,\n",
      "          9.3592e-01,  2.3383e-01, -5.9635e+00,  2.8129e+00, -2.8350e+00,\n",
      "         -1.7624e+00,  1.0067e+00, -2.3021e+00, -9.0001e-02,  2.5938e+00,\n",
      "         -1.3333e+00, -2.8762e+00,  4.5682e-01,  4.5932e-01,  5.8956e-01,\n",
      "          1.4983e+00, -3.4390e-01,  4.9225e+00,  1.8982e+00, -4.0196e-01,\n",
      "         -1.4366e+00,  7.9389e-02, -2.4730e+00, -3.4667e+00, -8.4288e-01,\n",
      "          1.5872e+00,  6.7413e-01,  1.2892e+00,  1.5479e+00, -2.9376e+00,\n",
      "          3.7552e+00, -1.0290e+00,  1.0744e+00,  1.7443e+00, -6.7868e-01,\n",
      "          1.4537e+00,  2.3461e+00,  2.0929e+00, -1.2307e+00,  2.0084e+00,\n",
      "          3.2163e+00,  7.6188e-01,  2.1911e+00,  3.4916e+00,  5.9685e-01,\n",
      "          8.2398e-01, -3.4410e-02,  2.4123e+00, -7.3261e-01,  1.5995e-01,\n",
      "          1.1382e+00,  1.5150e+00,  2.8766e-01, -1.1969e+00, -1.0107e+00,\n",
      "          1.1538e+00, -1.2463e+00, -2.6412e+00,  2.1086e+00, -2.2157e+00,\n",
      "          2.5370e+00, -4.6881e+00, -3.6386e-01, -1.0164e+00, -4.7405e+00,\n",
      "         -5.1055e-01,  2.7766e+00, -5.3713e-01,  8.5734e-01,  9.4925e-01,\n",
      "         -1.7233e-01,  1.6518e+00, -1.6216e-01,  1.6580e+00,  1.3505e+00,\n",
      "          7.5062e-02, -3.5458e-01,  2.0466e+00, -2.2008e+00,  1.6003e+00,\n",
      "         -2.2088e-01, -5.9542e-01,  1.0725e-01, -2.3641e-01, -2.3619e+00,\n",
      "         -2.6332e+00,  3.3523e+00, -4.2019e-01, -1.2060e+00,  1.4209e+00,\n",
      "         -4.4611e+00, -6.3842e-01, -2.9908e+00,  1.7514e+00,  2.1272e-03,\n",
      "         -1.7089e+00, -5.2966e+00,  2.3959e+00, -3.8570e+00,  1.2658e+00,\n",
      "          3.7582e+00,  1.5193e+00, -9.7867e-02, -7.1547e-01, -3.3049e+00,\n",
      "         -2.5434e+00, -1.8704e+00,  2.0238e+00,  9.7855e-01, -3.0192e-01,\n",
      "         -3.2443e+00,  2.0180e+00,  8.7406e-01,  1.4666e+00, -5.6570e-01,\n",
      "         -9.9208e-01,  1.1068e-01,  2.8017e+00,  3.7557e+00,  4.1288e-01,\n",
      "          1.2231e+00,  3.6819e+00,  1.6408e+00,  1.0336e+00,  8.3443e-02,\n",
      "         -2.1718e-01,  2.0745e+00,  2.5246e+00, -5.7355e-02, -2.3653e+00,\n",
      "         -3.1012e+00, -3.7632e+00, -1.9030e+00, -3.1211e-01,  3.9939e+00,\n",
      "         -2.4941e+00,  2.3295e+00,  5.0701e-01,  1.9074e+00, -2.4435e+00,\n",
      "         -1.9820e+00, -4.7218e+00,  1.1311e+00, -5.6040e-02,  2.0821e+00,\n",
      "          1.6971e+00,  1.0688e+00,  2.7585e+00,  3.0732e+00, -4.2951e-01,\n",
      "          5.4380e+00,  1.1212e+00, -4.7700e-01,  7.7136e-01, -9.5652e-01,\n",
      "         -1.3439e+00,  2.3741e+00,  1.9677e+00,  2.0530e+00,  1.5606e+00,\n",
      "         -1.8324e+00, -1.5913e-01, -1.4292e+00,  5.4062e-01, -8.5002e-01,\n",
      "          5.5642e-01, -4.4599e+00,  1.0871e+00,  1.0928e+00, -1.9785e+00,\n",
      "         -6.4040e-01,  2.0364e-02,  2.2609e-01, -6.8339e-01, -2.9999e+00,\n",
      "         -2.0889e+00, -3.8507e+00,  2.2257e+00,  1.2675e+00, -7.7333e-02,\n",
      "          5.9371e+00,  2.7245e-01, -2.6865e+00, -1.0419e+00, -2.0970e+00,\n",
      "         -5.7074e-01,  3.4364e+00,  1.7962e+00,  7.0115e-01, -1.3345e-01]]) tensor([0])\n",
      "tensor([[ 6.6739e-02, -4.7377e+00,  2.2504e+00, -1.7165e+00,  1.7015e+00,\n",
      "         -1.4013e+00,  1.5661e+00,  9.1741e+00,  7.4190e+00,  2.0156e+01,\n",
      "         -5.9977e+00, -4.0540e+00, -2.6111e+00,  9.2982e-01, -1.8290e+00,\n",
      "         -6.9683e-01,  7.3959e-01, -6.4564e-01,  5.1663e+00, -1.4979e+00,\n",
      "          1.6444e+00,  2.5713e+00,  9.0176e+00,  1.2978e+01,  3.3162e+00,\n",
      "         -2.8473e+00, -4.2092e+00, -6.0121e+00, -6.3598e+00,  1.4533e+00,\n",
      "         -2.4170e+00, -5.1232e+00, -2.3618e+00,  4.4991e+00,  6.9970e+00,\n",
      "          4.0131e+00,  4.6909e+00, -6.3666e-01, -4.5523e+00,  3.8470e+00,\n",
      "         -5.3597e+00, -2.3027e+00,  2.5720e-01, -7.4766e-01, -3.6949e+00,\n",
      "          4.8740e-01, -4.3798e+00, -1.5709e+00,  3.7388e+00,  5.8242e+00,\n",
      "          4.4065e+00,  1.4982e+00, -3.6330e+00, -4.3727e+00, -1.0243e-01,\n",
      "         -5.5595e+00, -1.2690e+00, -4.1200e+00, -1.9790e+00, -5.3466e+00,\n",
      "         -1.8226e+00, -8.9804e-01,  1.9280e+00,  2.3515e+00, -3.6240e+00,\n",
      "         -9.5500e-01, -4.6376e-01,  2.6240e+00, -5.4959e-02,  1.2120e+00,\n",
      "         -5.5305e+00, -1.2440e+00, -4.8165e+00, -1.2659e+00, -3.5318e+00,\n",
      "         -3.0115e+00,  2.4101e+00, -1.0203e+00, -3.6517e+00, -4.1106e+00,\n",
      "          6.3461e+00,  1.0447e+00,  4.2152e+00,  8.2796e-01,  6.5662e+00,\n",
      "          3.0368e+00,  2.5845e+00,  5.7929e+00,  3.0190e+00,  1.2212e+00,\n",
      "         -4.5658e-01,  4.7855e+00, -3.2340e+00,  1.0570e+01,  1.8546e-01,\n",
      "         -9.4799e-01,  4.0675e+00,  1.7566e+00,  4.1029e+00,  6.4252e+00,\n",
      "          1.1635e+01,  5.9411e+00,  7.6158e+00,  9.9081e-01,  6.6387e+00,\n",
      "          4.1617e+00,  8.1288e+00, -3.1057e+00, -3.1066e+00, -2.3833e+00,\n",
      "         -3.3438e+00, -5.8630e+00,  2.9784e+00, -1.4662e+00, -2.5826e+00,\n",
      "         -4.2990e+00, -1.9433e+00, -2.8410e+00, -1.6686e+00, -4.6274e-01,\n",
      "          8.4291e-01, -2.3137e+00, -6.1565e+00, -4.9353e+00, -5.6412e-01,\n",
      "          7.9855e-01, -1.7709e+00,  7.2785e+00,  9.0804e+00,  1.2402e+00,\n",
      "          1.8857e+00,  3.9293e+00,  8.8229e-01, -2.3151e+00,  7.0813e+00,\n",
      "          5.5417e+00,  6.3684e+00,  7.5267e+00,  9.5408e+00,  1.1656e+00,\n",
      "         -2.3053e+00, -3.1107e-01, -2.2904e+00,  5.5447e+00,  7.0618e+00,\n",
      "          5.1764e+00,  7.8881e+00,  4.4164e+00,  3.5679e+00, -1.0602e+00,\n",
      "          5.1666e+00,  3.2547e+00,  3.3722e+00,  4.3863e+00,  4.1020e+00,\n",
      "          8.3679e+00,  2.9790e+00,  1.9061e+00,  1.5711e+00,  2.7034e+00,\n",
      "          9.5159e+00,  3.9861e+00,  3.4955e+00,  4.5167e+00,  7.3122e+00,\n",
      "          3.6631e+00,  3.6453e+00,  1.9779e+00,  7.2353e-01,  5.9115e+00,\n",
      "          9.0605e+00,  3.1303e+00,  6.3489e+00,  2.4873e-01,  5.2021e+00,\n",
      "          5.0242e+00,  2.7604e+00,  9.2320e+00,  2.3717e+00,  9.1378e+00,\n",
      "          7.0326e+00,  7.2712e+00,  7.7676e+00,  1.0970e+01,  5.6442e+00,\n",
      "          4.5364e+00,  6.4271e+00,  4.9470e+00,  6.9614e+00,  1.3621e+01,\n",
      "          4.6063e+00,  7.4418e+00,  9.2091e+00,  5.0054e+00,  5.8260e+00,\n",
      "          8.5906e+00,  9.0504e+00,  1.4933e+01,  9.9161e+00,  1.3549e+01,\n",
      "          1.0669e+01,  5.2612e+00,  7.3636e+00,  7.2510e+00,  7.0376e+00,\n",
      "          9.2807e+00,  8.8407e+00,  1.5072e+00,  7.8611e+00,  4.9723e+00,\n",
      "          7.0392e+00,  1.3058e+00,  6.6444e+00, -2.7888e-01,  6.9462e+00,\n",
      "          7.6106e-01,  3.3033e+00,  8.5831e+00,  2.6888e-02,  7.0760e+00,\n",
      "          2.9620e+00,  9.0201e+00,  3.2827e+00,  9.0894e+00,  8.8669e+00,\n",
      "          2.6854e+00,  1.3553e+01,  6.5106e+00,  8.5873e+00,  1.1640e+01,\n",
      "          5.8699e+00,  7.7616e+00,  9.5638e+00,  1.4991e+01,  7.3178e+00,\n",
      "          5.3509e+00,  3.9909e+00,  2.1305e+00,  9.3731e+00,  1.0626e+01,\n",
      "          6.7375e+00,  5.6390e+00,  7.0998e+00,  7.1397e+00,  9.3302e+00,\n",
      "          1.2277e+01,  7.5826e+00,  6.5462e+00,  4.6814e+00,  6.4414e+00,\n",
      "          5.3656e+00,  5.1955e+00,  9.5217e+00,  3.5913e+00,  8.3499e+00,\n",
      "          3.3770e+00,  1.3821e+01,  3.9304e+00,  4.3333e+00,  4.8120e+00,\n",
      "          6.3747e+00,  4.4070e+00,  4.9628e+00,  2.8643e+00,  7.4377e+00,\n",
      "          9.5313e+00,  9.1054e+00,  1.1548e+01,  3.8836e+00,  4.3730e+00,\n",
      "          4.4156e+00,  4.9025e-01,  3.4733e+00,  4.6479e+00,  8.2993e-01,\n",
      "          8.2240e+00,  1.1335e+01,  2.6855e-02,  3.6185e+00,  6.5827e-01,\n",
      "          4.1392e+00,  5.8256e+00,  4.5235e+00,  2.8011e+00, -7.1117e-01,\n",
      "          4.6392e+00,  9.8509e-01,  2.4377e+00,  1.4319e+00,  2.3401e+00,\n",
      "          2.1350e+00,  1.9936e+00,  4.4188e-01,  1.9297e+00,  9.3201e+00,\n",
      "          1.2659e+01,  3.0030e+00,  1.4510e+01,  7.2196e+00,  6.1645e+00,\n",
      "         -6.3783e+00, -4.9476e+00, -2.1006e+00, -4.0693e+00, -5.1801e+00,\n",
      "          4.9389e+00, -1.4857e+00, -1.2252e+00, -5.3102e+00, -1.1687e+00,\n",
      "         -2.3529e+00, -5.9666e+00, -4.8535e+00, -5.2034e+00, -3.3173e+00,\n",
      "         -4.8187e+00, -3.7954e+00, -8.6800e+00, -7.4193e+00, -8.0710e+00,\n",
      "         -9.8167e+00, -2.9663e+00, -3.3205e+00, -7.9713e+00, -5.0355e+00,\n",
      "         -8.4534e+00, -6.5416e+00,  7.6641e-01, -2.6044e-01,  1.5354e+00,\n",
      "          5.0496e+00,  3.2920e+00,  3.3747e+00, -1.3895e+00,  7.8536e+00,\n",
      "         -1.6362e+00,  3.9481e+00,  6.1551e+00,  2.5054e+00, -1.4663e+00,\n",
      "          5.3479e+00,  8.3845e+00,  1.0882e+01,  7.7232e+00,  6.2381e+00,\n",
      "          9.8461e+00,  9.3985e+00,  1.1959e+01,  5.9796e+00,  2.0149e+00,\n",
      "          3.9214e+00, -1.2753e+00, -2.2150e+00,  1.0868e+00,  4.5147e+00,\n",
      "          9.5906e+00,  4.4430e+00,  5.8643e+00,  4.0407e+00,  4.6077e+00,\n",
      "          5.7612e+00,  9.1803e+00,  7.6484e+00,  4.0774e+00,  4.2939e+00,\n",
      "          1.8978e+00,  9.5958e+00,  9.7955e+00,  5.3213e+00,  9.5858e+00,\n",
      "          7.5777e+00,  6.3334e+00,  1.0227e+01,  6.6817e+00,  8.1856e+00,\n",
      "          8.0734e+00, -1.3443e-01,  4.8072e+00,  8.0810e+00,  7.5404e+00,\n",
      "          7.0227e+00,  7.8892e+00,  7.2348e-01,  3.4931e+00,  2.1900e+00,\n",
      "          6.5099e+00,  7.1304e+00,  3.2978e+00,  7.4239e+00, -2.3726e+00,\n",
      "         -1.4495e+00, -3.8837e-02, -3.6641e+00, -6.8298e+00,  1.5188e+00,\n",
      "          1.5519e-01, -3.7549e+00, -1.2571e+00, -5.1783e+00, -1.4627e-01,\n",
      "         -9.0699e-01, -2.4916e+00, -4.3170e+00, -4.5449e+00, -4.1119e+00,\n",
      "         -3.4535e+00, -5.6912e+00,  1.0077e+00,  2.2626e+00, -3.9662e+00,\n",
      "         -4.6477e+00, -3.3201e+00,  2.2617e+00,  5.5242e-01, -1.7111e+00,\n",
      "         -6.3879e+00, -4.6865e+00, -3.3909e+00, -5.0535e+00, -3.5915e+00,\n",
      "         -2.4521e+00, -1.3897e+00,  9.7540e-01, -9.8746e-01, -1.6270e+00,\n",
      "         -4.2486e+00, -3.3867e+00, -7.1999e-01,  3.9767e+00, -5.4922e-01,\n",
      "         -3.1245e+00, -3.1977e+00, -3.3516e-01, -1.9659e+00, -1.6703e+00,\n",
      "         -1.0684e+00, -8.2943e-01, -6.2477e-01, -4.0115e+00,  5.7937e+00,\n",
      "         -7.9916e-01, -2.9863e+00, -2.0098e+00, -6.8010e+00, -2.4486e-01,\n",
      "         -5.4821e-01, -8.8724e+00,  5.8152e-01, -1.7439e+00, -3.3454e+00,\n",
      "         -1.3115e+00, -3.5453e+00, -1.6138e+00, -3.8065e+00, -4.0247e+00,\n",
      "         -4.5982e+00,  1.1271e+00, -1.2644e+00, -3.2406e+00, -4.9545e-01,\n",
      "          1.5697e+00, -1.9758e+00,  1.7023e+00,  3.9455e+00, -5.8481e+00,\n",
      "         -2.5815e+00, -5.3886e+00, -4.9059e+00, -2.5817e+00,  2.9444e+00,\n",
      "         -1.6039e+00,  2.8134e+00, -2.1982e+00, -3.5318e+00, -1.3798e+00,\n",
      "          1.0508e-01, -4.9385e+00, -2.5655e+00, -7.1212e-02,  7.2511e-01,\n",
      "         -2.3166e+00, -5.4878e+00, -4.0677e+00, -3.0403e+00, -4.0385e+00,\n",
      "         -3.8732e+00, -1.5994e+00, -1.3780e+00, -2.1990e+00, -2.6785e+00,\n",
      "         -3.5211e+00, -9.9725e-01, -4.7908e+00, -6.9614e+00, -1.6920e+00,\n",
      "         -5.8469e+00, -3.1698e+00, -5.4874e+00, -8.0029e+00, -5.6011e+00,\n",
      "          1.4567e+00,  9.9046e-01, -3.5633e+00, -5.2545e+00, -2.4911e+00,\n",
      "         -7.4849e-01, -3.6911e+00, -3.1702e+00, -3.4034e+00, -5.6244e+00,\n",
      "         -2.4031e+00, -2.6291e+00, -3.3013e+00, -7.4694e-01, -7.8038e-01,\n",
      "         -1.1011e-02, -4.3008e+00, -1.5365e+00,  3.8018e+00, -2.8373e+00,\n",
      "         -5.1621e+00, -8.4584e-01, -1.1885e+00,  3.8789e+00, -2.9337e+00,\n",
      "          5.7560e-01, -4.5375e+00, -4.6952e+00, -2.9776e+00, -2.1767e+00,\n",
      "         -2.9304e+00, -3.7471e+00, -4.3083e+00, -4.4862e+00, -3.8633e+00,\n",
      "         -1.1376e+00, -3.3640e+00,  9.8617e-01, -2.1474e+00, -1.9332e+00,\n",
      "         -4.6664e+00, -1.1760e+00, -3.4374e+00,  2.5670e+00,  4.6736e-01,\n",
      "         -2.1829e+00, -1.2576e+00, -3.0599e+00, -4.2903e+00, -6.4057e+00,\n",
      "         -4.6593e+00, -1.4683e+00,  1.3099e+00, -3.7403e+00, -4.1528e+00,\n",
      "         -1.0381e+00, -4.9964e+00, -1.0932e+00, -6.0720e-01, -3.2838e+00,\n",
      "         -2.6096e+00,  8.4422e-01,  1.7218e+00, -3.9831e+00, -5.4315e+00,\n",
      "         -3.9680e+00, -1.1144e+00, -2.4349e+00,  4.5385e+00,  1.2426e+00,\n",
      "         -2.7458e-01, -8.8895e-01, -7.8313e-01,  7.3749e-03, -2.1232e+00,\n",
      "          4.0141e+00, -5.4086e+00, -1.7470e+00,  1.4163e+00, -2.0025e+00,\n",
      "         -8.9351e-01, -3.1650e+00, -3.8033e+00, -2.4558e+00, -5.2455e+00,\n",
      "         -9.8783e-01, -1.1503e+00,  5.2495e-01, -4.3050e+00,  2.8891e+00,\n",
      "         -3.5592e+00, -3.0533e+00, -6.2687e+00, -3.1696e+00, -6.1813e-01,\n",
      "         -1.1458e+00,  1.4955e+00, -3.5782e+00, -5.1565e+00, -4.8489e+00,\n",
      "          1.1231e+00, -4.4291e-01,  2.5026e-01,  5.0326e+00, -2.6760e+00,\n",
      "         -1.2648e+00, -2.5893e+00, -1.1264e+00, -2.0338e+00,  6.7426e+00,\n",
      "         -1.9548e+00, -3.3018e+00, -5.0666e-01, -1.1013e+00, -1.1994e+00,\n",
      "         -3.9503e-01,  1.2785e-01, -2.6956e+00, -2.1544e+00, -3.9954e+00,\n",
      "         -1.4984e+00,  2.9722e-01, -1.4365e+00, -4.9170e+00, -3.2517e+00,\n",
      "         -2.4553e+00, -5.0800e+00, -2.0562e+00, -4.3060e+00, -2.4633e+00,\n",
      "         -3.5269e+00, -2.5835e+00, -2.7850e+00, -6.0391e+00, -1.8481e+00,\n",
      "         -4.1603e+00, -4.1933e+00,  2.4979e+00,  1.4494e-01, -1.9872e-01,\n",
      "         -2.5713e+00, -3.7642e+00, -2.7065e+00, -1.3190e+00, -3.1022e+00,\n",
      "         -3.0768e+00,  1.4447e+00, -4.3212e+00, -4.7984e+00,  2.4300e+00,\n",
      "         -1.3400e+00, -4.0553e+00,  1.2399e+00, -1.2404e+00,  3.0814e+00,\n",
      "         -1.3776e+00,  5.7452e-01, -1.1954e+00, -7.8420e-01, -5.8944e+00,\n",
      "         -3.1067e+00, -1.6516e+00, -4.9986e+00, -2.1727e+00, -1.2929e+00,\n",
      "          1.8314e+00,  1.8271e+00, -8.9872e-01, -1.5832e+00, -3.6808e+00,\n",
      "          3.1014e+00,  2.5396e+00, -1.8858e+00, -4.2355e+00,  3.3940e-01,\n",
      "         -9.8411e-01,  6.3240e+00, -1.2782e+00, -1.8950e-01, -4.1605e+00,\n",
      "         -6.5654e-01, -2.9265e+00, -2.9310e+00, -1.2691e+00, -1.2233e+00,\n",
      "         -2.5114e+00, -4.3705e+00, -6.6028e+00, -2.7962e+00,  2.0940e-03,\n",
      "          6.0664e+00, -4.4522e-01, -6.0727e+00, -1.4588e+00, -2.1074e+00,\n",
      "         -3.2439e+00,  1.6481e-01, -2.5884e+00, -4.4264e-01, -1.2339e+00,\n",
      "          6.5582e-01, -3.0997e+00, -6.6179e-02, -6.0628e-01,  5.8181e-01,\n",
      "         -1.6913e+00, -1.4712e+00,  3.3660e+00, -5.8911e-01, -4.5657e+00,\n",
      "         -4.1913e+00, -3.9365e+00, -5.9286e+00, -4.5847e+00, -5.3221e+00,\n",
      "          1.5860e+00, -1.2813e+00,  8.6024e-01, -2.3133e+00, -4.3748e+00,\n",
      "         -5.5029e+00, -3.7471e+00, -7.2445e-01, -4.5790e+00, -2.8746e+00,\n",
      "         -6.4775e-01, -3.7048e+00, -3.4065e+00, -1.0755e+00, -7.8407e+00,\n",
      "          5.3320e+00,  3.5952e+00, -3.9734e+00,  4.3970e-01, -9.6590e-01,\n",
      "         -2.0619e-01, -5.3482e+00, -1.4205e+00, -2.8057e-01, -3.1281e-01,\n",
      "         -3.6920e-01, -2.0625e+00, -3.9366e+00, -1.9902e+00, -9.4888e-01,\n",
      "         -4.6041e+00, -2.0397e+00, -2.3172e+00, -3.8385e+00, -1.7009e-02,\n",
      "         -1.4634e+00,  1.4731e+00, -3.7633e+00, -1.8217e+00, -4.4096e+00,\n",
      "         -1.0608e+00,  1.5164e+00, -1.5771e+00,  3.3477e-01, -1.5694e+00,\n",
      "         -4.5697e+00, -1.1626e+00, -5.5236e+00, -1.1624e+00,  1.9836e+00,\n",
      "         -3.1222e+00, -3.3269e+00, -6.4696e+00, -2.3649e+00, -5.8675e+00,\n",
      "         -3.7945e-02, -1.1626e+00, -4.2959e+00, -3.8259e+00, -1.5595e+00,\n",
      "         -5.6814e-01, -1.6242e+00, -1.8804e+00, -2.5530e+00,  7.9654e-02,\n",
      "         -5.6546e+00, -6.3309e+00, -2.1565e+00, -8.6636e-01, -1.2418e+00,\n",
      "         -4.0225e+00, -3.2739e+00,  1.7185e+00, -6.4461e+00, -4.3130e+00,\n",
      "         -9.4434e-01,  2.4575e+00,  3.7215e+00, -9.9585e-01, -3.0959e+00,\n",
      "         -2.6419e+00,  5.6269e-01, -1.6297e+00, -8.4352e+00,  2.6626e-01,\n",
      "         -4.9718e+00,  1.5214e+00, -1.2490e+00, -1.6230e+00, -8.0890e-01,\n",
      "          3.2612e+00, -1.5537e+00, -4.8879e-01, -2.8745e+00, -3.1368e+00,\n",
      "         -6.5311e+00,  5.2072e-01, -4.1473e+00, -3.6279e+00, -3.1087e+00,\n",
      "         -4.2387e+00, -9.3669e-01, -2.5349e+00, -1.8127e+00, -4.3342e+00,\n",
      "         -3.0733e-01, -2.6811e+00, -1.2251e+00, -5.0484e+00,  2.0279e+00,\n",
      "         -6.2962e-01, -3.6579e+00, -8.9830e-01, -4.9452e+00, -1.6332e+00,\n",
      "          1.1408e+00, -3.7045e+00, -3.7850e+00, -9.7713e-01, -5.3029e-01,\n",
      "          7.4562e-01, -1.1548e+00, -6.9845e-01,  6.7903e-01, -7.0824e-01,\n",
      "          3.5615e+00, -2.7089e+00,  1.3710e+00,  2.0821e+00, -1.8971e+00,\n",
      "         -3.6522e+00, -2.3525e+00, -8.9711e-02, -3.2506e+00, -2.2696e+00,\n",
      "          2.1890e+00, -7.4931e-01,  1.2424e+00,  1.7815e+00, -6.9052e+00,\n",
      "         -5.5820e+00, -1.8051e+00, -5.8256e+00, -2.7976e+00, -3.8940e+00,\n",
      "         -6.7252e+00, -2.2282e+00,  4.6990e-01, -2.7709e+00,  2.2437e-01,\n",
      "         -3.0533e+00,  2.5714e+00, -3.2699e+00, -4.0938e+00, -2.0086e+00,\n",
      "          2.0318e+00, -4.9001e+00,  1.6559e+00, -1.2077e+00, -1.9048e+00,\n",
      "         -1.8989e+00, -5.5053e-02, -1.0464e+00, -6.8480e+00,  1.3200e+00,\n",
      "          3.5394e+00, -5.1995e+00,  5.1395e-01, -5.6055e-01, -2.4099e+00,\n",
      "         -2.6269e+00, -3.4526e+00, -4.4567e+00, -1.6887e+00, -3.0756e+00,\n",
      "          9.9549e-01, -1.0987e+00, -4.2828e+00, -6.8596e+00, -6.4893e+00,\n",
      "         -2.8116e+00,  4.1163e-01, -1.2366e+00,  4.6834e-01,  1.7269e+00,\n",
      "         -4.2404e+00, -2.2722e+00, -2.0143e+00, -2.6002e-01, -2.4616e+00,\n",
      "         -6.7601e+00, -5.6255e+00,  5.7198e-01, -4.5331e+00, -2.3783e+00,\n",
      "         -3.3095e+00,  4.3706e-01,  1.1800e-02,  1.2342e+00, -4.4756e+00,\n",
      "         -6.2850e-01, -2.3315e+00, -3.9725e+00, -1.3785e+00, -7.0499e-01,\n",
      "         -2.3820e+00, -2.9299e+00, -5.9360e+00, -5.4750e+00, -5.5028e+00,\n",
      "         -5.2389e+00, -5.3946e+00, -4.1361e+00, -5.4536e+00,  9.1881e-01,\n",
      "         -7.1413e+00, -5.4660e+00, -5.6847e+00, -6.1872e+00, -4.3342e+00,\n",
      "         -4.1100e+00, -5.1279e-01, -2.7109e+00, -3.3854e+00, -3.4823e+00,\n",
      "         -3.6414e+00, -5.5682e-01, -1.7805e+00, -4.4836e+00, -1.2716e+00,\n",
      "         -2.8523e+00, -1.3826e+00, -2.3592e+00, -3.6474e+00, -2.5565e+00,\n",
      "         -3.5502e+00, -5.7087e+00, -1.0559e+00, -2.1238e+00, -2.8163e+00,\n",
      "         -2.5731e+00, -1.0002e+00, -4.2295e+00,  1.6502e+00, -4.5662e+00,\n",
      "         -2.1870e+00, -3.9954e+00, -5.8074e+00, -6.6694e+00, -8.3169e+00,\n",
      "         -4.5415e+00,  2.6580e-01, -4.8952e+00, -3.0332e+00, -5.6719e+00,\n",
      "          3.2422e-01, -1.0688e+00,  2.1501e+00, -2.6906e+00,  2.9920e+00,\n",
      "          2.3462e+00,  1.8057e+00,  4.4200e+00,  3.0416e+00,  3.0748e+00,\n",
      "          4.1511e+00,  1.0519e+00,  1.9197e+00,  9.0646e-01, -4.2153e+00,\n",
      "         -4.2929e+00, -4.7481e+00, -2.8516e+00, -4.2450e+00, -2.2490e+00,\n",
      "         -5.0394e+00, -2.1477e+00, -3.9121e+00, -1.2259e+00, -2.8178e+00,\n",
      "         -1.1216e+00, -2.3797e+00, -2.1794e+00, -3.1835e+00,  9.0284e-01]]) tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 15.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.7602e+00, -5.1006e+00, -1.5845e+00, -1.3637e+00,  7.1186e-01,\n",
      "          1.7239e+00,  2.2597e+00,  5.1177e+00,  5.0591e+00,  2.2972e+01,\n",
      "          9.2571e-02, -1.1743e+00,  3.0293e-01, -1.3205e+00, -1.7226e+00,\n",
      "          1.6729e-01, -1.1525e+00, -9.4002e-01,  3.0077e+00, -2.2720e+00,\n",
      "          9.4055e-01,  4.2800e+00,  6.8286e+00,  8.9723e+00,  3.6879e+00,\n",
      "         -6.6410e-01,  8.0953e-01, -1.2493e+00, -2.5607e+00, -6.3088e-01,\n",
      "         -1.8721e-01, -7.4575e-01,  1.0072e+00,  1.3309e+00,  7.0461e-01,\n",
      "         -1.7939e-01,  1.1260e+00, -8.7020e-01,  2.5821e+00,  2.5286e+00,\n",
      "          2.0509e+00,  3.3878e+00,  2.7445e+00,  3.8563e+00,  2.8725e+00,\n",
      "          2.9410e+00,  8.5213e-01,  3.7949e+00,  3.1803e+00,  4.1433e+00,\n",
      "          2.2746e-01,  2.0610e+00,  1.5298e+00,  4.7920e-01,  2.2985e+00,\n",
      "          1.3052e+00, -1.1126e+00,  3.8941e-01,  2.2656e+00,  3.5423e+00,\n",
      "          4.7905e+00,  3.3872e+00,  5.9888e+00,  3.2111e+00,  2.1360e+00,\n",
      "          4.5508e-01,  5.5269e+00,  6.7378e+00,  4.8817e+00,  3.6956e+00,\n",
      "          3.9021e+00,  1.9237e+00, -6.2564e-01,  2.2048e+00,  1.9214e+00,\n",
      "         -1.3119e+00, -4.2308e-01,  4.1604e+00,  5.9833e-01,  1.4559e+00,\n",
      "          5.8673e+00,  4.7307e+00,  4.2480e+00,  5.1862e+00,  6.1050e+00,\n",
      "          3.5312e+00,  4.4376e+00, -2.5560e+00,  7.1709e-01, -7.5335e-01,\n",
      "         -3.6272e+00,  9.8805e-01,  2.5927e+00,  6.2860e+00, -4.1910e-01,\n",
      "         -7.9246e-01,  4.2591e-01, -4.4699e-01,  1.3114e+00,  3.2959e+00,\n",
      "          6.5670e+00,  5.5686e+00,  2.7538e-01, -2.7688e+00,  3.4431e+00,\n",
      "         -1.1444e+00,  1.1949e+00, -1.7854e-01, -1.4186e+00, -3.7461e+00,\n",
      "         -2.7792e+00,  7.1716e-01,  5.9497e-01, -1.7415e-01, -1.5046e+00,\n",
      "         -1.7814e-01, -8.4334e-01, -1.6076e-01, -7.4423e-01,  6.9175e-01,\n",
      "          3.8423e+00, -1.7617e+00, -4.0701e+00,  3.9044e-01,  2.7370e+00,\n",
      "          5.8824e-02,  1.5951e+00,  9.5591e+00,  1.0173e+01,  7.4793e+00,\n",
      "          4.6558e+00,  7.1082e+00,  8.1206e+00,  5.7941e+00,  1.1809e+01,\n",
      "          8.3540e+00,  5.5009e+00,  4.0962e+00,  1.8169e+01,  3.3700e+00,\n",
      "          2.1894e+00,  5.4889e+00,  6.9665e+00,  5.5856e+00,  6.2606e+00,\n",
      "         -3.5176e-01,  8.6290e+00, -1.4692e-01, -2.6814e+00, -3.3740e+00,\n",
      "         -1.6055e+00, -5.5931e-01, -3.2133e+00, -2.8683e+00, -2.5505e+00,\n",
      "         -9.9124e-01, -2.7327e+00, -2.6956e+00, -2.0760e+00,  6.4430e-01,\n",
      "          2.4189e+00, -2.9817e+00, -3.6492e+00,  1.0134e+00,  8.9047e-01,\n",
      "         -7.7718e-01,  4.9522e-01,  1.5478e+00, -1.3914e+00,  2.5665e+00,\n",
      "          4.5038e+00,  1.5711e+00,  7.5568e+00,  2.6707e+00, -1.2101e+00,\n",
      "         -1.3867e-01,  4.8061e+00,  4.6878e+00,  1.8996e+00, -5.2562e-01,\n",
      "         -1.9233e-01, -3.2668e-01, -9.9132e-01, -2.9729e-01,  1.1359e+00,\n",
      "         -2.8230e-02, -7.8982e-01, -1.8590e+00, -4.2880e-01,  1.2969e+00,\n",
      "         -7.6624e-01, -7.8467e-02,  1.1068e-01, -2.3567e+00,  3.0379e-01,\n",
      "         -5.3900e-01,  1.6885e-01,  3.0260e+00, -8.9085e-01,  1.2860e+00,\n",
      "          1.9202e+00, -2.8094e+00,  5.4328e-01, -2.4754e+00, -6.4529e-01,\n",
      "          1.6743e+00,  1.8319e+00, -5.8342e-02, -4.3373e-01,  2.5110e+00,\n",
      "          1.8917e+00,  4.2387e-01,  1.7506e+00, -3.7725e-01, -1.5870e-02,\n",
      "         -6.9976e-01, -1.6313e+00,  8.6083e-02, -3.1813e+00, -1.6619e+00,\n",
      "         -7.6513e-01,  7.1788e-01,  1.8452e-01, -3.6827e+00, -1.9117e-01,\n",
      "         -7.6480e-01,  1.7489e+00, -9.4350e-01, -1.2372e+00, -7.8708e-01,\n",
      "         -1.7698e+00,  1.3558e+00,  2.2932e+00,  1.0968e+00, -5.5907e-01,\n",
      "         -1.1171e-01, -4.0461e-01, -3.8142e+00,  1.4949e+00, -1.0858e+00,\n",
      "         -2.4200e+00, -2.1258e+00,  1.0296e+00,  2.3088e+00, -8.4811e-02,\n",
      "         -2.4646e+00,  5.6087e+00, -1.4565e+00,  2.9241e-01,  8.3425e-02,\n",
      "          1.5392e-01, -2.4149e-01, -2.4097e+00, -1.6403e+00, -1.6807e+00,\n",
      "          1.9993e-01,  2.0329e+00, -1.9591e-01, -2.1951e+00, -1.6021e+00,\n",
      "         -3.4868e+00, -2.3214e+00, -3.9750e+00, -3.0932e+00,  4.4702e-01,\n",
      "         -8.7729e-01, -9.9752e-01,  2.0730e+00,  5.5583e-01,  3.9740e+00,\n",
      "          1.2317e+00,  2.6527e+00,  5.9500e+00,  2.3947e+00,  2.3359e+00,\n",
      "          9.3224e+00,  9.6100e+00, -8.5172e-01,  8.7300e-01, -1.1893e-01,\n",
      "          9.7391e-01, -5.5653e-02,  7.4912e-01, -1.5224e+00, -4.0353e+00,\n",
      "          6.0530e-01,  1.5529e+00,  2.2664e+00,  3.7079e+00,  3.7046e+00,\n",
      "         -5.2124e-01,  4.7517e+00, -1.2214e+00,  5.3971e+00,  1.6301e-01,\n",
      "          7.0507e-01, -2.9780e+00,  2.2165e+00,  1.3825e+00,  4.6234e+00,\n",
      "          1.3025e+00, -1.4432e+00, -7.8190e-01,  1.0195e+00, -2.7060e+00,\n",
      "          2.4028e+00,  4.2326e-01,  3.1501e+00,  4.5793e-01, -2.3664e+00,\n",
      "          2.2419e+00,  1.2097e+00,  3.0494e+00,  1.7888e+00,  1.7953e+00,\n",
      "          4.1721e+00,  3.3129e-01, -1.3523e+00,  2.1788e+00, -9.1289e-01,\n",
      "         -2.2907e+00, -6.4950e-02,  1.3153e-01, -2.9666e+00, -1.4349e+00,\n",
      "         -2.4257e+00, -2.8500e+00,  7.5226e-01, -1.6598e+00, -6.6344e-01,\n",
      "          2.9750e+00,  4.7924e+00, -1.3225e+00, -3.7238e+00,  1.6659e-01,\n",
      "         -3.5248e+00, -2.1615e+00, -1.6837e+00, -4.0870e+00,  1.0611e+00,\n",
      "          6.5645e+00,  1.0458e+00,  1.9412e+00,  4.5165e+00,  3.7797e-01,\n",
      "          6.1767e+00,  6.4753e+00,  7.0089e+00,  7.8588e+00,  8.8056e+00,\n",
      "          6.5903e+00,  9.6558e+00,  1.1163e+01,  1.1573e+01,  1.0825e+01,\n",
      "          9.3140e+00, -3.6813e-01, -6.2379e-01, -3.2562e+00, -2.0388e+00,\n",
      "         -1.3426e+00, -3.3674e+00,  7.7738e-01, -1.5289e+00,  1.8753e+00,\n",
      "         -6.1375e-01,  1.3647e+00,  8.9533e-01,  1.4122e+00,  2.1335e+00,\n",
      "         -1.5161e-01,  3.0263e+00,  6.3460e+00,  1.5227e+00,  3.5342e+00,\n",
      "         -1.8166e-01, -1.1565e+00,  8.7804e-01, -5.0387e-02, -8.3769e-02,\n",
      "          1.5477e+00,  2.7638e-01, -7.7953e-01,  6.5298e-02, -8.1706e-01,\n",
      "          4.1402e+00,  5.9148e+00, -5.3153e+00, -4.0271e+00, -1.6005e+00,\n",
      "          1.3898e-01, -2.3051e+00, -4.7040e+00, -4.5618e+00,  4.4327e-01,\n",
      "          2.0189e+00, -3.3815e+00, -1.6733e+00, -2.3312e+00, -2.2452e+00,\n",
      "         -3.8737e+00, -2.1639e+00, -1.4994e+00, -2.3648e+00, -4.1651e+00,\n",
      "         -2.3616e+00, -2.3344e+00, -1.8694e+00, -9.9751e-01, -3.9765e-01,\n",
      "          5.8782e-01, -7.3293e-02,  1.3675e+00,  3.8602e-01, -1.1155e+00,\n",
      "         -2.9607e+00, -2.9595e+00, -1.9611e+00, -3.1837e+00, -2.5719e+00,\n",
      "         -6.1317e-01,  1.7471e+00, -3.3192e+00,  1.2174e+00, -2.3130e+00,\n",
      "          8.3851e-01, -1.6469e+00,  2.2880e+00,  4.0464e+00, -1.0386e+00,\n",
      "         -2.1809e+00, -1.8106e+00, -1.3866e+00, -2.2655e+00, -1.6858e+00,\n",
      "         -8.0196e-01, -7.4322e-01,  2.5755e+00,  1.0224e+00, -1.0273e+00,\n",
      "         -3.3102e+00, -2.0923e+00, -1.2867e+00, -2.3227e+00,  8.6940e-01,\n",
      "         -1.7625e+00, -3.4219e+00,  3.7056e+00,  4.8319e+00,  3.2920e-01,\n",
      "         -3.9196e+00,  8.6400e-01, -1.8349e+00, -2.8385e+00, -3.6774e+00,\n",
      "         -2.7030e+00,  2.7876e+00, -3.1139e+00,  8.3406e-01,  8.5443e-01,\n",
      "          1.2921e+00, -1.6243e+00,  1.7228e-01,  2.9283e+00, -9.0552e-01,\n",
      "         -5.6548e-01, -3.3702e+00, -1.6162e+00, -3.4766e+00,  2.3504e+00,\n",
      "         -1.1029e+00,  1.2052e+00, -2.6054e+00, -9.3233e-01, -7.3344e-01,\n",
      "          4.3411e-01, -3.5268e+00, -1.7758e+00, -1.0997e+00, -1.5789e+00,\n",
      "         -2.5052e+00,  8.4776e-02, -6.2689e-01,  2.4895e-01, -2.1322e+00,\n",
      "         -1.8740e+00, -1.7042e+00, -1.2701e+00,  8.1920e-01,  3.4303e+00,\n",
      "         -1.9576e+00, -1.5686e+00, -6.5902e-01, -1.6087e+00,  1.1780e+00,\n",
      "         -4.9834e+00, -2.8754e+00,  2.1503e-01, -5.0936e+00, -3.3075e+00,\n",
      "          4.3093e+00, -1.3734e+00, -4.2086e+00, -3.0679e+00, -7.0461e-02,\n",
      "          4.8743e-01,  5.3375e-01,  1.2930e+00, -2.8760e+00, -2.3643e+00,\n",
      "         -2.7472e+00, -2.8106e+00,  9.0607e-02, -1.5708e-01, -3.4770e-01,\n",
      "          1.5769e+00, -7.4785e-01,  1.3398e-01, -4.7751e-01,  3.8846e-01,\n",
      "         -3.0495e+00, -2.8901e-02, -2.4566e+00,  2.5797e+00, -1.1721e+00,\n",
      "          3.3436e+00, -8.0359e-01, -2.5125e+00,  4.6791e-01, -2.2291e+00,\n",
      "         -9.9494e-01, -1.8792e+00,  2.0948e+00, -1.5295e+00, -3.1878e+00,\n",
      "         -1.6802e-01, -9.5440e-01, -7.2281e-01, -5.1544e-01, -2.4697e+00,\n",
      "         -1.8590e+00, -1.0283e+00, -1.5167e+00,  4.7460e-01,  2.1943e+00,\n",
      "         -5.1257e-01, -8.4377e-01,  8.0657e-01, -2.2701e+00, -1.0825e-02,\n",
      "         -4.3232e+00, -8.5739e-01, -1.2480e+00, -5.9978e-01, -2.8915e+00,\n",
      "         -2.9526e-01,  2.0736e-02,  1.0912e+00, -1.8775e+00,  1.9122e+00,\n",
      "         -2.0082e+00, -2.1688e+00,  7.6704e-01, -3.2469e+00, -1.7964e+00,\n",
      "          5.1885e-01,  6.9733e-01, -1.4045e+00,  2.2901e+00, -3.9876e+00,\n",
      "         -7.5385e-01,  2.4692e+00,  1.7693e-01, -3.7898e+00, -5.5168e-01,\n",
      "         -8.1473e-01, -5.8565e+00,  3.3327e-01, -4.2693e-02, -3.5579e-01,\n",
      "         -2.3545e+00, -8.3387e-01, -1.1527e+00,  3.5621e-01, -2.2066e+00,\n",
      "         -4.6709e-01,  1.9348e+00,  1.2764e+00, -2.9529e+00,  1.5022e+00,\n",
      "         -2.4000e+00,  3.6992e-01, -2.8471e+00, -8.4632e-01,  9.5457e-01,\n",
      "          7.2152e-01,  2.9865e+00, -2.8548e+00, -2.3804e+00,  1.7425e+00,\n",
      "          5.4257e+00, -9.9830e-02, -1.6819e+00,  1.4392e+00, -1.0291e+00,\n",
      "          1.2748e+00, -1.6900e+00, -2.5162e+00, -1.9421e+00,  3.5670e+00,\n",
      "          7.2809e-01, -3.0663e+00, -4.7515e-01,  8.7708e-01, -3.8728e+00,\n",
      "         -4.4705e+00,  4.0108e+00, -1.7506e+00,  1.8218e+00,  1.4936e+00,\n",
      "         -4.6251e-01, -1.8759e+00, -5.2679e-01, -4.6602e-01, -1.7030e+00,\n",
      "         -2.4959e+00, -5.0336e+00, -4.6958e+00, -3.6281e+00, -1.6861e+00,\n",
      "         -6.5058e+00, -1.8398e+00, -1.9694e+00, -1.4371e+00,  6.4653e-01,\n",
      "         -2.2541e+00,  1.6873e+00,  4.9211e+00, -1.2149e+00,  2.8407e-01,\n",
      "         -2.6553e+00, -9.4299e-01, -4.3583e+00,  4.3756e-01,  7.6645e-01,\n",
      "         -5.4842e-01, -7.0712e-01,  7.4258e-02, -4.5757e+00,  4.7811e+00,\n",
      "          1.1058e-01, -2.4615e+00,  1.9818e+00,  1.1674e+00, -4.8687e-01,\n",
      "         -2.6822e+00, -1.4171e+00, -9.2636e-01, -1.8248e+00, -3.5146e-01,\n",
      "          9.0336e-01, -3.6560e+00, -1.6890e+00,  2.5789e-01, -1.8425e+00,\n",
      "          5.9827e-01,  2.4990e+00, -2.9170e+00, -1.6060e+00, -3.9938e+00,\n",
      "          7.4329e-01,  2.6772e+00, -5.9064e-01, -3.6477e+00, -4.8174e-01,\n",
      "         -5.0349e+00,  3.9314e+00,  5.7841e+00, -1.5403e+00, -1.0707e+00,\n",
      "         -2.7330e+00, -2.0617e+00,  2.0210e+00, -2.4855e+00, -3.1810e+00,\n",
      "         -3.0092e+00, -3.6336e+00, -3.1026e+00, -9.7668e-01, -1.4896e+00,\n",
      "          4.9990e+00, -3.8522e+00, -8.1021e-01, -1.6132e-02, -2.2428e+00,\n",
      "          1.4356e+00, -6.7525e-01, -3.7957e+00, -1.2148e+00, -3.6483e+00,\n",
      "          2.9482e+00,  1.1457e+00,  2.9625e-01,  3.0268e+00,  6.7173e-01,\n",
      "          4.6504e-01, -1.6117e+00,  1.7089e+00,  4.2773e+00, -3.1544e+00,\n",
      "         -2.4957e+00, -2.0233e-01, -1.9252e+00, -2.7250e+00, -3.0228e+00,\n",
      "         -1.0803e+00, -4.1096e-01, -1.8693e+00,  1.8814e+00, -3.7869e+00,\n",
      "         -3.5354e+00, -6.1103e-01, -1.3049e+00,  5.8307e-01,  8.8265e-01,\n",
      "          1.2667e+00, -4.9227e+00, -2.3672e+00,  2.6604e+00, -3.1379e+00,\n",
      "          5.6284e+00,  1.4735e+00, -2.2287e+00,  4.7703e+00, -3.9022e+00,\n",
      "         -8.7755e-01, -4.9505e+00, -1.2368e+00, -4.9105e-01, -1.2139e+00,\n",
      "         -2.3012e+00, -2.0571e+00, -2.1190e+00, -1.0773e-01,  5.8067e-01,\n",
      "         -3.1130e+00, -1.0797e+00, -6.4402e-01,  1.2613e+00,  7.9687e-02,\n",
      "          5.5447e-01, -1.0365e+00, -3.2141e+00, -2.2312e+00,  2.8114e-01,\n",
      "          2.1392e+00,  2.8573e-01, -7.7782e-01,  1.1207e-01, -1.5456e+00,\n",
      "         -3.4829e+00, -1.7400e+00, -2.2205e+00,  6.3056e-02,  1.1200e+00,\n",
      "          1.7131e+00, -2.2536e+00, -1.4954e+00, -7.3331e-01, -1.8815e+00,\n",
      "         -1.0014e+00, -9.8771e-01,  3.5343e+00, -2.0358e+00, -2.8447e+00,\n",
      "         -1.4047e+00, -1.9037e+00, -1.3230e+00, -1.4480e+00, -1.7243e+00,\n",
      "         -2.9147e+00, -9.3756e-01, -1.5747e+00,  9.7809e-01, -4.4905e-02,\n",
      "         -2.3679e+00, -3.1289e-01,  3.1690e+00, -6.2427e+00, -2.2665e+00,\n",
      "          1.1287e-01,  1.1719e+00,  2.4326e+00, -4.5917e-01, -1.6853e+00,\n",
      "         -1.3178e+00, -7.5244e-01,  2.5256e-01, -4.0626e+00, -3.8827e-01,\n",
      "         -5.9903e+00, -2.4716e+00, -1.0734e+00, -4.1693e+00, -8.7314e-01,\n",
      "          4.3461e-01, -4.1390e+00, -4.3036e-01, -1.6888e+00, -1.7482e-01,\n",
      "         -1.7989e+00, -1.9875e+00, -3.4327e+00,  1.9120e+00, -4.9103e+00,\n",
      "          1.1749e+00, -9.3998e-01, -4.4039e+00,  3.2928e-01, -1.1156e+00,\n",
      "          7.9037e-01,  7.8069e-01, -2.3101e+00, -3.7410e+00, -1.1472e+00,\n",
      "          5.5958e+00, -2.8460e+00,  9.0763e-01,  8.3749e-01,  1.4918e+00,\n",
      "          1.1863e+00, -4.6805e-01, -1.3222e+00, -2.0373e+00, -1.2018e+00,\n",
      "          3.6901e+00, -1.0201e+00, -3.0434e-01, -4.4919e-02,  2.8158e+00,\n",
      "          1.3689e+00, -9.9845e-01, -1.4104e+00,  1.2551e+00,  1.8747e+00,\n",
      "         -1.0760e+00,  1.7389e+00,  2.7111e+00, -8.6478e-01,  4.3668e-01,\n",
      "         -9.2986e-01,  1.1119e-01, -1.0649e+00,  3.0038e+00, -3.4844e+00,\n",
      "         -2.6149e+00,  1.5954e+00, -1.2904e+00, -7.5929e-01, -2.9224e+00,\n",
      "         -4.1845e+00,  6.1166e-02,  2.1616e+00, -4.5480e-01, -3.6495e-01,\n",
      "         -3.8432e+00,  3.4105e+00, -1.2743e+00,  2.3852e-01, -1.6424e+00,\n",
      "          1.0154e-01, -2.7386e+00,  3.9093e+00,  3.2063e+00, -1.3133e+00,\n",
      "         -1.0745e+00, -3.7925e-01, -5.4449e-01, -1.2092e+00,  3.6333e-01,\n",
      "          1.6703e+00, -7.2864e-01, -3.2743e+00, -2.6527e-01,  8.2417e-02,\n",
      "          7.4703e-01, -4.4167e+00, -2.7351e+00,  2.1420e+00, -4.6086e+00,\n",
      "          1.2311e+00, -2.9651e+00, -2.2884e-01, -2.0036e+00, -2.3309e+00,\n",
      "          1.7852e-01,  8.3700e-01, -9.7172e-01, -6.9697e-01,  1.8436e+00,\n",
      "          1.7505e+00, -2.3597e+00, -2.4140e+00, -3.0808e+00,  2.9440e-01,\n",
      "         -1.9572e+00, -4.0550e+00, -2.0766e-01, -1.9467e+00, -3.5259e+00,\n",
      "          5.8635e-01, -1.3734e-01,  3.7188e+00,  7.8753e-01, -3.7276e+00,\n",
      "          2.2438e+00, -8.1559e-01, -1.9496e+00, -3.4528e+00,  1.6964e+00,\n",
      "         -2.8375e+00,  1.5300e+00, -2.7356e+00, -1.7412e+00, -1.3071e+00,\n",
      "         -2.4491e+00, -4.2350e+00, -3.3250e+00, -3.1757e+00,  1.6958e-01,\n",
      "         -2.4717e+00, -1.7724e+00, -3.5049e+00, -3.2283e+00, -4.4679e+00,\n",
      "         -1.3443e+00, -7.4340e-01, -1.7299e+00, -2.5239e+00, -3.4458e+00,\n",
      "         -1.4293e+00, -1.6978e+00, -1.9780e+00, -1.8036e+00,  5.2952e-01,\n",
      "         -1.3025e+00,  1.5164e+00,  3.8988e+00, -4.0908e-01, -4.3107e+00,\n",
      "         -1.8744e+00, -3.0191e+00, -1.7837e+00, -8.8887e-01, -9.3475e-01,\n",
      "         -2.7460e+00,  1.2273e-01, -1.6598e+00,  2.0667e+00, -1.6149e+00,\n",
      "         -2.4546e+00, -2.1487e-02, -1.9901e+00, -4.2173e+00, -7.8559e-01,\n",
      "         -2.1928e+00,  9.7907e-01, -1.7279e+00, -1.1619e-02, -2.2820e+00,\n",
      "          2.0677e+00,  2.4554e-01,  4.7449e+00, -3.1820e+00,  1.8564e+00,\n",
      "          3.1866e+00,  2.4513e+00,  3.5351e+00,  4.0260e+00,  2.5520e+00,\n",
      "          3.8970e+00,  9.3137e-01, -5.0111e-02, -2.7873e+00,  2.0224e+00,\n",
      "         -1.2788e+00,  6.1936e-02,  1.1857e-01, -1.1351e+00,  4.6472e+00,\n",
      "         -1.7425e+00,  1.4774e+00,  7.7104e-01,  5.3952e-01, -1.4696e+00,\n",
      "          1.0192e+00,  1.8919e+00,  1.3806e+00,  3.5333e-01,  8.2069e-01]]) tensor([0])\n",
      "2024-12-17 07:59:23,934 - Eval - INFO - Avg accuracy Top 1: 0.000000 Avg accuracy Top 5: 0.000000 on validation Dataset\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = ImageNetDataPipeline.evaluate(model, use_cuda)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Create a quantization simulation model and determine quantized accuracy\n",
    "\n",
    "### Fold Batch Norm layers\n",
    "\n",
    "Before calculating the simulated quantized accuracy using QuantizationSimModel, fold the BatchNorm (BN) layers into adjacent Convolutional layers. The BN layers that cannot be folded are left as they are.\n",
    "\n",
    "BN folding improves inference performance on quantized runtimes but can degrade accuracy on these platforms. This step simulates this on-target drop in accuracy. \n",
    "\n",
    "**3.1 Use the following code to call AIMET to fold the BN layers in-place on the given model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-12-20 10:45:37,981] [WARNING] [real_accelerator.py:162:get_accelerator] Setting accelerator to CPU. If you have GPU or other accelerator, we were unable to detect it.\n",
      "[2024-12-20 10:45:37,982] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cpu (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "df: /root/.triton/autotune: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "from aimet_torch.batch_norm_fold import fold_all_batch_norms\n",
    "\n",
    "_ = fold_all_batch_norms(model, input_shapes=(1, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Quantization Sim Model\n",
    "\n",
    "**3.2 Use AIMET to create a QuantizationSimModel.**\n",
    "\n",
    " In this step, AIMET inserts fake quantization ops in the model graph and configures them.\n",
    "\n",
    "Key parameters:\n",
    "\n",
    "- Setting **default_output_bw** to 8 performs all activation quantizations in the model using integer 8-bit precision\n",
    "- Setting **default_param_bw** to 8 performs all parameter quantizations in the model using integer 8-bit precision\n",
    "- **num_batches** is the number of batches to use to compute encodings. Only five batches are used here for the sake of speed\n",
    "\n",
    "See [QuantizationSimModel in the AIMET API documentation](https://quic.github.io/aimet-pages/AimetDocs/api_docs/torch_quantsim.html#aimet_torch.quantsim.QuantizationSimModel.compute_encodings) for a full explanation of the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-20 10:46:01,360 - Quant - INFO - Unsupported op type Squeeze\n",
      "2024-12-20 10:46:01,361 - Quant - INFO - Unsupported op type Mean\n",
      "2024-12-20 10:46:01,362 - Quant - INFO - Selecting DefaultOpInstanceConfigGenerator to compute the specialized config. hw_version:default\n"
     ]
    }
   ],
   "source": [
    "from aimet_common.defs import QuantScheme\n",
    "from aimet_torch.v1.quantsim import QuantizationSimModel\n",
    "\n",
    "dummy_input = torch.rand(1, 3, 224, 224)    # Shape for each ImageNet sample is (3 channels) x (224 height) x (224 width)\n",
    "if use_cuda:\n",
    "    dummy_input = dummy_input.cuda()\n",
    "\n",
    "sim = QuantizationSimModel(model=model,\n",
    "                           quant_scheme=QuantScheme.post_training_tf_enhanced,\n",
    "                           dummy_input=dummy_input,\n",
    "                           default_output_bw=8,\n",
    "                           default_param_bw=8,\n",
    "                           config_file=\"/home/shayan/Desktop/aimet/my_config.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**3.3 Print the model to verify the modifications AIMET has made. **\n",
    "\n",
    "Note that AIMET has added quantization wrapper layers. \n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Note\n",
    "\n",
    "Use sim.model to access the modified PyTorch model. By default, AIMET creates a copy of the original model prior to modifying it. There is a parameter to override this behavior.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphModule(\n",
      "  (conv1): StaticGridQuantWrapper(\n",
      "    (_module_to_wrap): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "  )\n",
      "  (bn1): Identity()\n",
      "  (relu): StaticGridQuantWrapper(\n",
      "    (_module_to_wrap): ReLU(inplace=True)\n",
      "  )\n",
      "  (maxpool): StaticGridQuantWrapper(\n",
      "    (_module_to_wrap): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer1): Module(\n",
      "    (0): Module(\n",
      "      (conv1): StaticGridQuantWrapper(\n",
      "        (_module_to_wrap): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu): StaticGridQuantWrapper(\n",
      "        (_module_to_wrap): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv2): StaticGridQuantWrapper(\n",
      "        (_module_to_wrap): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (module_add): StaticGridQuantWrapper(\n",
      "        (_module_to_wrap): Add()\n",
      "      )\n",
      "      (module_relu_1): StaticGridQuantWrapper(\n",
      "        (_module_to_wrap): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Module(\n",
      "      (conv1): StaticGridQuantWrapper(\n",
      "        (_module_to_wrap): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu): StaticGridQuantWrapper(\n",
      "        (_module_to_wrap): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv2): StaticGridQuantWrapper(\n",
      "        (_module_to_wrap): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (module_add_1): StaticGridQuantWrapper(\n",
      "        (_module_to_wrap): Add()\n",
      "      )\n",
      "      (module_relu_1): StaticGridQuantWrapper(\n",
      "        (_module_to_wrap): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Module(\n",
      "    (0): Module(\n",
      "      (conv1): StaticGridQuantWrapper(\n",
      "        (_module_to_wrap): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu): StaticGridQuantWrapper(\n",
      "        (_module_to_wrap): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv2): StaticGridQuantWrapper(\n",
      "        (_module_to_wrap): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (downsample): Module(\n",
      "        (0): StaticGridQuantWrapper(\n",
      "          (_module_to_wrap): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
      "        )\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (module_add_2): StaticGridQuantWrapper(\n",
      "        (_module_to_wrap): Add()\n",
      "      )\n",
      "      (module_relu_1): StaticGridQuantWrapper(\n",
      "        (_module_to_wrap): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Module(\n",
      "      (conv1): StaticGridQuantWrapper(\n",
      "        (_module_to_wrap): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu): StaticGridQuantWrapper(\n",
      "        (_module_to_wrap): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv2): StaticGridQuantWrapper(\n",
      "        (_module_to_wrap): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (module_add_3): StaticGridQuantWrapper(\n",
      "        (_module_to_wrap): Add()\n",
      "      )\n",
      "      (module_relu_1): StaticGridQuantWrapper(\n",
      "        (_module_to_wrap): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Module(\n",
      "    (0): Module(\n",
      "      (conv1): StaticGridQuantWrapper(\n",
      "        (_module_to_wrap): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu): StaticGridQuantWrapper(\n",
      "        (_module_to_wrap): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv2): StaticGridQuantWrapper(\n",
      "        (_module_to_wrap): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (downsample): Module(\n",
      "        (0): StaticGridQuantWrapper(\n",
      "          (_module_to_wrap): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
      "        )\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (module_add_4): StaticGridQuantWrapper(\n",
      "        (_module_to_wrap): Add()\n",
      "      )\n",
      "      (module_relu_1): StaticGridQuantWrapper(\n",
      "        (_module_to_wrap): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Module(\n",
      "      (conv1): StaticGridQuantWrapper(\n",
      "        (_module_to_wrap): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu): StaticGridQuantWrapper(\n",
      "        (_module_to_wrap): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv2): StaticGridQuantWrapper(\n",
      "        (_module_to_wrap): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (module_add_5): StaticGridQuantWrapper(\n",
      "        (_module_to_wrap): Add()\n",
      "      )\n",
      "      (module_relu_1): StaticGridQuantWrapper(\n",
      "        (_module_to_wrap): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Module(\n",
      "    (0): Module(\n",
      "      (conv1): StaticGridQuantWrapper(\n",
      "        (_module_to_wrap): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu): StaticGridQuantWrapper(\n",
      "        (_module_to_wrap): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv2): StaticGridQuantWrapper(\n",
      "        (_module_to_wrap): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (downsample): Module(\n",
      "        (0): StaticGridQuantWrapper(\n",
      "          (_module_to_wrap): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
      "        )\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (module_add_6): StaticGridQuantWrapper(\n",
      "        (_module_to_wrap): Add()\n",
      "      )\n",
      "      (module_relu_1): StaticGridQuantWrapper(\n",
      "        (_module_to_wrap): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Module(\n",
      "      (conv1): StaticGridQuantWrapper(\n",
      "        (_module_to_wrap): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu): StaticGridQuantWrapper(\n",
      "        (_module_to_wrap): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv2): StaticGridQuantWrapper(\n",
      "        (_module_to_wrap): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (module_add_7): StaticGridQuantWrapper(\n",
      "        (_module_to_wrap): Add()\n",
      "      )\n",
      "      (module_relu_1): StaticGridQuantWrapper(\n",
      "        (_module_to_wrap): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): StaticGridQuantWrapper(\n",
      "    (_module_to_wrap): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  )\n",
      "  (fc): StaticGridQuantWrapper(\n",
      "    (_module_to_wrap): Linear(in_features=512, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x : torch.Tensor) -> torch.Tensor:\n",
      "    conv1 = self.conv1(x);  x = None\n",
      "    bn1 = self.bn1(conv1);  conv1 = None\n",
      "    relu = self.relu(bn1);  bn1 = None\n",
      "    maxpool = self.maxpool(relu);  relu = None\n",
      "    layer1_0_conv1 = getattr(self.layer1, \"0\").conv1(maxpool)\n",
      "    layer1_0_bn1 = getattr(self.layer1, \"0\").bn1(layer1_0_conv1);  layer1_0_conv1 = None\n",
      "    layer1_0_relu = getattr(self.layer1, \"0\").relu(layer1_0_bn1);  layer1_0_bn1 = None\n",
      "    layer1_0_conv2 = getattr(self.layer1, \"0\").conv2(layer1_0_relu);  layer1_0_relu = None\n",
      "    layer1_0_bn2 = getattr(self.layer1, \"0\").bn2(layer1_0_conv2);  layer1_0_conv2 = None\n",
      "    layer1_0_module_add = getattr(self.layer1, \"0\").module_add(layer1_0_bn2, maxpool);  layer1_0_bn2 = maxpool = None\n",
      "    layer1_0_module_relu_1 = getattr(self.layer1, \"0\").module_relu_1(layer1_0_module_add);  layer1_0_module_add = None\n",
      "    layer1_1_conv1 = getattr(self.layer1, \"1\").conv1(layer1_0_module_relu_1)\n",
      "    layer1_1_bn1 = getattr(self.layer1, \"1\").bn1(layer1_1_conv1);  layer1_1_conv1 = None\n",
      "    layer1_1_relu = getattr(self.layer1, \"1\").relu(layer1_1_bn1);  layer1_1_bn1 = None\n",
      "    layer1_1_conv2 = getattr(self.layer1, \"1\").conv2(layer1_1_relu);  layer1_1_relu = None\n",
      "    layer1_1_bn2 = getattr(self.layer1, \"1\").bn2(layer1_1_conv2);  layer1_1_conv2 = None\n",
      "    layer1_1_module_add_1 = getattr(self.layer1, \"1\").module_add_1(layer1_1_bn2, layer1_0_module_relu_1);  layer1_1_bn2 = layer1_0_module_relu_1 = None\n",
      "    layer1_1_module_relu_1 = getattr(self.layer1, \"1\").module_relu_1(layer1_1_module_add_1);  layer1_1_module_add_1 = None\n",
      "    layer2_0_conv1 = getattr(self.layer2, \"0\").conv1(layer1_1_module_relu_1)\n",
      "    layer2_0_bn1 = getattr(self.layer2, \"0\").bn1(layer2_0_conv1);  layer2_0_conv1 = None\n",
      "    layer2_0_relu = getattr(self.layer2, \"0\").relu(layer2_0_bn1);  layer2_0_bn1 = None\n",
      "    layer2_0_conv2 = getattr(self.layer2, \"0\").conv2(layer2_0_relu);  layer2_0_relu = None\n",
      "    layer2_0_bn2 = getattr(self.layer2, \"0\").bn2(layer2_0_conv2);  layer2_0_conv2 = None\n",
      "    layer2_0_downsample_0 = getattr(getattr(self.layer2, \"0\").downsample, \"0\")(layer1_1_module_relu_1);  layer1_1_module_relu_1 = None\n",
      "    layer2_0_downsample_1 = getattr(getattr(self.layer2, \"0\").downsample, \"1\")(layer2_0_downsample_0);  layer2_0_downsample_0 = None\n",
      "    layer2_0_module_add_2 = getattr(self.layer2, \"0\").module_add_2(layer2_0_bn2, layer2_0_downsample_1);  layer2_0_bn2 = layer2_0_downsample_1 = None\n",
      "    layer2_0_module_relu_1 = getattr(self.layer2, \"0\").module_relu_1(layer2_0_module_add_2);  layer2_0_module_add_2 = None\n",
      "    layer2_1_conv1 = getattr(self.layer2, \"1\").conv1(layer2_0_module_relu_1)\n",
      "    layer2_1_bn1 = getattr(self.layer2, \"1\").bn1(layer2_1_conv1);  layer2_1_conv1 = None\n",
      "    layer2_1_relu = getattr(self.layer2, \"1\").relu(layer2_1_bn1);  layer2_1_bn1 = None\n",
      "    layer2_1_conv2 = getattr(self.layer2, \"1\").conv2(layer2_1_relu);  layer2_1_relu = None\n",
      "    layer2_1_bn2 = getattr(self.layer2, \"1\").bn2(layer2_1_conv2);  layer2_1_conv2 = None\n",
      "    layer2_1_module_add_3 = getattr(self.layer2, \"1\").module_add_3(layer2_1_bn2, layer2_0_module_relu_1);  layer2_1_bn2 = layer2_0_module_relu_1 = None\n",
      "    layer2_1_module_relu_1 = getattr(self.layer2, \"1\").module_relu_1(layer2_1_module_add_3);  layer2_1_module_add_3 = None\n",
      "    layer3_0_conv1 = getattr(self.layer3, \"0\").conv1(layer2_1_module_relu_1)\n",
      "    layer3_0_bn1 = getattr(self.layer3, \"0\").bn1(layer3_0_conv1);  layer3_0_conv1 = None\n",
      "    layer3_0_relu = getattr(self.layer3, \"0\").relu(layer3_0_bn1);  layer3_0_bn1 = None\n",
      "    layer3_0_conv2 = getattr(self.layer3, \"0\").conv2(layer3_0_relu);  layer3_0_relu = None\n",
      "    layer3_0_bn2 = getattr(self.layer3, \"0\").bn2(layer3_0_conv2);  layer3_0_conv2 = None\n",
      "    layer3_0_downsample_0 = getattr(getattr(self.layer3, \"0\").downsample, \"0\")(layer2_1_module_relu_1);  layer2_1_module_relu_1 = None\n",
      "    layer3_0_downsample_1 = getattr(getattr(self.layer3, \"0\").downsample, \"1\")(layer3_0_downsample_0);  layer3_0_downsample_0 = None\n",
      "    layer3_0_module_add_4 = getattr(self.layer3, \"0\").module_add_4(layer3_0_bn2, layer3_0_downsample_1);  layer3_0_bn2 = layer3_0_downsample_1 = None\n",
      "    layer3_0_module_relu_1 = getattr(self.layer3, \"0\").module_relu_1(layer3_0_module_add_4);  layer3_0_module_add_4 = None\n",
      "    layer3_1_conv1 = getattr(self.layer3, \"1\").conv1(layer3_0_module_relu_1)\n",
      "    layer3_1_bn1 = getattr(self.layer3, \"1\").bn1(layer3_1_conv1);  layer3_1_conv1 = None\n",
      "    layer3_1_relu = getattr(self.layer3, \"1\").relu(layer3_1_bn1);  layer3_1_bn1 = None\n",
      "    layer3_1_conv2 = getattr(self.layer3, \"1\").conv2(layer3_1_relu);  layer3_1_relu = None\n",
      "    layer3_1_bn2 = getattr(self.layer3, \"1\").bn2(layer3_1_conv2);  layer3_1_conv2 = None\n",
      "    layer3_1_module_add_5 = getattr(self.layer3, \"1\").module_add_5(layer3_1_bn2, layer3_0_module_relu_1);  layer3_1_bn2 = layer3_0_module_relu_1 = None\n",
      "    layer3_1_module_relu_1 = getattr(self.layer3, \"1\").module_relu_1(layer3_1_module_add_5);  layer3_1_module_add_5 = None\n",
      "    layer4_0_conv1 = getattr(self.layer4, \"0\").conv1(layer3_1_module_relu_1)\n",
      "    layer4_0_bn1 = getattr(self.layer4, \"0\").bn1(layer4_0_conv1);  layer4_0_conv1 = None\n",
      "    layer4_0_relu = getattr(self.layer4, \"0\").relu(layer4_0_bn1);  layer4_0_bn1 = None\n",
      "    layer4_0_conv2 = getattr(self.layer4, \"0\").conv2(layer4_0_relu);  layer4_0_relu = None\n",
      "    layer4_0_bn2 = getattr(self.layer4, \"0\").bn2(layer4_0_conv2);  layer4_0_conv2 = None\n",
      "    layer4_0_downsample_0 = getattr(getattr(self.layer4, \"0\").downsample, \"0\")(layer3_1_module_relu_1);  layer3_1_module_relu_1 = None\n",
      "    layer4_0_downsample_1 = getattr(getattr(self.layer4, \"0\").downsample, \"1\")(layer4_0_downsample_0);  layer4_0_downsample_0 = None\n",
      "    layer4_0_module_add_6 = getattr(self.layer4, \"0\").module_add_6(layer4_0_bn2, layer4_0_downsample_1);  layer4_0_bn2 = layer4_0_downsample_1 = None\n",
      "    layer4_0_module_relu_1 = getattr(self.layer4, \"0\").module_relu_1(layer4_0_module_add_6);  layer4_0_module_add_6 = None\n",
      "    layer4_1_conv1 = getattr(self.layer4, \"1\").conv1(layer4_0_module_relu_1)\n",
      "    layer4_1_bn1 = getattr(self.layer4, \"1\").bn1(layer4_1_conv1);  layer4_1_conv1 = None\n",
      "    layer4_1_relu = getattr(self.layer4, \"1\").relu(layer4_1_bn1);  layer4_1_bn1 = None\n",
      "    layer4_1_conv2 = getattr(self.layer4, \"1\").conv2(layer4_1_relu);  layer4_1_relu = None\n",
      "    layer4_1_bn2 = getattr(self.layer4, \"1\").bn2(layer4_1_conv2);  layer4_1_conv2 = None\n",
      "    layer4_1_module_add_7 = getattr(self.layer4, \"1\").module_add_7(layer4_1_bn2, layer4_0_module_relu_1);  layer4_1_bn2 = layer4_0_module_relu_1 = None\n",
      "    layer4_1_module_relu_1 = getattr(self.layer4, \"1\").module_relu_1(layer4_1_module_add_7);  layer4_1_module_add_7 = None\n",
      "    avgpool = self.avgpool(layer4_1_module_relu_1);  layer4_1_module_relu_1 = None\n",
      "    flatten = torch.flatten(avgpool, 1);  avgpool = None\n",
      "    fc = self.fc(flatten);  flatten = None\n",
      "    return fc\n",
      "    \n",
      "# To see more debug info, please use `graph_module.print_readable()`\n"
     ]
    }
   ],
   "source": [
    "print(sim.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Note also that AIMET has configured the added fake quantization nodes, which AIMET refers to as \"quantizers\". \n",
    "\n",
    "**3.4 Print the sim object to see the quantizers.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv1': {'inputs': {'0': {}},\n",
       "  'params': {'weight': {}, 'bias': {}},\n",
       "  'outputs': {'0': {}}},\n",
       " 'relu': {'inputs': {'0': {}}, 'params': {}, 'outputs': {'0': {}}},\n",
       " 'maxpool': {'inputs': {'0': {}}, 'params': {}, 'outputs': {'0': {}}},\n",
       " 'layer1.0.conv1': {'inputs': {'0': {}},\n",
       "  'params': {'weight': {}, 'bias': {}},\n",
       "  'outputs': {'0': {}}},\n",
       " 'layer1.0.relu': {'inputs': {'0': {}}, 'params': {}, 'outputs': {'0': {}}},\n",
       " 'layer1.0.conv2': {'inputs': {'0': {}},\n",
       "  'params': {'weight': {}, 'bias': {}},\n",
       "  'outputs': {'0': {}}},\n",
       " 'layer1.0.module_add': {'inputs': {'0': {}, '1': {}},\n",
       "  'params': {},\n",
       "  'outputs': {'0': {}}},\n",
       " 'layer1.0.module_relu_1': {'inputs': {'0': {}},\n",
       "  'params': {},\n",
       "  'outputs': {'0': {}}},\n",
       " 'layer1.1.conv1': {'inputs': {'0': {}},\n",
       "  'params': {'weight': {}, 'bias': {}},\n",
       "  'outputs': {'0': {}}},\n",
       " 'layer1.1.relu': {'inputs': {'0': {}}, 'params': {}, 'outputs': {'0': {}}},\n",
       " 'layer1.1.conv2': {'inputs': {'0': {}},\n",
       "  'params': {'weight': {}, 'bias': {}},\n",
       "  'outputs': {'0': {}}},\n",
       " 'layer1.1.module_add_1': {'inputs': {'0': {}, '1': {}},\n",
       "  'params': {},\n",
       "  'outputs': {'0': {}}},\n",
       " 'layer1.1.module_relu_1': {'inputs': {'0': {}},\n",
       "  'params': {},\n",
       "  'outputs': {'0': {}}},\n",
       " 'layer2.0.conv1': {'inputs': {'0': {}},\n",
       "  'params': {'weight': {}, 'bias': {}},\n",
       "  'outputs': {'0': {}}},\n",
       " 'layer2.0.relu': {'inputs': {'0': {}}, 'params': {}, 'outputs': {'0': {}}},\n",
       " 'layer2.0.conv2': {'inputs': {'0': {}},\n",
       "  'params': {'weight': {}, 'bias': {}},\n",
       "  'outputs': {'0': {}}},\n",
       " 'layer2.0.downsample.0': {'inputs': {'0': {}},\n",
       "  'params': {'weight': {}, 'bias': {}},\n",
       "  'outputs': {'0': {}}},\n",
       " 'layer2.0.module_add_2': {'inputs': {'0': {}, '1': {}},\n",
       "  'params': {},\n",
       "  'outputs': {'0': {}}},\n",
       " 'layer2.0.module_relu_1': {'inputs': {'0': {}},\n",
       "  'params': {},\n",
       "  'outputs': {'0': {}}},\n",
       " 'layer2.1.conv1': {'inputs': {'0': {}},\n",
       "  'params': {'weight': {}, 'bias': {}},\n",
       "  'outputs': {'0': {}}},\n",
       " 'layer2.1.relu': {'inputs': {'0': {}}, 'params': {}, 'outputs': {'0': {}}},\n",
       " 'layer2.1.conv2': {'inputs': {'0': {}},\n",
       "  'params': {'weight': {}, 'bias': {}},\n",
       "  'outputs': {'0': {}}},\n",
       " 'layer2.1.module_add_3': {'inputs': {'0': {}, '1': {}},\n",
       "  'params': {},\n",
       "  'outputs': {'0': {}}},\n",
       " 'layer2.1.module_relu_1': {'inputs': {'0': {}},\n",
       "  'params': {},\n",
       "  'outputs': {'0': {}}},\n",
       " 'layer3.0.conv1': {'inputs': {'0': {}},\n",
       "  'params': {'weight': {}, 'bias': {}},\n",
       "  'outputs': {'0': {}}},\n",
       " 'layer3.0.relu': {'inputs': {'0': {}}, 'params': {}, 'outputs': {'0': {}}},\n",
       " 'layer3.0.conv2': {'inputs': {'0': {}},\n",
       "  'params': {'weight': {}, 'bias': {}},\n",
       "  'outputs': {'0': {}}},\n",
       " 'layer3.0.downsample.0': {'inputs': {'0': {}},\n",
       "  'params': {'weight': {}, 'bias': {}},\n",
       "  'outputs': {'0': {}}},\n",
       " 'layer3.0.module_add_4': {'inputs': {'0': {}, '1': {}},\n",
       "  'params': {},\n",
       "  'outputs': {'0': {}}},\n",
       " 'layer3.0.module_relu_1': {'inputs': {'0': {}},\n",
       "  'params': {},\n",
       "  'outputs': {'0': {}}},\n",
       " 'layer3.1.conv1': {'inputs': {'0': {}},\n",
       "  'params': {'weight': {}, 'bias': {}},\n",
       "  'outputs': {'0': {}}},\n",
       " 'layer3.1.relu': {'inputs': {'0': {}}, 'params': {}, 'outputs': {'0': {}}},\n",
       " 'layer3.1.conv2': {'inputs': {'0': {}},\n",
       "  'params': {'weight': {}, 'bias': {}},\n",
       "  'outputs': {'0': {}}},\n",
       " 'layer3.1.module_add_5': {'inputs': {'0': {}, '1': {}},\n",
       "  'params': {},\n",
       "  'outputs': {'0': {}}},\n",
       " 'layer3.1.module_relu_1': {'inputs': {'0': {}},\n",
       "  'params': {},\n",
       "  'outputs': {'0': {}}},\n",
       " 'layer4.0.conv1': {'inputs': {'0': {}},\n",
       "  'params': {'weight': {}, 'bias': {}},\n",
       "  'outputs': {'0': {}}},\n",
       " 'layer4.0.relu': {'inputs': {'0': {}}, 'params': {}, 'outputs': {'0': {}}},\n",
       " 'layer4.0.conv2': {'inputs': {'0': {}},\n",
       "  'params': {'weight': {}, 'bias': {}},\n",
       "  'outputs': {'0': {}}},\n",
       " 'layer4.0.downsample.0': {'inputs': {'0': {}},\n",
       "  'params': {'weight': {}, 'bias': {}},\n",
       "  'outputs': {'0': {}}},\n",
       " 'layer4.0.module_add_6': {'inputs': {'0': {}, '1': {}},\n",
       "  'params': {},\n",
       "  'outputs': {'0': {}}},\n",
       " 'layer4.0.module_relu_1': {'inputs': {'0': {}},\n",
       "  'params': {},\n",
       "  'outputs': {'0': {}}},\n",
       " 'layer4.1.conv1': {'inputs': {'0': {}},\n",
       "  'params': {'weight': {}, 'bias': {}},\n",
       "  'outputs': {'0': {}}},\n",
       " 'layer4.1.relu': {'inputs': {'0': {}}, 'params': {}, 'outputs': {'0': {}}},\n",
       " 'layer4.1.conv2': {'inputs': {'0': {}},\n",
       "  'params': {'weight': {}, 'bias': {}},\n",
       "  'outputs': {'0': {}}},\n",
       " 'layer4.1.module_add_7': {'inputs': {'0': {}, '1': {}},\n",
       "  'params': {},\n",
       "  'outputs': {'0': {}}},\n",
       " 'layer4.1.module_relu_1': {'inputs': {'0': {}},\n",
       "  'params': {},\n",
       "  'outputs': {'0': {}}},\n",
       " 'avgpool': {'inputs': {'0': {}}, 'params': {}, 'outputs': {'0': {}}},\n",
       " 'fc': {'inputs': {'0': {}},\n",
       "  'params': {'weight': {}, 'bias': {}},\n",
       "  'outputs': {'0': {}}}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim.__dict__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "AIMET has added quantizer nodes to the model graph, but before the sim model can be used for inference or training, scale and offset quantization parameters must be calculated for each quantizer node by passing unlabeled data samples through the model to collect range statistics. This process is sometimes referred to as calibration. AIMET refers to it as \"computing encodings\".\n",
    "\n",
    "**3.5 Create a routine to pass unlabeled data samples through the model.** \n",
    "\n",
    "The following code is one way to write a routine that passes unlabeled samples through the model to compute encodings. It uses the existing train or validation data loader to extract samples and pass them to the model. Since there is no need to compute loss metrics, it ignores the model output.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-20 10:46:08,713 - Dataloader - INFO - Dataset consists of 3 images in 1 classes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = ImageNetDataPipeline.get_val_dataloader()\n",
    "data_loader.batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pass_calibration_data(sim_model, use_cuda):\n",
    "    data_loader = ImageNetDataPipeline.get_val_dataloader()\n",
    "    batch_size = data_loader.batch_size\n",
    "\n",
    "    if use_cuda:\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "\n",
    "    sim_model.eval()\n",
    "    samples = 1000\n",
    "\n",
    "    batch_cntr = 0\n",
    "    idx = 0\n",
    "    with torch.no_grad():\n",
    "        for path, input_data, target_data in data_loader:\n",
    "            # if \"cf135f199d8c7a9d0dce9aa35acfb4c70c14e0aa\" not in path[0]:\n",
    "            #     continue\n",
    "            # if \"cf\" in path[0]:\n",
    "            print(path)\n",
    "            inputs_batch = input_data.to(device)\n",
    "            sim_model(inputs_batch)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few notes regarding the data samples:\n",
    "\n",
    "- A very small percentage of the data samples are needed. For example, the training dataset for ImageNet has 1M samples; 500 or 1000 suffice to compute encodings.\n",
    "- The samples should be reasonably well distributed. While it's not necessary to cover all classes, avoid extreme scenarios like using only dark or only light samples. That is, using only pictures captured at night, say, could skew the results.\n",
    "\n",
    "---\n",
    "\n",
    "**3.6 Call AIMET to use the routine to pass data through the model and compute the quantization encodings.** \n",
    "\n",
    "Encodings here refer to scale and offset quantization parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-20 10:46:16,564 - Dataloader - INFO - Dataset consists of 3 images in 1 classes\n",
      "('/home/shayan/Desktop/aimet/Examples/torch/quantization/val/9/cf135f199d8c7a9d0dce9aa35acfb4c70c14e0aa.jpeg',)\n"
     ]
    }
   ],
   "source": [
    "sim.compute_encodings(forward_pass_callback=pass_calibration_data,\n",
    "                      forward_pass_callback_args=use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "Quantized Model Report\n",
      "-------------------------\n",
      "----------------------------------------------------------\n",
      "Layer: conv1\n",
      "  Input[0]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-2.231783390045166, max=2.231783390045166, delta=0.017573097559410757, offset=-127.0\n",
      "  -------\n",
      "  Param[weight]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-0.39387544989585876, max=0.39387544989585876, delta=0.0031013814952429823, offset=-127.0\n",
      "  -------\n",
      "  Param[bias]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-0.6932891607284546, max=0.6932891607284546, delta=0.005458969769515391, offset=-127.0\n",
      "  -------\n",
      "  Output[0]: Not quantized\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: relu\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Output[0]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-3.4561045169830322, max=3.4561045169830322, delta=0.027213421393567184, offset=-127.0\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: maxpool\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Output[0]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-3.4561045169830322, max=3.4561045169830322, delta=0.027213421393567184, offset=-127.0\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: layer1.0.conv1\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Param[weight]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-0.3745041489601135, max=0.3745041489601135, delta=0.002948851566615067, offset=-127.0\n",
      "  -------\n",
      "  Param[bias]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-1.1022106409072876, max=1.1022106409072876, delta=0.008678823944151872, offset=-127.0\n",
      "  -------\n",
      "  Output[0]: Not quantized\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: layer1.0.relu\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Output[0]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-1.1845502853393555, max=1.1845502853393555, delta=0.009327167601097287, offset=-127.0\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: layer1.0.conv2\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Param[weight]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-0.7707811594009399, max=0.7707811594009399, delta=0.006069142987408976, offset=-127.0\n",
      "  -------\n",
      "  Param[bias]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-1.7853344678878784, max=1.7853344678878784, delta=0.014057751715652586, offset=-127.0\n",
      "  -------\n",
      "  Output[0]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-2.8630332946777344, max=2.8630332946777344, delta=0.02254356924943098, offset=-127.0\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: layer1.0.module_add\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Input[1]: Not quantized\n",
      "  -------\n",
      "  Output[0]: Not quantized\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: layer1.0.module_relu_1\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Output[0]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-3.4839067459106445, max=3.4839067459106445, delta=0.02743233658197358, offset=-127.0\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: layer1.1.conv1\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Param[weight]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-0.2799574136734009, max=0.2799574136734009, delta=0.0022043890840425266, offset=-127.0\n",
      "  -------\n",
      "  Param[bias]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-1.2079195976257324, max=1.2079195976257324, delta=0.009511177934060885, offset=-127.0\n",
      "  -------\n",
      "  Output[0]: Not quantized\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: layer1.1.relu\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Output[0]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-1.7572615146636963, max=1.7572615146636963, delta=0.013836704839871624, offset=-127.0\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: layer1.1.conv2\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Param[weight]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-1.0473909378051758, max=1.0473909378051758, delta=0.008247172738623432, offset=-127.0\n",
      "  -------\n",
      "  Param[bias]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-1.170573115348816, max=1.170573115348816, delta=0.009217111144478865, offset=-127.0\n",
      "  -------\n",
      "  Output[0]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-3.725557565689087, max=3.725557565689087, delta=0.029335098942433756, offset=-127.0\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: layer1.1.module_add_1\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Input[1]: Not quantized\n",
      "  -------\n",
      "  Output[0]: Not quantized\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: layer1.1.module_relu_1\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Output[0]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-4.982845306396484, max=4.982845306396484, delta=0.039235002412570746, offset=-127.0\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: layer2.0.conv1\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Param[weight]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-0.21269579231739044, max=0.21269579231739044, delta=0.0016747700182471689, offset=-127.0\n",
      "  -------\n",
      "  Param[bias]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-0.7400765419006348, max=0.7400765419006348, delta=0.005827374345674289, offset=-127.0\n",
      "  -------\n",
      "  Output[0]: Not quantized\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: layer2.0.relu\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Output[0]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-1.7159000635147095, max=1.7159000635147095, delta=0.013511024122163066, offset=-127.0\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: layer2.0.conv2\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Param[weight]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-0.7241502404212952, max=0.7241502404212952, delta=0.005701970397018072, offset=-127.0\n",
      "  -------\n",
      "  Param[bias]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-1.446347951889038, max=1.446347951889038, delta=0.011388566550307386, offset=-127.0\n",
      "  -------\n",
      "  Output[0]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-2.7933433055877686, max=2.7933433055877686, delta=0.021994829177856445, offset=-127.0\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: layer2.0.downsample.0\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Param[weight]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-0.6922507882118225, max=0.6922507882118225, delta=0.005450793607967106, offset=-127.0\n",
      "  -------\n",
      "  Param[bias]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-1.1103509664535522, max=1.1103509664535522, delta=0.008742920995697262, offset=-127.0\n",
      "  -------\n",
      "  Output[0]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-1.690948724746704, max=1.690948724746704, delta=0.013314556887769323, offset=-127.0\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: layer2.0.module_add_2\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Input[1]: Not quantized\n",
      "  -------\n",
      "  Output[0]: Not quantized\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: layer2.0.module_relu_1\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Output[0]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-2.891108274459839, max=2.891108274459839, delta=0.022764632082360937, offset=-127.0\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: layer2.1.conv1\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Param[weight]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-0.3110506236553192, max=0.3110506236553192, delta=0.0024492175090970016, offset=-127.0\n",
      "  -------\n",
      "  Param[bias]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-0.8257396221160889, max=0.8257396221160889, delta=0.00650188678831566, offset=-127.0\n",
      "  -------\n",
      "  Output[0]: Not quantized\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: layer2.1.relu\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Output[0]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-1.8285105228424072, max=1.8285105228424072, delta=0.01439772065230242, offset=-127.0\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: layer2.1.conv2\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Param[weight]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-0.8770784139633179, max=0.8770784139633179, delta=0.006906129243805652, offset=-127.0\n",
      "  -------\n",
      "  Param[bias]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-1.159238576889038, max=1.159238576889038, delta=0.009127862810149906, offset=-127.0\n",
      "  -------\n",
      "  Output[0]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-2.471842050552368, max=2.471842050552368, delta=0.01946332323269581, offset=-127.0\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: layer2.1.module_add_3\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Input[1]: Not quantized\n",
      "  -------\n",
      "  Output[0]: Not quantized\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: layer2.1.module_relu_1\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Output[0]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-4.6385064125061035, max=4.6385064125061035, delta=0.036523672539418135, offset=-127.0\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: layer3.0.conv1\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Param[weight]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-0.23571734130382538, max=0.23571734130382538, delta=0.001856042057510436, offset=-127.0\n",
      "  -------\n",
      "  Param[bias]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-0.8612890243530273, max=0.8612890243530273, delta=0.00678180334136242, offset=-127.0\n",
      "  -------\n",
      "  Output[0]: Not quantized\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: layer3.0.relu\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Output[0]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-1.7147417068481445, max=1.7147417068481445, delta=0.013501903203528696, offset=-127.0\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: layer3.0.conv2\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Param[weight]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-0.563919186592102, max=0.563919186592102, delta=0.004440308555843323, offset=-127.0\n",
      "  -------\n",
      "  Param[bias]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-0.6091494560241699, max=0.6091494560241699, delta=0.004796452409639133, offset=-127.0\n",
      "  -------\n",
      "  Output[0]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-2.2017791271209717, max=2.2017791271209717, delta=0.017336843520637572, offset=-127.0\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: layer3.0.downsample.0\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Param[weight]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-0.4081612229347229, max=0.4081612229347229, delta=0.0032138678971238024, offset=-127.0\n",
      "  -------\n",
      "  Param[bias]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-0.3355441093444824, max=0.3355441093444824, delta=0.002642079601137657, offset=-127.0\n",
      "  -------\n",
      "  Output[0]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-1.1659480333328247, max=1.1659480333328247, delta=0.009180693175849013, offset=-127.0\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: layer3.0.module_add_4\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Input[1]: Not quantized\n",
      "  -------\n",
      "  Output[0]: Not quantized\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: layer3.0.module_relu_1\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Output[0]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-2.1018495559692383, max=2.1018495559692383, delta=0.016549996503694788, offset=-127.0\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: layer3.1.conv1\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Param[weight]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-0.27238303422927856, max=0.27238303422927856, delta=0.0021447483010179416, offset=-127.0\n",
      "  -------\n",
      "  Param[bias]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-0.8067159056663513, max=0.8067159056663513, delta=0.006352093745404341, offset=-127.0\n",
      "  -------\n",
      "  Output[0]: Not quantized\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: layer3.1.relu\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Output[0]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-1.2258715629577637, max=1.2258715629577637, delta=0.009652531991793415, offset=-127.0\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: layer3.1.conv2\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Param[weight]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-0.9701208472251892, max=0.9701208472251892, delta=0.007638746828544797, offset=-127.0\n",
      "  -------\n",
      "  Param[bias]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-1.061082124710083, max=1.061082124710083, delta=0.008354977359921913, offset=-127.0\n",
      "  -------\n",
      "  Output[0]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-2.9392735958099365, max=2.9392735958099365, delta=0.023143886581180603, offset=-127.0\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: layer3.1.module_add_5\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Input[1]: Not quantized\n",
      "  -------\n",
      "  Output[0]: Not quantized\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: layer3.1.module_relu_1\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Output[0]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-2.718599319458008, max=2.718599319458008, delta=0.02140629385400006, offset=-127.0\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: layer4.0.conv1\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Param[weight]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-0.30162283778190613, max=0.30162283778190613, delta=0.002374982974660678, offset=-127.0\n",
      "  -------\n",
      "  Param[bias]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-0.564267635345459, max=0.564267635345459, delta=0.004443052246814638, offset=-127.0\n",
      "  -------\n",
      "  Output[0]: Not quantized\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: layer4.0.relu\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Output[0]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-1.4338197708129883, max=1.4338197708129883, delta=0.01128991945522038, offset=-127.0\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: layer4.0.conv2\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Param[weight]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-1.1437747478485107, max=1.1437747478485107, delta=0.009006100376759927, offset=-127.0\n",
      "  -------\n",
      "  Param[bias]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-1.1255919933319092, max=1.1255919933319092, delta=0.008862929081353615, offset=-127.0\n",
      "  -------\n",
      "  Output[0]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-3.4736530780792236, max=3.4736530780792236, delta=0.027351599039993887, offset=-127.0\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: layer4.0.downsample.0\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Param[weight]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-0.9982079863548278, max=0.9982079863548278, delta=0.007859905404368723, offset=-127.0\n",
      "  -------\n",
      "  Param[bias]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-0.7599548697471619, max=0.7599548697471619, delta=0.005983896612182377, offset=-127.0\n",
      "  -------\n",
      "  Output[0]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-1.438810110092163, max=1.438810110092163, delta=0.011329213465292623, offset=-127.0\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: layer4.0.module_add_6\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Input[1]: Not quantized\n",
      "  -------\n",
      "  Output[0]: Not quantized\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: layer4.0.module_relu_1\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Output[0]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-4.400547504425049, max=4.400547504425049, delta=0.03464998034980354, offset=-127.0\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: layer4.1.conv1\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Param[weight]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-0.2932627201080322, max=0.2932627201080322, delta=0.0023091552764411987, offset=-127.0\n",
      "  -------\n",
      "  Param[bias]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-0.8511659502983093, max=0.8511659502983093, delta=0.006702094096837081, offset=-127.0\n",
      "  -------\n",
      "  Output[0]: Not quantized\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: layer4.1.relu\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Output[0]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-1.176621675491333, max=1.176621675491333, delta=0.009264737602293962, offset=-127.0\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: layer4.1.conv2\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Param[weight]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-3.648308038711548, max=3.648308038711548, delta=0.028726834950484628, offset=-127.0\n",
      "  -------\n",
      "  Param[bias]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-2.225013017654419, max=2.225013017654419, delta=0.017519787540585977, offset=-127.0\n",
      "  -------\n",
      "  Output[0]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-12.381731033325195, max=12.381731033325195, delta=0.09749394514429288, offset=-127.0\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: layer4.1.module_add_7\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Input[1]: Not quantized\n",
      "  -------\n",
      "  Output[0]: Not quantized\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: layer4.1.module_relu_1\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Output[0]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-14.905149459838867, max=14.905149459838867, delta=0.11736338157353439, offset=-127.0\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: avgpool\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Output[0]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-5.364097595214844, max=5.364097595214844, delta=0.04223698893869956, offset=-127.0\n",
      "  -------\n",
      "----------------------------------------------------------\n",
      "Layer: fc\n",
      "  Input[0]: Not quantized\n",
      "  -------\n",
      "  Param[weight]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-0.7152369618415833, max=0.7152369618415833, delta=0.005631787101114828, offset=-127.0\n",
      "  -------\n",
      "  Param[bias]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-0.061649736016988754, max=0.061649736016988754, delta=0.000485430992259754, offset=-127.0\n",
      "  -------\n",
      "  Output[0]: bw=8, encoding-present=True\n",
      "    StaticGrid TensorQuantizer:\n",
      "    quant-scheme:QuantScheme.post_training_tf, round_mode=RoundingMode.ROUND_NEAREST, bitwidth=8, enabled=True\n",
      "    min:-11.122593879699707, max=11.122593879699707, delta=0.08757947936771422, offset=-127.0\n",
      "  -------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# with open(\"/home/shayan/Desktop/aimet/quantsim_report/tf/cf135f199d8c7a9d0dce9aa35acfb4c70c14e0aa.json\", \"w\") as f:\n",
    "# with open(\"/home/shayan/Desktop/aimet/quantsim_report/tf/c31381770ecd2ebd7530960f11a9c6ca56fd7f62.json\", \"w\") as f:\n",
    "with open(\"/home/shayan/Desktop/aimet/quantsim_report/tf/c3913df91d5dea761373473b38c96f3a1c9711b6.json\", \"w\") as f:\n",
    "    json.dump(sim.__dict__(), f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The QuantizationSim model is now ready to be used for inference or training. \n",
    "\n",
    "**3.7 Pass the model to the same evaluation routine as before to calculate a simulated quantized accuracy score for INT8 quantization for comparison with the FP32 score.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-20 10:47:23,613 - Dataloader - INFO - Dataset consists of 3 images in 1 classes\n",
      "('/home/shayan/Desktop/aimet/Examples/torch/quantization/val/9/cf135f199d8c7a9d0dce9aa35acfb4c70c14e0aa.jpeg',)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quant_outputs = forward(sim.model, ImageNetDataPipeline.get_val_dataloader())\n",
    "quant_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0698)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "torch.mean((fp32_output - quant_outputs)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-17 07:48:46,724 - Dataloader - INFO - Dataset consists of 1110 images in 111 classes\n",
      "2024-12-17 07:48:46,726 - Eval - INFO - No value of iteration is provided, running evaluation on complete dataset.\n",
      "2024-12-17 07:48:46,727 - Eval - INFO - Evaluating nn.Module for 1110 iterations with batch_size 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1110 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1110/1110 [01:31<00:00, 12.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-17 07:50:18,060 - Eval - INFO - Avg accuracy Top 1: 0.000000 Avg accuracy Top 5: 0.450450 on validation Dataset\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = ImageNetDataPipeline.evaluate(sim.model, use_cuda)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Apply CLE and BC\n",
    "\n",
    "### CLE\n",
    "\n",
    "**4.1 Perform CLE**\n",
    "\n",
    "The next cell performs cross-layer equalization on the model. As noted before, the function folds batch norms, applies cross-layer scaling, and then folds high biases.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Note\n",
    "\n",
    "The CLE procedure needs BN statistics. If a BN folded model is provided, CLE runs the cross-layer scaling (CLS) optimization step but skips the high-bias absorption (HBA) step. To avoid this, load the original model again before running CLE.\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Note\n",
    "\n",
    "CLE equalizes the model in-place.\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18(pretrained=True) # Reload the model\n",
    "model = prepare_model(model)\n",
    "\n",
    "use_cuda = False\n",
    "if torch.cuda.is_available():\n",
    "    use_cuda = True\n",
    "    model.to(torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aimet_torch.cross_layer_equalization import equalize_model\n",
    "\n",
    "equalize_model(model, input_shapes=(1, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**4.2 Compute the accuracy of the equalized model.** \n",
    "\n",
    "Create a simulation model as before and evaluate it to determine simulated quantized accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sim = QuantizationSimModel(model=model,\n",
    "                           quant_scheme=QuantScheme.post_training_tf,\n",
    "                           dummy_input=dummy_input,\n",
    "                           default_output_bw=8,\n",
    "                           default_param_bw=8)\n",
    "\n",
    "sim.compute_encodings(forward_pass_callback=pass_calibration_data,\n",
    "                      forward_pass_callback_args=use_cuda)\n",
    "\n",
    "accuracy = ImageNetDataPipeline.evaluate(sim.model, use_cuda)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Bias Correction\n",
    "\n",
    "**4.3 Apply AIMET Bias Correction to the equalized model from the previous step. **\n",
    "\n",
    "Bias correction uses a reference FP32 model and a QuantizationSimModel to perform the procedure. For details see [Post-training quantization techiques](https://quic.github.io/aimet-pages/releases/latest/user_guide/post_training_quant_techniques.html#) in the [AIMET User Guide](https://quic.github.io/aimet-pages/releases/latest/user_guide/index.html).\n",
    "\n",
    "Key parameters:\n",
    "\n",
    "- **num_quant_samples** is the number of samples used for computing encodings. Set low in this example to save time. A more typical number is 500-1000.\n",
    "- **num_bias_correct_samples** is the number of samples used for bias correction. Set low in this example to save time. A more typical number is 1000-2000.\n",
    "- **data_loader**: BC uses unlabeled data samples from this data loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aimet_torch.v1.quantsim import QuantParams\n",
    "from aimet_torch.bias_correction import correct_bias\n",
    "\n",
    "data_loader = ImageNetDataPipeline.get_val_dataloader()\n",
    "\n",
    "bc_params = QuantParams(weight_bw=8, act_bw=8, round_mode=\"nearest\",\n",
    "                        quant_scheme=QuantScheme.post_training_tf_enhanced)\n",
    "\n",
    "correct_bias(model, bc_params, num_quant_samples=16,\n",
    "             data_loader=data_loader, num_bias_correct_samples=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The QuantizationSim model is now ready to be used for inference or training. \n",
    "\n",
    "**4.4 Again calculate a simulated quantized accuracy, this time for the bias-corrected model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = QuantizationSimModel(model=model,\n",
    "                           quant_scheme=QuantScheme.post_training_tf_enhanced,\n",
    "                           dummy_input=dummy_input,\n",
    "                           default_output_bw=8,\n",
    "                           default_param_bw=8)\n",
    "\n",
    "sim.compute_encodings(forward_pass_callback=pass_calibration_data,\n",
    "                      forward_pass_callback_args=use_cuda)\n",
    "\n",
    "accuracy = ImageNetDataPipeline.evaluate(sim.model, use_cuda)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "There might be little gain in accuracy after this limited application of CLE and BC. Experiment with the hyper-parameters to get better results.\n",
    "\n",
    "## Next steps\n",
    "\n",
    "The next step is to export this model for installation on the target.\n",
    "\n",
    "**Export the model and encodings.**\n",
    "\n",
    "- Export the model with the updated weights but without the fake quant ops. \n",
    "- Export the encodings (scale and offset quantization parameters). AIMET QuantizationSimModel provides an export API for this purpose.\n",
    "\n",
    "The following code performs these exports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./output/', exist_ok=True)\n",
    "dummy_input = dummy_input.cpu()\n",
    "sim.export(path='./output/', filename_prefix='resnet18_after_cle_bc', dummy_input=dummy_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For more information\n",
    "\n",
    "See the [AIMET API docs](https://quic.github.io/aimet-pages/AimetDocs/api_docs/index.html) for details about the AIMET APIs and optional parameters.\n",
    "\n",
    "See the [other example notebooks](https://github.com/quic/aimet/tree/develop/Examples/torch/quantization) to learn how to use other AIMET post-training quantization techniques.\n",
    "\n",
    "To learn more about these techniques, see [\"Data-Free Quantization Through Weight Equalization and Bias Correction\"](https://arxiv.org/abs/1906.04721) from ICCV 2019."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
