{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from mmcv.transforms import Compose\n",
    "from mmdet.utils import get_test_pipeline_cfg\n",
    "\n",
    "def read_json(json_path):\n",
    "    with open(json_path) as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def read_txt(txt_path):\n",
    "    with open(txt_path) as f:\n",
    "        data = f.readlines()\n",
    "    data = [x.strip() for x in data]\n",
    "    return data\n",
    "\n",
    "def preprocess(test_pipeline, image):\n",
    "    if isinstance(image, np.ndarray):\n",
    "        # Calling this method across libraries will result\n",
    "        # in module unregistered error if not prefixed with mmdet.\n",
    "        test_pipeline[0].type = 'mmdet.LoadImageFromNDArray'\n",
    "    test_pipeline = Compose(test_pipeline)\n",
    "    return test_pipeline(dict(img=image))\n",
    "\n",
    "class CustomImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, images_dir, annotations_json_path, transform=None):\n",
    "        self.transform = transform\n",
    "        self.images_dir = images_dir\n",
    "        self.annotations_json = read_json(annotations_json_path)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations_json['images'])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_dict = self.annotations_json['images'][idx]\n",
    "        image_path = os.path.join(self.images_dir, image_dict['file_name'])\n",
    "        image_id = image_dict['id']\n",
    "\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            transformed_images = self.transform(image)\n",
    "        else:\n",
    "            transformed_images = image\n",
    "\n",
    "        return image_id, image_path, transformed_images\n",
    "\n",
    "\n",
    "# calibrationDataloader = DataLoader(calibrationDataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: /teamspace/studios/this_studio/mmdetection/rtmdet_tiny_8xb32-300e_coco_20220902_112414-78e30dcc.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: data_preprocessor.mean, data_preprocessor.std\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/mmengine/visualization/visualizer.py:196: UserWarning: Failed to add <class 'mmengine.visualization.vis_backend.LocalVisBackend'>, please provide the `save_dir` argument.\n",
      "  warnings.warn(f'Failed to add {vis_backend.__class__}, '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from mmdet.apis import DetInferencer\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize([640, 640]),  # Resize\n",
    "])\n",
    "\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "CONFIG_PATH = '/teamspace/studios/this_studio/mmdetection/rtmdet_tiny_8xb32-300e_coco.py'\n",
    "WEIGHTS_PATH = '/teamspace/studios/this_studio/mmdetection/rtmdet_tiny_8xb32-300e_coco_20220902_112414-78e30dcc.pth'\n",
    "EVAL_DATASET_SIZE = 5000\n",
    "CALIBRATION_DATASET_SIZE = 1000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "ROOT_DATASET_DIR = '/teamspace/studios/this_studio/COCO'\n",
    "IMAGES_DIR = os.path.join(ROOT_DATASET_DIR, 'images')\n",
    "ANNOTATIONS_JSON_PATH = os.path.join(ROOT_DATASET_DIR, 'annotations/instances_val2017.json')\n",
    "# ANNOTATIONS_JSON_PATH = \"/home/shayaan/Desktop/aimet/my_mmdet/temp.json\"\n",
    "\n",
    "model = DetInferencer(model=CONFIG_PATH, weights=WEIGHTS_PATH, device=DEVICE)\n",
    "evalDataset = CustomImageDataset(images_dir=IMAGES_DIR, annotations_json_path=ANNOTATIONS_JSON_PATH, transform=transform)\n",
    "eval_data_loader = DataLoader(evalDataset, batch_size=BATCH_SIZE)\n",
    "calibration_images = read_txt('/teamspace/studios/this_studio/aimet/Examples/torch/quantization/calibration_image_ids.txt')\n",
    "calibration_data_loader = DataLoader(calibration_images, batch_size=BATCH_SIZE)\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import inspect\n",
    "\n",
    "# lines = inspect.getsource(dict(model.model.named_modules())['backbone.stem.1.bn'].__class__)\n",
    "# print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from copy import deepcopy\n",
    "\n",
    "def replace_rtm_bn(model):\n",
    "    m = deepcopy(model.model)\n",
    "\n",
    "    def is_leaf(module): \n",
    "        return len(module._modules) == 0\n",
    "\n",
    "    def replace_bn(m):\n",
    "\n",
    "        if is_leaf(m):\n",
    "            return \n",
    "\n",
    "        for _, child in m.named_children(): \n",
    "            \n",
    "            if \"bn\" in child._modules.keys():\n",
    "                bn = child._modules.get(\"bn\")\n",
    "                bn_params = deepcopy(bn._parameters)\n",
    "                bn_buffers = deepcopy(bn._buffers)\n",
    "                new_bn = torch.nn.BatchNorm2d(bn.num_features, eps=bn.eps, momentum=bn.momentum, affine=bn.affine, track_running_stats=bn.track_running_stats)\n",
    "                new_bn._parameters[\"weight\"].data = bn_params[\"weight\"].data\n",
    "                new_bn._parameters[\"bias\"].data = bn_params[\"bias\"].data\n",
    "                new_bn._buffers[\"running_mean\"].data = bn_buffers[\"running_mean\"].data\n",
    "                new_bn._buffers[\"running_var\"].data = bn_buffers[\"running_var\"].data\n",
    "                new_bn._buffers[\"num_batches_tracked\"].data = bn_buffers[\"num_batches_tracked\"].data\n",
    "                child._modules[\"bn\"] = new_bn\n",
    "                \n",
    "            replace_bn(child)\n",
    "\n",
    "    replace_bn(m)\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done (t=1.16s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "from mmdet.models.utils import samplelist_boxtype2tensor\n",
    "from mmengine.registry import MODELS\n",
    "from mmcv.transforms import Compose\n",
    "\n",
    "test_evaluator = model.cfg.test_evaluator\n",
    "test_evaluator.type = 'mmdet.evaluation.CocoMetric' \n",
    "test_evaluator.dataset_meta = model.model.dataset_meta\n",
    "test_evaluator.ann_file = ANNOTATIONS_JSON_PATH\n",
    "test_evaluator = Compose(test_evaluator)\n",
    "\n",
    "collate_preprocessor = model.preprocess\n",
    "predict_by_feat = model.model.bbox_head.predict_by_feat\n",
    "rescale = True\n",
    "\n",
    "preprocessor = MODELS.build(model.cfg.model.data_preprocessor)\n",
    "def add_pred_to_datasample(data_samples, results_list):\n",
    "    for data_sample, pred_instances in zip(data_samples, results_list):\n",
    "        data_sample.pred_instances = pred_instances\n",
    "    samplelist_boxtype2tensor(data_samples)\n",
    "    return data_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pass_calibration_data(model: torch.nn.Module, samples: int):\n",
    "    data_loader = eval_data_loader\n",
    "    batch_size = data_loader.batch_size\n",
    "    model.eval()\n",
    "    batch_ctr = 0\n",
    "    with torch.no_grad():\n",
    "        for image_path in tqdm(calibration_data_loader):\n",
    "            image_path = [os.path.join(IMAGES_DIR, x) for x in image_path]\n",
    "            pre_processed = collate_preprocessor(inputs=image_path, batch_size=batch_size)\n",
    "            _, data = list(pre_processed)[0]\n",
    "            data = preprocessor(data, False)\n",
    "            \n",
    "            preds = model(data['inputs'].to(DEVICE))  \n",
    "\n",
    "            # batch_ctr += 1\n",
    "            # if (batch_ctr * batch_size) > samples:\n",
    "            #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([1.3939, 0.4195, 0.4683, 0.4950, 0.5379, 0.4248, 0.3259, 1.5808, 1.2741,\n",
       "        0.5667, 0.2874, 0.1334, 0.3919, 0.5569, 0.6871, 0.5312, 0.8215, 0.9876,\n",
       "        0.2597, 0.6685, 0.6328, 0.7639, 0.1999, 0.3412], device='cuda:0',\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(model.model.named_modules())['backbone.stage1.1.main_conv.bn'].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from aimet_torch.model_preparer import prepare_model\n",
    "\n",
    "# class CustomBatchNorm2d(torch.nn.Module):\n",
    "#     def __init__(self, *args, **kwargs):\n",
    "#         super().__init__(*args, **kwargs)\n",
    "#         self.bn = torch.nn.BatchNorm2d(num_features = 12, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         return self.bn(x)\n",
    "    \n",
    "# class CustomBatchNorm2d(torch.nn.modules.batchnorm._BatchNorm):\n",
    "#     def __init__(self, *args, **kwargs):\n",
    "#         super().__init__(*args, **kwargs)\n",
    "\n",
    "#     def _check_input_dim(self, input: torch.Tensor):\n",
    "#         return\n",
    "\n",
    "# class CustomModel(torch.nn.Module):\n",
    "#     def __init__(self): \n",
    "#         super().__init__()\n",
    "\n",
    "#         self.conv = torch.nn.Conv2d(3, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "#         self.bn = CustomBatchNorm2d(num_features = 12, eps = 1e-05, momentum = 0.1, affine = True, track_running_stats = True)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv(x)\n",
    "#         x = self.bn(x)\n",
    "#         return x\n",
    "    \n",
    "\n",
    "# custom_model = CustomModel()\n",
    "\n",
    "# model = prepare_model(custom_model)\n",
    "\n",
    "# from aimet_torch.batch_norm_fold import fold_all_batch_norms\n",
    "\n",
    "# fold_all_batch_norms(model, input_shapes=(1, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-04 13:06:36,143 - ModelPreparer - INFO - Functional         : Adding new module for node: {backbone.stage1.1.blocks.0.module_add} \n",
      "2024-09-04 13:06:36,145 - ModelPreparer - INFO - Functional         : Adding new module for node: {backbone.stage1.1.module_cat} \n",
      "2024-09-04 13:06:36,146 - ModelPreparer - INFO - Functional         : Adding new module for node: {backbone.stage1.1.attention.module_mul} \n",
      "2024-09-04 13:06:36,148 - ModelPreparer - INFO - Functional         : Adding new module for node: {backbone.stage2.1.blocks.0.module_add_1} \n",
      "2024-09-04 13:06:36,149 - ModelPreparer - INFO - Functional         : Adding new module for node: {backbone.stage2.1.module_cat_1} \n",
      "2024-09-04 13:06:36,150 - ModelPreparer - INFO - Functional         : Adding new module for node: {backbone.stage2.1.attention.module_mul_1} \n",
      "2024-09-04 13:06:36,151 - ModelPreparer - INFO - Functional         : Adding new module for node: {backbone.stage3.1.blocks.0.module_add_2} \n",
      "2024-09-04 13:06:36,152 - ModelPreparer - INFO - Functional         : Adding new module for node: {backbone.stage3.1.module_cat_2} \n",
      "2024-09-04 13:06:36,154 - ModelPreparer - INFO - Functional         : Adding new module for node: {backbone.stage3.1.attention.module_mul_2} \n",
      "2024-09-04 13:06:36,155 - ModelPreparer - INFO - Functional         : Adding new module for node: {backbone.stage4.1.module_cat_3} \n",
      "2024-09-04 13:06:36,156 - ModelPreparer - INFO - Functional         : Adding new module for node: {backbone.stage4.2.module_cat_4} \n",
      "2024-09-04 13:06:36,157 - ModelPreparer - INFO - Functional         : Adding new module for node: {backbone.stage4.2.attention.module_mul_3} \n",
      "2024-09-04 13:06:36,159 - ModelPreparer - INFO - Functional         : Adding new module for node: {neck.module_cat_5} \n",
      "2024-09-04 13:06:36,160 - ModelPreparer - INFO - Functional         : Adding new module for node: {neck.top_down_blocks.0.module_cat_6} \n",
      "2024-09-04 13:06:36,163 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {neck.module_upsample_1} \n",
      "2024-09-04 13:06:36,164 - ModelPreparer - INFO - Functional         : Adding new module for node: {neck.module_cat_7} \n",
      "2024-09-04 13:06:36,165 - ModelPreparer - INFO - Functional         : Adding new module for node: {neck.top_down_blocks.1.module_cat_8} \n",
      "2024-09-04 13:06:36,167 - ModelPreparer - INFO - Functional         : Adding new module for node: {neck.module_cat_9} \n",
      "2024-09-04 13:06:36,169 - ModelPreparer - INFO - Functional         : Adding new module for node: {neck.bottom_up_blocks.0.module_cat_10} \n",
      "2024-09-04 13:06:36,170 - ModelPreparer - INFO - Functional         : Adding new module for node: {neck.module_cat_11} \n",
      "2024-09-04 13:06:36,171 - ModelPreparer - INFO - Functional         : Adding new module for node: {neck.bottom_up_blocks.1.module_cat_12} \n",
      "2024-09-04 13:06:36,173 - ModelPreparer - INFO - Functional         : Adding new module for node: {bbox_head.module_mul_4} \n",
      "2024-09-04 13:06:36,174 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {bbox_head.cls_convs.0.0.module_conv_1} \n",
      "2024-09-04 13:06:36,176 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {bbox_head.cls_convs.0.1.module_conv_1} \n",
      "2024-09-04 13:06:36,178 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {bbox_head.reg_convs.0.0.module_conv_1} \n",
      "2024-09-04 13:06:36,179 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {bbox_head.reg_convs.0.1.module_conv_1} \n",
      "2024-09-04 13:06:36,180 - ModelPreparer - INFO - Functional         : Adding new module for node: {bbox_head.module_mul_5} \n",
      "2024-09-04 13:06:36,181 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {bbox_head.cls_convs.0.0.module_conv_2} \n",
      "2024-09-04 13:06:36,183 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {bbox_head.cls_convs.0.1.module_conv_2} \n",
      "2024-09-04 13:06:36,184 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {bbox_head.reg_convs.0.0.module_conv_2} \n",
      "2024-09-04 13:06:36,185 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {bbox_head.reg_convs.0.1.module_conv_2} \n",
      "2024-09-04 13:06:36,186 - ModelPreparer - INFO - Functional         : Adding new module for node: {bbox_head.module_mul_6} \n",
      "2024-09-04 13:06:43,799 - BatchNormFolding - INFO - 0 BatchNorms' weights got converted\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bn_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-04 12:32:06,567 - ModelPreparer - INFO - Functional         : Adding new module for node: {backbone.stage1.1.blocks.0.module_add} \n",
      "2024-09-04 12:32:06,568 - ModelPreparer - INFO - Functional         : Adding new module for node: {backbone.stage1.1.module_cat} \n",
      "2024-09-04 12:32:06,570 - ModelPreparer - INFO - Functional         : Adding new module for node: {backbone.stage1.1.attention.module_mul} \n",
      "2024-09-04 12:32:06,571 - ModelPreparer - INFO - Functional         : Adding new module for node: {backbone.stage2.1.blocks.0.module_add_1} \n",
      "2024-09-04 12:32:06,572 - ModelPreparer - INFO - Functional         : Adding new module for node: {backbone.stage2.1.module_cat_1} \n",
      "2024-09-04 12:32:06,573 - ModelPreparer - INFO - Functional         : Adding new module for node: {backbone.stage2.1.attention.module_mul_1} \n",
      "2024-09-04 12:32:06,574 - ModelPreparer - INFO - Functional         : Adding new module for node: {backbone.stage3.1.blocks.0.module_add_2} \n",
      "2024-09-04 12:32:06,575 - ModelPreparer - INFO - Functional         : Adding new module for node: {backbone.stage3.1.module_cat_2} \n",
      "2024-09-04 12:32:06,577 - ModelPreparer - INFO - Functional         : Adding new module for node: {backbone.stage3.1.attention.module_mul_2} \n",
      "2024-09-04 12:32:06,578 - ModelPreparer - INFO - Functional         : Adding new module for node: {backbone.stage4.1.module_cat_3} \n",
      "2024-09-04 12:32:06,579 - ModelPreparer - INFO - Functional         : Adding new module for node: {backbone.stage4.2.module_cat_4} \n",
      "2024-09-04 12:32:06,581 - ModelPreparer - INFO - Functional         : Adding new module for node: {backbone.stage4.2.attention.module_mul_3} \n",
      "2024-09-04 12:32:06,582 - ModelPreparer - INFO - Functional         : Adding new module for node: {neck.module_cat_5} \n",
      "2024-09-04 12:32:06,583 - ModelPreparer - INFO - Functional         : Adding new module for node: {neck.top_down_blocks.0.module_cat_6} \n",
      "2024-09-04 12:32:06,584 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {neck.module_upsample_1} \n",
      "2024-09-04 12:32:06,585 - ModelPreparer - INFO - Functional         : Adding new module for node: {neck.module_cat_7} \n",
      "2024-09-04 12:32:06,586 - ModelPreparer - INFO - Functional         : Adding new module for node: {neck.top_down_blocks.1.module_cat_8} \n",
      "2024-09-04 12:32:06,587 - ModelPreparer - INFO - Functional         : Adding new module for node: {neck.module_cat_9} \n",
      "2024-09-04 12:32:06,588 - ModelPreparer - INFO - Functional         : Adding new module for node: {neck.bottom_up_blocks.0.module_cat_10} \n",
      "2024-09-04 12:32:06,589 - ModelPreparer - INFO - Functional         : Adding new module for node: {neck.module_cat_11} \n",
      "2024-09-04 12:32:06,590 - ModelPreparer - INFO - Functional         : Adding new module for node: {neck.bottom_up_blocks.1.module_cat_12} \n",
      "2024-09-04 12:32:06,592 - ModelPreparer - INFO - Functional         : Adding new module for node: {bbox_head.module_mul_4} \n",
      "2024-09-04 12:32:06,594 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {bbox_head.cls_convs.0.0.module_conv_1} \n",
      "2024-09-04 12:32:06,595 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {bbox_head.cls_convs.0.1.module_conv_1} \n",
      "2024-09-04 12:32:06,597 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {bbox_head.reg_convs.0.0.module_conv_1} \n",
      "2024-09-04 12:32:06,599 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {bbox_head.reg_convs.0.1.module_conv_1} \n",
      "2024-09-04 12:32:06,600 - ModelPreparer - INFO - Functional         : Adding new module for node: {bbox_head.module_mul_5} \n",
      "2024-09-04 12:32:06,602 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {bbox_head.cls_convs.0.0.module_conv_2} \n",
      "2024-09-04 12:32:06,603 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {bbox_head.cls_convs.0.1.module_conv_2} \n",
      "2024-09-04 12:32:06,605 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {bbox_head.reg_convs.0.0.module_conv_2} \n",
      "2024-09-04 12:32:06,606 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {bbox_head.reg_convs.0.1.module_conv_2} \n",
      "2024-09-04 12:32:06,607 - ModelPreparer - INFO - Functional         : Adding new module for node: {bbox_head.module_mul_6} \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-04 12:32:14,620 - BatchNormFolding - INFO - 0 BatchNorms' weights got converted\n",
      "Length of bn pairs:  76\n",
      "dtype of model:  torch.float32\n",
      "2024-09-04 12:32:18,710 - Quant - INFO - Changed quantization params for this module: backbone.stage2.1.blocks.0.conv2.pointwise_conv.conv\n",
      "2024-09-04 12:32:18,781 - Quant - INFO - No config file provided, defaulting to config file at /usr/local/lib/python3.10/dist-packages/aimet_common/quantsim_config/default_config.json\n",
      "2024-09-04 12:32:18,833 - Quant - INFO - Unsupported op type Squeeze\n",
      "2024-09-04 12:32:18,834 - Quant - INFO - Unsupported op type Mean\n",
      "2024-09-04 12:32:18,858 - Quant - INFO - Selecting DefaultOpInstanceConfigGenerator to compute the specialized config. hw_version:default\n"
     ]
    }
   ],
   "source": [
    "from aimet_torch.v2.quantsim import QuantizationSimModel\n",
    "from aimet_common.defs import QuantScheme, QuantizationDataType\n",
    "from aimet_torch.model_preparer import prepare_model\n",
    "from aimet_torch.batch_norm_fold import fold_all_batch_norms\n",
    "\n",
    "def exclude_modules_from_quant(sim, modules_to_ignore):\n",
    "    name_to_quant_wrapper_dict = {}\n",
    "    for name, module in sim.model.named_modules():\n",
    "        name_to_quant_wrapper_dict[name] = module\n",
    "\n",
    "    quant_wrappers_to_ignore = []\n",
    "    for name in modules_to_ignore:\n",
    "        quant_wrapper = name_to_quant_wrapper_dict[name]\n",
    "        quant_wrappers_to_ignore.append(quant_wrapper)\n",
    "\n",
    "    sim.exclude_layers_from_quantization(quant_wrappers_to_ignore)\n",
    "\n",
    "dummy_input = torch.rand(1, 3, 640, 640).to(DEVICE)# Shape for each ImageNet sample is (3 channels) x (224 height) x (224 width)\n",
    "\n",
    "m = replace_rtm_bn(model)\n",
    "m = prepare_model(m)\n",
    "bn_pairs = fold_all_batch_norms(m, input_shapes=(1, 3, 640, 640))\n",
    "print(\"Length of bn pairs: \", len(bn_pairs))\n",
    "\n",
    "modules = dict(m.named_modules())\n",
    "\n",
    "modules_to_change = ['backbone.stage2.1.blocks.0.conv2.depthwise_conv.bn', 'backbone.stage1.1.blocks.0.conv2.depthwise_conv.bn', 'backbone.stage2.1.blocks.0.conv2.pointwise_conv.conv', 'backbone.stage3.1.blocks.0.conv2.depthwise_conv.bn', 'backbone.stage4.2.blocks.0.conv2.depthwise_conv.bn', 'neck.top_down_blocks.0.blocks.0.conv2.depthwise_conv.bn', 'neck.top_down_blocks.1.blocks.0.conv2.depthwise_conv.bn', 'neck.bottom_up_blocks.0.blocks.0.conv2.depthwise_conv.bn', 'neck.bottom_up_blocks.1.blocks.0.conv2.depthwise_conv.bn']\n",
    "modules_to_change = {modules[x]: {\"output_bw\": 16, \"param_bw\": 16, \"data_type\": QuantizationDataType.float, \"module_name\": x} for x in modules_to_change}\n",
    "\n",
    "print(\"dtype of model: \", list(dict(m.named_parameters()).values())[0].dtype)\n",
    "quant_sim = QuantizationSimModel(model=m,\n",
    "                                quant_scheme=QuantScheme.post_training_tf_enhanced,\n",
    "                                default_param_bw=8,\n",
    "                                default_output_bw=8,\n",
    "                                config_file=None,\n",
    "                                dummy_input=dummy_input,\n",
    "                                modules_to_change=modules_to_change,\n",
    "                                in_place=True)\n",
    "\n",
    "### if load encodings\n",
    "# quant_sim.load_encodings(encodings=\"/teamspace/studios/this_studio/aimet/Examples/torch/quantization/sim_model_excluded_modules/rtm_det_torch.encodings\")\n",
    "# quant_sim.load_encodings(encodings=\"/teamspace/studios/this_studio/aimet/Examples/torch/quantization/quant_scheme_W@tf / A@tf/rtm_det_torch.encodings\")\n",
    "# quant_sim.load_encodings(encodings=f\"{BASE_PATH}/rtm_det_torch.encodings\")\n",
    "\n",
    "### else compute encodings\n",
    "# quant_sim.compute_encodings(pass_calibration_data, 1000)\n",
    "\n",
    "# modules_to_ignore = ['backbone.stage2.1.blocks.0.conv2.depthwise_conv.bn.module_batch_norm_14', 'backbone.stage1.1.blocks.0.conv2.depthwise_conv.bn.module_batch_norm_7', 'backbone.stage2.1.blocks.0.conv2.pointwise_conv.conv', 'backbone.stage3.1.blocks.0.conv2.depthwise_conv.bn.module_batch_norm_21', 'backbone.stage4.2.blocks.0.conv2.depthwise_conv.bn.module_batch_norm_30', 'neck.top_down_blocks.0.blocks.0.conv2.depthwise_conv.bn.module_batch_norm_37', 'neck.top_down_blocks.1.blocks.0.conv2.depthwise_conv.bn.module_batch_norm_44', 'neck.bottom_up_blocks.0.blocks.0.conv2.depthwise_conv.bn.module_batch_norm_51', 'neck.bottom_up_blocks.1.blocks.0.conv2.depthwise_conv.bn.module_batch_norm_58']\n",
    "# exclude_modules_from_quant(quant_sim, modules_to_ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "Quantized Model Report\n",
      "-------------------------\n",
      "GraphModule(\n",
      "  (backbone): Module(\n",
      "    (stem): Module(\n",
      "      (0): Module(\n",
      "        (conv): QuantizedConv2d(\n",
      "          3, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "        (bn): Identity()\n",
      "        (activate): CustomSiLU(\n",
      "          (sigmoid): QuantizedSigmoid(\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (mul): QuantizedMultiply(\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0-1): 2 x None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): Module(\n",
      "        (conv): QuantizedConv2d(\n",
      "          12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "        (bn): Identity()\n",
      "        (activate): CustomSiLU(\n",
      "          (sigmoid): QuantizedSigmoid(\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (mul): QuantizedMultiply(\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0-1): 2 x None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): Module(\n",
      "        (conv): QuantizedConv2d(\n",
      "          12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "        (bn): Identity()\n",
      "        (activate): CustomSiLU(\n",
      "          (sigmoid): QuantizedSigmoid(\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (mul): QuantizedMultiply(\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0-1): 2 x None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (stage1): Module(\n",
      "      (0): Module(\n",
      "        (conv): QuantizedConv2d(\n",
      "          24, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "        (bn): Identity()\n",
      "        (activate): CustomSiLU(\n",
      "          (sigmoid): QuantizedSigmoid(\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (mul): QuantizedMultiply(\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0-1): 2 x None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): Module(\n",
      "        (short_conv): Module(\n",
      "          (conv): QuantizedConv2d(\n",
      "            48, 24, kernel_size=(1, 1), stride=(1, 1)\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (bn): Identity()\n",
      "          (activate): CustomSiLU(\n",
      "            (sigmoid): QuantizedSigmoid(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0): None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "            (mul): QuantizedMultiply(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0-1): 2 x None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (main_conv): Module(\n",
      "          (conv): QuantizedConv2d(\n",
      "            48, 24, kernel_size=(1, 1), stride=(1, 1)\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (bn): Identity()\n",
      "          (activate): CustomSiLU(\n",
      "            (sigmoid): QuantizedSigmoid(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0): None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "            (mul): QuantizedMultiply(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0-1): 2 x None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (blocks): Module(\n",
      "          (0): Module(\n",
      "            (conv1): Module(\n",
      "              (conv): QuantizedConv2d(\n",
      "                24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "                (param_quantizers): ModuleDict(\n",
      "                  (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "                  (bias): None\n",
      "                )\n",
      "                (input_quantizers): ModuleList(\n",
      "                  (0): None\n",
      "                )\n",
      "                (output_quantizers): ModuleList(\n",
      "                  (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                )\n",
      "              )\n",
      "              (bn): Identity()\n",
      "              (activate): CustomSiLU(\n",
      "                (sigmoid): QuantizedSigmoid(\n",
      "                  (param_quantizers): ModuleDict()\n",
      "                  (input_quantizers): ModuleList(\n",
      "                    (0): None\n",
      "                  )\n",
      "                  (output_quantizers): ModuleList(\n",
      "                    (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                  )\n",
      "                )\n",
      "                (mul): QuantizedMultiply(\n",
      "                  (param_quantizers): ModuleDict()\n",
      "                  (input_quantizers): ModuleList(\n",
      "                    (0-1): 2 x None\n",
      "                  )\n",
      "                  (output_quantizers): ModuleList(\n",
      "                    (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (conv2): Module(\n",
      "              (depthwise_conv): Module(\n",
      "                (conv): QuantizedConv2d(\n",
      "                  24, 24, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=24\n",
      "                  (param_quantizers): ModuleDict(\n",
      "                    (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "                    (bias): None\n",
      "                  )\n",
      "                  (input_quantizers): ModuleList(\n",
      "                    (0): None\n",
      "                  )\n",
      "                  (output_quantizers): ModuleList(\n",
      "                    (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                  )\n",
      "                )\n",
      "                (bn): Identity()\n",
      "                (activate): CustomSiLU(\n",
      "                  (sigmoid): QuantizedSigmoid(\n",
      "                    (param_quantizers): ModuleDict()\n",
      "                    (input_quantizers): ModuleList(\n",
      "                      (0): None\n",
      "                    )\n",
      "                    (output_quantizers): ModuleList(\n",
      "                      (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (mul): QuantizedMultiply(\n",
      "                    (param_quantizers): ModuleDict()\n",
      "                    (input_quantizers): ModuleList(\n",
      "                      (0-1): 2 x None\n",
      "                    )\n",
      "                    (output_quantizers): ModuleList(\n",
      "                      (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                    )\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "              (pointwise_conv): Module(\n",
      "                (conv): QuantizedConv2d(\n",
      "                  24, 24, kernel_size=(1, 1), stride=(1, 1)\n",
      "                  (param_quantizers): ModuleDict(\n",
      "                    (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "                    (bias): None\n",
      "                  )\n",
      "                  (input_quantizers): ModuleList(\n",
      "                    (0): None\n",
      "                  )\n",
      "                  (output_quantizers): ModuleList(\n",
      "                    (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                  )\n",
      "                )\n",
      "                (bn): Identity()\n",
      "                (activate): CustomSiLU(\n",
      "                  (sigmoid): QuantizedSigmoid(\n",
      "                    (param_quantizers): ModuleDict()\n",
      "                    (input_quantizers): ModuleList(\n",
      "                      (0): None\n",
      "                    )\n",
      "                    (output_quantizers): ModuleList(\n",
      "                      (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (mul): QuantizedMultiply(\n",
      "                    (param_quantizers): ModuleDict()\n",
      "                    (input_quantizers): ModuleList(\n",
      "                      (0-1): 2 x None\n",
      "                    )\n",
      "                    (output_quantizers): ModuleList(\n",
      "                      (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                    )\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (module_add): QuantizedAdd(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0-1): 2 x None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (attention): Module(\n",
      "          (global_avgpool): FakeQuantizedAdaptiveAvgPool2d(\n",
      "            output_size=1\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (fc): QuantizedConv2d(\n",
      "            48, 48, kernel_size=(1, 1), stride=(1, 1)\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (act): FakeQuantizedHardsigmoid(\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (module_mul): QuantizedMultiply(\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0-1): 2 x None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (final_conv): Module(\n",
      "          (conv): QuantizedConv2d(\n",
      "            48, 48, kernel_size=(1, 1), stride=(1, 1)\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (bn): Identity()\n",
      "          (activate): CustomSiLU(\n",
      "            (sigmoid): QuantizedSigmoid(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0): None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "            (mul): QuantizedMultiply(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0-1): 2 x None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (module_cat): FakeQuantizedConcat(\n",
      "          (param_quantizers): ModuleDict()\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (stage2): Module(\n",
      "      (0): Module(\n",
      "        (conv): QuantizedConv2d(\n",
      "          48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "        (bn): Identity()\n",
      "        (activate): CustomSiLU(\n",
      "          (sigmoid): QuantizedSigmoid(\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (mul): QuantizedMultiply(\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0-1): 2 x None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): Module(\n",
      "        (short_conv): Module(\n",
      "          (conv): QuantizedConv2d(\n",
      "            96, 48, kernel_size=(1, 1), stride=(1, 1)\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (bn): Identity()\n",
      "          (activate): CustomSiLU(\n",
      "            (sigmoid): QuantizedSigmoid(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0): None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "            (mul): QuantizedMultiply(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0-1): 2 x None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (main_conv): Module(\n",
      "          (conv): QuantizedConv2d(\n",
      "            96, 48, kernel_size=(1, 1), stride=(1, 1)\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (bn): Identity()\n",
      "          (activate): CustomSiLU(\n",
      "            (sigmoid): QuantizedSigmoid(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0): None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "            (mul): QuantizedMultiply(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0-1): 2 x None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (blocks): Module(\n",
      "          (0): Module(\n",
      "            (conv1): Module(\n",
      "              (conv): QuantizedConv2d(\n",
      "                48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "                (param_quantizers): ModuleDict(\n",
      "                  (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "                  (bias): None\n",
      "                )\n",
      "                (input_quantizers): ModuleList(\n",
      "                  (0): None\n",
      "                )\n",
      "                (output_quantizers): ModuleList(\n",
      "                  (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                )\n",
      "              )\n",
      "              (bn): Identity()\n",
      "              (activate): CustomSiLU(\n",
      "                (sigmoid): QuantizedSigmoid(\n",
      "                  (param_quantizers): ModuleDict()\n",
      "                  (input_quantizers): ModuleList(\n",
      "                    (0): None\n",
      "                  )\n",
      "                  (output_quantizers): ModuleList(\n",
      "                    (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                  )\n",
      "                )\n",
      "                (mul): QuantizedMultiply(\n",
      "                  (param_quantizers): ModuleDict()\n",
      "                  (input_quantizers): ModuleList(\n",
      "                    (0-1): 2 x None\n",
      "                  )\n",
      "                  (output_quantizers): ModuleList(\n",
      "                    (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (conv2): Module(\n",
      "              (depthwise_conv): Module(\n",
      "                (conv): QuantizedConv2d(\n",
      "                  48, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=48\n",
      "                  (param_quantizers): ModuleDict(\n",
      "                    (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "                    (bias): None\n",
      "                  )\n",
      "                  (input_quantizers): ModuleList(\n",
      "                    (0): None\n",
      "                  )\n",
      "                  (output_quantizers): ModuleList(\n",
      "                    (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                  )\n",
      "                )\n",
      "                (bn): Identity()\n",
      "                (activate): CustomSiLU(\n",
      "                  (sigmoid): QuantizedSigmoid(\n",
      "                    (param_quantizers): ModuleDict()\n",
      "                    (input_quantizers): ModuleList(\n",
      "                      (0): None\n",
      "                    )\n",
      "                    (output_quantizers): ModuleList(\n",
      "                      (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (mul): QuantizedMultiply(\n",
      "                    (param_quantizers): ModuleDict()\n",
      "                    (input_quantizers): ModuleList(\n",
      "                      (0-1): 2 x None\n",
      "                    )\n",
      "                    (output_quantizers): ModuleList(\n",
      "                      (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                    )\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "              (pointwise_conv): Module(\n",
      "                (conv): QuantizedConv2d(\n",
      "                  48, 48, kernel_size=(1, 1), stride=(1, 1)\n",
      "                  (param_quantizers): ModuleDict(\n",
      "                    (weight): FloatQuantizeDequantize(exponent_bits=5, mantissa_bits=10)\n",
      "                    (bias): None\n",
      "                  )\n",
      "                  (input_quantizers): ModuleList(\n",
      "                    (0): None\n",
      "                  )\n",
      "                  (output_quantizers): ModuleList(\n",
      "                    (0): FloatQuantizeDequantize(exponent_bits=5, mantissa_bits=10)\n",
      "                  )\n",
      "                )\n",
      "                (bn): Identity()\n",
      "                (activate): CustomSiLU(\n",
      "                  (sigmoid): QuantizedSigmoid(\n",
      "                    (param_quantizers): ModuleDict()\n",
      "                    (input_quantizers): ModuleList(\n",
      "                      (0): None\n",
      "                    )\n",
      "                    (output_quantizers): ModuleList(\n",
      "                      (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (mul): QuantizedMultiply(\n",
      "                    (param_quantizers): ModuleDict()\n",
      "                    (input_quantizers): ModuleList(\n",
      "                      (0-1): 2 x None\n",
      "                    )\n",
      "                    (output_quantizers): ModuleList(\n",
      "                      (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                    )\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (module_add_1): QuantizedAdd(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0-1): 2 x None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (attention): Module(\n",
      "          (global_avgpool): FakeQuantizedAdaptiveAvgPool2d(\n",
      "            output_size=1\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (fc): QuantizedConv2d(\n",
      "            96, 96, kernel_size=(1, 1), stride=(1, 1)\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (act): FakeQuantizedHardsigmoid(\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (module_mul_1): QuantizedMultiply(\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0-1): 2 x None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (final_conv): Module(\n",
      "          (conv): QuantizedConv2d(\n",
      "            96, 96, kernel_size=(1, 1), stride=(1, 1)\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (bn): Identity()\n",
      "          (activate): CustomSiLU(\n",
      "            (sigmoid): QuantizedSigmoid(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0): None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "            (mul): QuantizedMultiply(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0-1): 2 x None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (module_cat_1): FakeQuantizedConcat(\n",
      "          (param_quantizers): ModuleDict()\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (stage3): Module(\n",
      "      (0): Module(\n",
      "        (conv): QuantizedConv2d(\n",
      "          96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "        (bn): Identity()\n",
      "        (activate): CustomSiLU(\n",
      "          (sigmoid): QuantizedSigmoid(\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (mul): QuantizedMultiply(\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0-1): 2 x None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): Module(\n",
      "        (short_conv): Module(\n",
      "          (conv): QuantizedConv2d(\n",
      "            192, 96, kernel_size=(1, 1), stride=(1, 1)\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (bn): Identity()\n",
      "          (activate): CustomSiLU(\n",
      "            (sigmoid): QuantizedSigmoid(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0): None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "            (mul): QuantizedMultiply(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0-1): 2 x None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (main_conv): Module(\n",
      "          (conv): QuantizedConv2d(\n",
      "            192, 96, kernel_size=(1, 1), stride=(1, 1)\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (bn): Identity()\n",
      "          (activate): CustomSiLU(\n",
      "            (sigmoid): QuantizedSigmoid(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0): None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "            (mul): QuantizedMultiply(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0-1): 2 x None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (blocks): Module(\n",
      "          (0): Module(\n",
      "            (conv1): Module(\n",
      "              (conv): QuantizedConv2d(\n",
      "                96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "                (param_quantizers): ModuleDict(\n",
      "                  (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "                  (bias): None\n",
      "                )\n",
      "                (input_quantizers): ModuleList(\n",
      "                  (0): None\n",
      "                )\n",
      "                (output_quantizers): ModuleList(\n",
      "                  (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                )\n",
      "              )\n",
      "              (bn): Identity()\n",
      "              (activate): CustomSiLU(\n",
      "                (sigmoid): QuantizedSigmoid(\n",
      "                  (param_quantizers): ModuleDict()\n",
      "                  (input_quantizers): ModuleList(\n",
      "                    (0): None\n",
      "                  )\n",
      "                  (output_quantizers): ModuleList(\n",
      "                    (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                  )\n",
      "                )\n",
      "                (mul): QuantizedMultiply(\n",
      "                  (param_quantizers): ModuleDict()\n",
      "                  (input_quantizers): ModuleList(\n",
      "                    (0-1): 2 x None\n",
      "                  )\n",
      "                  (output_quantizers): ModuleList(\n",
      "                    (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (conv2): Module(\n",
      "              (depthwise_conv): Module(\n",
      "                (conv): QuantizedConv2d(\n",
      "                  96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96\n",
      "                  (param_quantizers): ModuleDict(\n",
      "                    (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "                    (bias): None\n",
      "                  )\n",
      "                  (input_quantizers): ModuleList(\n",
      "                    (0): None\n",
      "                  )\n",
      "                  (output_quantizers): ModuleList(\n",
      "                    (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                  )\n",
      "                )\n",
      "                (bn): Identity()\n",
      "                (activate): CustomSiLU(\n",
      "                  (sigmoid): QuantizedSigmoid(\n",
      "                    (param_quantizers): ModuleDict()\n",
      "                    (input_quantizers): ModuleList(\n",
      "                      (0): None\n",
      "                    )\n",
      "                    (output_quantizers): ModuleList(\n",
      "                      (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (mul): QuantizedMultiply(\n",
      "                    (param_quantizers): ModuleDict()\n",
      "                    (input_quantizers): ModuleList(\n",
      "                      (0-1): 2 x None\n",
      "                    )\n",
      "                    (output_quantizers): ModuleList(\n",
      "                      (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                    )\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "              (pointwise_conv): Module(\n",
      "                (conv): QuantizedConv2d(\n",
      "                  96, 96, kernel_size=(1, 1), stride=(1, 1)\n",
      "                  (param_quantizers): ModuleDict(\n",
      "                    (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "                    (bias): None\n",
      "                  )\n",
      "                  (input_quantizers): ModuleList(\n",
      "                    (0): None\n",
      "                  )\n",
      "                  (output_quantizers): ModuleList(\n",
      "                    (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                  )\n",
      "                )\n",
      "                (bn): Identity()\n",
      "                (activate): CustomSiLU(\n",
      "                  (sigmoid): QuantizedSigmoid(\n",
      "                    (param_quantizers): ModuleDict()\n",
      "                    (input_quantizers): ModuleList(\n",
      "                      (0): None\n",
      "                    )\n",
      "                    (output_quantizers): ModuleList(\n",
      "                      (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (mul): QuantizedMultiply(\n",
      "                    (param_quantizers): ModuleDict()\n",
      "                    (input_quantizers): ModuleList(\n",
      "                      (0-1): 2 x None\n",
      "                    )\n",
      "                    (output_quantizers): ModuleList(\n",
      "                      (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                    )\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (module_add_2): QuantizedAdd(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0-1): 2 x None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (attention): Module(\n",
      "          (global_avgpool): FakeQuantizedAdaptiveAvgPool2d(\n",
      "            output_size=1\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (fc): QuantizedConv2d(\n",
      "            192, 192, kernel_size=(1, 1), stride=(1, 1)\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (act): FakeQuantizedHardsigmoid(\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (module_mul_2): QuantizedMultiply(\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0-1): 2 x None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (final_conv): Module(\n",
      "          (conv): QuantizedConv2d(\n",
      "            192, 192, kernel_size=(1, 1), stride=(1, 1)\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (bn): Identity()\n",
      "          (activate): CustomSiLU(\n",
      "            (sigmoid): QuantizedSigmoid(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0): None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "            (mul): QuantizedMultiply(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0-1): 2 x None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (module_cat_2): FakeQuantizedConcat(\n",
      "          (param_quantizers): ModuleDict()\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (stage4): Module(\n",
      "      (0): Module(\n",
      "        (conv): QuantizedConv2d(\n",
      "          192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "        (bn): Identity()\n",
      "        (activate): CustomSiLU(\n",
      "          (sigmoid): QuantizedSigmoid(\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (mul): QuantizedMultiply(\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0-1): 2 x None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): Module(\n",
      "        (conv1): Module(\n",
      "          (conv): QuantizedConv2d(\n",
      "            384, 192, kernel_size=(1, 1), stride=(1, 1)\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (bn): Identity()\n",
      "          (activate): CustomSiLU(\n",
      "            (sigmoid): QuantizedSigmoid(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0): None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "            (mul): QuantizedMultiply(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0-1): 2 x None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (poolings): Module(\n",
      "          (0): FakeQuantizedMaxPool2d(\n",
      "            kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (1): FakeQuantizedMaxPool2d(\n",
      "            kernel_size=9, stride=1, padding=4, dilation=1, ceil_mode=False\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (2): FakeQuantizedMaxPool2d(\n",
      "            kernel_size=13, stride=1, padding=6, dilation=1, ceil_mode=False\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (conv2): Module(\n",
      "          (conv): QuantizedConv2d(\n",
      "            768, 384, kernel_size=(1, 1), stride=(1, 1)\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (bn): Identity()\n",
      "          (activate): CustomSiLU(\n",
      "            (sigmoid): QuantizedSigmoid(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0): None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "            (mul): QuantizedMultiply(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0-1): 2 x None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (module_cat_3): FakeQuantizedConcat(\n",
      "          (param_quantizers): ModuleDict()\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): Module(\n",
      "        (short_conv): Module(\n",
      "          (conv): QuantizedConv2d(\n",
      "            384, 192, kernel_size=(1, 1), stride=(1, 1)\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (bn): Identity()\n",
      "          (activate): CustomSiLU(\n",
      "            (sigmoid): QuantizedSigmoid(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0): None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "            (mul): QuantizedMultiply(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0-1): 2 x None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (main_conv): Module(\n",
      "          (conv): QuantizedConv2d(\n",
      "            384, 192, kernel_size=(1, 1), stride=(1, 1)\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (bn): Identity()\n",
      "          (activate): CustomSiLU(\n",
      "            (sigmoid): QuantizedSigmoid(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0): None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "            (mul): QuantizedMultiply(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0-1): 2 x None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (blocks): Module(\n",
      "          (0): Module(\n",
      "            (conv1): Module(\n",
      "              (conv): QuantizedConv2d(\n",
      "                192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "                (param_quantizers): ModuleDict(\n",
      "                  (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "                  (bias): None\n",
      "                )\n",
      "                (input_quantizers): ModuleList(\n",
      "                  (0): None\n",
      "                )\n",
      "                (output_quantizers): ModuleList(\n",
      "                  (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                )\n",
      "              )\n",
      "              (bn): Identity()\n",
      "              (activate): CustomSiLU(\n",
      "                (sigmoid): QuantizedSigmoid(\n",
      "                  (param_quantizers): ModuleDict()\n",
      "                  (input_quantizers): ModuleList(\n",
      "                    (0): None\n",
      "                  )\n",
      "                  (output_quantizers): ModuleList(\n",
      "                    (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                  )\n",
      "                )\n",
      "                (mul): QuantizedMultiply(\n",
      "                  (param_quantizers): ModuleDict()\n",
      "                  (input_quantizers): ModuleList(\n",
      "                    (0-1): 2 x None\n",
      "                  )\n",
      "                  (output_quantizers): ModuleList(\n",
      "                    (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (conv2): Module(\n",
      "              (depthwise_conv): Module(\n",
      "                (conv): QuantizedConv2d(\n",
      "                  192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192\n",
      "                  (param_quantizers): ModuleDict(\n",
      "                    (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "                    (bias): None\n",
      "                  )\n",
      "                  (input_quantizers): ModuleList(\n",
      "                    (0): None\n",
      "                  )\n",
      "                  (output_quantizers): ModuleList(\n",
      "                    (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                  )\n",
      "                )\n",
      "                (bn): Identity()\n",
      "                (activate): CustomSiLU(\n",
      "                  (sigmoid): QuantizedSigmoid(\n",
      "                    (param_quantizers): ModuleDict()\n",
      "                    (input_quantizers): ModuleList(\n",
      "                      (0): None\n",
      "                    )\n",
      "                    (output_quantizers): ModuleList(\n",
      "                      (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (mul): QuantizedMultiply(\n",
      "                    (param_quantizers): ModuleDict()\n",
      "                    (input_quantizers): ModuleList(\n",
      "                      (0-1): 2 x None\n",
      "                    )\n",
      "                    (output_quantizers): ModuleList(\n",
      "                      (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                    )\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "              (pointwise_conv): Module(\n",
      "                (conv): QuantizedConv2d(\n",
      "                  192, 192, kernel_size=(1, 1), stride=(1, 1)\n",
      "                  (param_quantizers): ModuleDict(\n",
      "                    (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "                    (bias): None\n",
      "                  )\n",
      "                  (input_quantizers): ModuleList(\n",
      "                    (0): None\n",
      "                  )\n",
      "                  (output_quantizers): ModuleList(\n",
      "                    (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                  )\n",
      "                )\n",
      "                (bn): Identity()\n",
      "                (activate): CustomSiLU(\n",
      "                  (sigmoid): QuantizedSigmoid(\n",
      "                    (param_quantizers): ModuleDict()\n",
      "                    (input_quantizers): ModuleList(\n",
      "                      (0): None\n",
      "                    )\n",
      "                    (output_quantizers): ModuleList(\n",
      "                      (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (mul): QuantizedMultiply(\n",
      "                    (param_quantizers): ModuleDict()\n",
      "                    (input_quantizers): ModuleList(\n",
      "                      (0-1): 2 x None\n",
      "                    )\n",
      "                    (output_quantizers): ModuleList(\n",
      "                      (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                    )\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (attention): Module(\n",
      "          (global_avgpool): FakeQuantizedAdaptiveAvgPool2d(\n",
      "            output_size=1\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (fc): QuantizedConv2d(\n",
      "            384, 384, kernel_size=(1, 1), stride=(1, 1)\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (act): FakeQuantizedHardsigmoid(\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (module_mul_3): QuantizedMultiply(\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0-1): 2 x None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (final_conv): Module(\n",
      "          (conv): QuantizedConv2d(\n",
      "            384, 384, kernel_size=(1, 1), stride=(1, 1)\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (bn): Identity()\n",
      "          (activate): CustomSiLU(\n",
      "            (sigmoid): QuantizedSigmoid(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0): None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "            (mul): QuantizedMultiply(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0-1): 2 x None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (module_cat_4): FakeQuantizedConcat(\n",
      "          (param_quantizers): ModuleDict()\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (neck): Module(\n",
      "    (reduce_layers): Module(\n",
      "      (0): Module(\n",
      "        (conv): QuantizedConv2d(\n",
      "          384, 192, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "        (bn): Identity()\n",
      "        (activate): CustomSiLU(\n",
      "          (sigmoid): QuantizedSigmoid(\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (mul): QuantizedMultiply(\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0-1): 2 x None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): Module(\n",
      "        (conv): QuantizedConv2d(\n",
      "          192, 96, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "        (bn): Identity()\n",
      "        (activate): CustomSiLU(\n",
      "          (sigmoid): QuantizedSigmoid(\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (mul): QuantizedMultiply(\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0-1): 2 x None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (upsample): FakeQuantizedUpsample(\n",
      "      scale_factor=2.0, mode='nearest'\n",
      "      (param_quantizers): ModuleDict()\n",
      "      (input_quantizers): ModuleList(\n",
      "        (0): None\n",
      "      )\n",
      "      (output_quantizers): ModuleList(\n",
      "        (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "      )\n",
      "    )\n",
      "    (top_down_blocks): Module(\n",
      "      (0): Module(\n",
      "        (short_conv): Module(\n",
      "          (conv): QuantizedConv2d(\n",
      "            384, 96, kernel_size=(1, 1), stride=(1, 1)\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (bn): Identity()\n",
      "          (activate): CustomSiLU(\n",
      "            (sigmoid): QuantizedSigmoid(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0): None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "            (mul): QuantizedMultiply(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0-1): 2 x None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (main_conv): Module(\n",
      "          (conv): QuantizedConv2d(\n",
      "            384, 96, kernel_size=(1, 1), stride=(1, 1)\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (bn): Identity()\n",
      "          (activate): CustomSiLU(\n",
      "            (sigmoid): QuantizedSigmoid(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0): None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "            (mul): QuantizedMultiply(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0-1): 2 x None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (blocks): Module(\n",
      "          (0): Module(\n",
      "            (conv1): Module(\n",
      "              (conv): QuantizedConv2d(\n",
      "                96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "                (param_quantizers): ModuleDict(\n",
      "                  (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "                  (bias): None\n",
      "                )\n",
      "                (input_quantizers): ModuleList(\n",
      "                  (0): None\n",
      "                )\n",
      "                (output_quantizers): ModuleList(\n",
      "                  (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                )\n",
      "              )\n",
      "              (bn): Identity()\n",
      "              (activate): CustomSiLU(\n",
      "                (sigmoid): QuantizedSigmoid(\n",
      "                  (param_quantizers): ModuleDict()\n",
      "                  (input_quantizers): ModuleList(\n",
      "                    (0): None\n",
      "                  )\n",
      "                  (output_quantizers): ModuleList(\n",
      "                    (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                  )\n",
      "                )\n",
      "                (mul): QuantizedMultiply(\n",
      "                  (param_quantizers): ModuleDict()\n",
      "                  (input_quantizers): ModuleList(\n",
      "                    (0-1): 2 x None\n",
      "                  )\n",
      "                  (output_quantizers): ModuleList(\n",
      "                    (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (conv2): Module(\n",
      "              (depthwise_conv): Module(\n",
      "                (conv): QuantizedConv2d(\n",
      "                  96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96\n",
      "                  (param_quantizers): ModuleDict(\n",
      "                    (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "                    (bias): None\n",
      "                  )\n",
      "                  (input_quantizers): ModuleList(\n",
      "                    (0): None\n",
      "                  )\n",
      "                  (output_quantizers): ModuleList(\n",
      "                    (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                  )\n",
      "                )\n",
      "                (bn): Identity()\n",
      "                (activate): CustomSiLU(\n",
      "                  (sigmoid): QuantizedSigmoid(\n",
      "                    (param_quantizers): ModuleDict()\n",
      "                    (input_quantizers): ModuleList(\n",
      "                      (0): None\n",
      "                    )\n",
      "                    (output_quantizers): ModuleList(\n",
      "                      (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (mul): QuantizedMultiply(\n",
      "                    (param_quantizers): ModuleDict()\n",
      "                    (input_quantizers): ModuleList(\n",
      "                      (0-1): 2 x None\n",
      "                    )\n",
      "                    (output_quantizers): ModuleList(\n",
      "                      (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                    )\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "              (pointwise_conv): Module(\n",
      "                (conv): QuantizedConv2d(\n",
      "                  96, 96, kernel_size=(1, 1), stride=(1, 1)\n",
      "                  (param_quantizers): ModuleDict(\n",
      "                    (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "                    (bias): None\n",
      "                  )\n",
      "                  (input_quantizers): ModuleList(\n",
      "                    (0): None\n",
      "                  )\n",
      "                  (output_quantizers): ModuleList(\n",
      "                    (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                  )\n",
      "                )\n",
      "                (bn): Identity()\n",
      "                (activate): CustomSiLU(\n",
      "                  (sigmoid): QuantizedSigmoid(\n",
      "                    (param_quantizers): ModuleDict()\n",
      "                    (input_quantizers): ModuleList(\n",
      "                      (0): None\n",
      "                    )\n",
      "                    (output_quantizers): ModuleList(\n",
      "                      (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (mul): QuantizedMultiply(\n",
      "                    (param_quantizers): ModuleDict()\n",
      "                    (input_quantizers): ModuleList(\n",
      "                      (0-1): 2 x None\n",
      "                    )\n",
      "                    (output_quantizers): ModuleList(\n",
      "                      (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                    )\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (final_conv): Module(\n",
      "          (conv): QuantizedConv2d(\n",
      "            192, 192, kernel_size=(1, 1), stride=(1, 1)\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (bn): Identity()\n",
      "          (activate): CustomSiLU(\n",
      "            (sigmoid): QuantizedSigmoid(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0): None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "            (mul): QuantizedMultiply(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0-1): 2 x None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (module_cat_6): FakeQuantizedConcat(\n",
      "          (param_quantizers): ModuleDict()\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): Module(\n",
      "        (short_conv): Module(\n",
      "          (conv): QuantizedConv2d(\n",
      "            192, 48, kernel_size=(1, 1), stride=(1, 1)\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (bn): Identity()\n",
      "          (activate): CustomSiLU(\n",
      "            (sigmoid): QuantizedSigmoid(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0): None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "            (mul): QuantizedMultiply(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0-1): 2 x None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (main_conv): Module(\n",
      "          (conv): QuantizedConv2d(\n",
      "            192, 48, kernel_size=(1, 1), stride=(1, 1)\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (bn): Identity()\n",
      "          (activate): CustomSiLU(\n",
      "            (sigmoid): QuantizedSigmoid(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0): None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "            (mul): QuantizedMultiply(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0-1): 2 x None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (blocks): Module(\n",
      "          (0): Module(\n",
      "            (conv1): Module(\n",
      "              (conv): QuantizedConv2d(\n",
      "                48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "                (param_quantizers): ModuleDict(\n",
      "                  (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "                  (bias): None\n",
      "                )\n",
      "                (input_quantizers): ModuleList(\n",
      "                  (0): None\n",
      "                )\n",
      "                (output_quantizers): ModuleList(\n",
      "                  (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                )\n",
      "              )\n",
      "              (bn): Identity()\n",
      "              (activate): CustomSiLU(\n",
      "                (sigmoid): QuantizedSigmoid(\n",
      "                  (param_quantizers): ModuleDict()\n",
      "                  (input_quantizers): ModuleList(\n",
      "                    (0): None\n",
      "                  )\n",
      "                  (output_quantizers): ModuleList(\n",
      "                    (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                  )\n",
      "                )\n",
      "                (mul): QuantizedMultiply(\n",
      "                  (param_quantizers): ModuleDict()\n",
      "                  (input_quantizers): ModuleList(\n",
      "                    (0-1): 2 x None\n",
      "                  )\n",
      "                  (output_quantizers): ModuleList(\n",
      "                    (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (conv2): Module(\n",
      "              (depthwise_conv): Module(\n",
      "                (conv): QuantizedConv2d(\n",
      "                  48, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=48\n",
      "                  (param_quantizers): ModuleDict(\n",
      "                    (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "                    (bias): None\n",
      "                  )\n",
      "                  (input_quantizers): ModuleList(\n",
      "                    (0): None\n",
      "                  )\n",
      "                  (output_quantizers): ModuleList(\n",
      "                    (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                  )\n",
      "                )\n",
      "                (bn): Identity()\n",
      "                (activate): CustomSiLU(\n",
      "                  (sigmoid): QuantizedSigmoid(\n",
      "                    (param_quantizers): ModuleDict()\n",
      "                    (input_quantizers): ModuleList(\n",
      "                      (0): None\n",
      "                    )\n",
      "                    (output_quantizers): ModuleList(\n",
      "                      (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (mul): QuantizedMultiply(\n",
      "                    (param_quantizers): ModuleDict()\n",
      "                    (input_quantizers): ModuleList(\n",
      "                      (0-1): 2 x None\n",
      "                    )\n",
      "                    (output_quantizers): ModuleList(\n",
      "                      (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                    )\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "              (pointwise_conv): Module(\n",
      "                (conv): QuantizedConv2d(\n",
      "                  48, 48, kernel_size=(1, 1), stride=(1, 1)\n",
      "                  (param_quantizers): ModuleDict(\n",
      "                    (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "                    (bias): None\n",
      "                  )\n",
      "                  (input_quantizers): ModuleList(\n",
      "                    (0): None\n",
      "                  )\n",
      "                  (output_quantizers): ModuleList(\n",
      "                    (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                  )\n",
      "                )\n",
      "                (bn): Identity()\n",
      "                (activate): CustomSiLU(\n",
      "                  (sigmoid): QuantizedSigmoid(\n",
      "                    (param_quantizers): ModuleDict()\n",
      "                    (input_quantizers): ModuleList(\n",
      "                      (0): None\n",
      "                    )\n",
      "                    (output_quantizers): ModuleList(\n",
      "                      (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (mul): QuantizedMultiply(\n",
      "                    (param_quantizers): ModuleDict()\n",
      "                    (input_quantizers): ModuleList(\n",
      "                      (0-1): 2 x None\n",
      "                    )\n",
      "                    (output_quantizers): ModuleList(\n",
      "                      (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                    )\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (final_conv): Module(\n",
      "          (conv): QuantizedConv2d(\n",
      "            96, 96, kernel_size=(1, 1), stride=(1, 1)\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (bn): Identity()\n",
      "          (activate): CustomSiLU(\n",
      "            (sigmoid): QuantizedSigmoid(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0): None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "            (mul): QuantizedMultiply(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0-1): 2 x None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (module_cat_8): FakeQuantizedConcat(\n",
      "          (param_quantizers): ModuleDict()\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (downsamples): Module(\n",
      "      (0): Module(\n",
      "        (conv): QuantizedConv2d(\n",
      "          96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "        (bn): Identity()\n",
      "        (activate): CustomSiLU(\n",
      "          (sigmoid): QuantizedSigmoid(\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (mul): QuantizedMultiply(\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0-1): 2 x None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): Module(\n",
      "        (conv): QuantizedConv2d(\n",
      "          192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "        (bn): Identity()\n",
      "        (activate): CustomSiLU(\n",
      "          (sigmoid): QuantizedSigmoid(\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (mul): QuantizedMultiply(\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0-1): 2 x None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bottom_up_blocks): Module(\n",
      "      (0): Module(\n",
      "        (short_conv): Module(\n",
      "          (conv): QuantizedConv2d(\n",
      "            192, 96, kernel_size=(1, 1), stride=(1, 1)\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (bn): Identity()\n",
      "          (activate): CustomSiLU(\n",
      "            (sigmoid): QuantizedSigmoid(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0): None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "            (mul): QuantizedMultiply(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0-1): 2 x None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (main_conv): Module(\n",
      "          (conv): QuantizedConv2d(\n",
      "            192, 96, kernel_size=(1, 1), stride=(1, 1)\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (bn): Identity()\n",
      "          (activate): CustomSiLU(\n",
      "            (sigmoid): QuantizedSigmoid(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0): None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "            (mul): QuantizedMultiply(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0-1): 2 x None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (blocks): Module(\n",
      "          (0): Module(\n",
      "            (conv1): Module(\n",
      "              (conv): QuantizedConv2d(\n",
      "                96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "                (param_quantizers): ModuleDict(\n",
      "                  (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "                  (bias): None\n",
      "                )\n",
      "                (input_quantizers): ModuleList(\n",
      "                  (0): None\n",
      "                )\n",
      "                (output_quantizers): ModuleList(\n",
      "                  (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                )\n",
      "              )\n",
      "              (bn): Identity()\n",
      "              (activate): CustomSiLU(\n",
      "                (sigmoid): QuantizedSigmoid(\n",
      "                  (param_quantizers): ModuleDict()\n",
      "                  (input_quantizers): ModuleList(\n",
      "                    (0): None\n",
      "                  )\n",
      "                  (output_quantizers): ModuleList(\n",
      "                    (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                  )\n",
      "                )\n",
      "                (mul): QuantizedMultiply(\n",
      "                  (param_quantizers): ModuleDict()\n",
      "                  (input_quantizers): ModuleList(\n",
      "                    (0-1): 2 x None\n",
      "                  )\n",
      "                  (output_quantizers): ModuleList(\n",
      "                    (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (conv2): Module(\n",
      "              (depthwise_conv): Module(\n",
      "                (conv): QuantizedConv2d(\n",
      "                  96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96\n",
      "                  (param_quantizers): ModuleDict(\n",
      "                    (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "                    (bias): None\n",
      "                  )\n",
      "                  (input_quantizers): ModuleList(\n",
      "                    (0): None\n",
      "                  )\n",
      "                  (output_quantizers): ModuleList(\n",
      "                    (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                  )\n",
      "                )\n",
      "                (bn): Identity()\n",
      "                (activate): CustomSiLU(\n",
      "                  (sigmoid): QuantizedSigmoid(\n",
      "                    (param_quantizers): ModuleDict()\n",
      "                    (input_quantizers): ModuleList(\n",
      "                      (0): None\n",
      "                    )\n",
      "                    (output_quantizers): ModuleList(\n",
      "                      (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (mul): QuantizedMultiply(\n",
      "                    (param_quantizers): ModuleDict()\n",
      "                    (input_quantizers): ModuleList(\n",
      "                      (0-1): 2 x None\n",
      "                    )\n",
      "                    (output_quantizers): ModuleList(\n",
      "                      (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                    )\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "              (pointwise_conv): Module(\n",
      "                (conv): QuantizedConv2d(\n",
      "                  96, 96, kernel_size=(1, 1), stride=(1, 1)\n",
      "                  (param_quantizers): ModuleDict(\n",
      "                    (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "                    (bias): None\n",
      "                  )\n",
      "                  (input_quantizers): ModuleList(\n",
      "                    (0): None\n",
      "                  )\n",
      "                  (output_quantizers): ModuleList(\n",
      "                    (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                  )\n",
      "                )\n",
      "                (bn): Identity()\n",
      "                (activate): CustomSiLU(\n",
      "                  (sigmoid): QuantizedSigmoid(\n",
      "                    (param_quantizers): ModuleDict()\n",
      "                    (input_quantizers): ModuleList(\n",
      "                      (0): None\n",
      "                    )\n",
      "                    (output_quantizers): ModuleList(\n",
      "                      (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (mul): QuantizedMultiply(\n",
      "                    (param_quantizers): ModuleDict()\n",
      "                    (input_quantizers): ModuleList(\n",
      "                      (0-1): 2 x None\n",
      "                    )\n",
      "                    (output_quantizers): ModuleList(\n",
      "                      (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                    )\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (final_conv): Module(\n",
      "          (conv): QuantizedConv2d(\n",
      "            192, 192, kernel_size=(1, 1), stride=(1, 1)\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (bn): Identity()\n",
      "          (activate): CustomSiLU(\n",
      "            (sigmoid): QuantizedSigmoid(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0): None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "            (mul): QuantizedMultiply(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0-1): 2 x None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (module_cat_10): FakeQuantizedConcat(\n",
      "          (param_quantizers): ModuleDict()\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): Module(\n",
      "        (short_conv): Module(\n",
      "          (conv): QuantizedConv2d(\n",
      "            384, 192, kernel_size=(1, 1), stride=(1, 1)\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (bn): Identity()\n",
      "          (activate): CustomSiLU(\n",
      "            (sigmoid): QuantizedSigmoid(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0): None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "            (mul): QuantizedMultiply(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0-1): 2 x None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (main_conv): Module(\n",
      "          (conv): QuantizedConv2d(\n",
      "            384, 192, kernel_size=(1, 1), stride=(1, 1)\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (bn): Identity()\n",
      "          (activate): CustomSiLU(\n",
      "            (sigmoid): QuantizedSigmoid(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0): None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "            (mul): QuantizedMultiply(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0-1): 2 x None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (blocks): Module(\n",
      "          (0): Module(\n",
      "            (conv1): Module(\n",
      "              (conv): QuantizedConv2d(\n",
      "                192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "                (param_quantizers): ModuleDict(\n",
      "                  (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "                  (bias): None\n",
      "                )\n",
      "                (input_quantizers): ModuleList(\n",
      "                  (0): None\n",
      "                )\n",
      "                (output_quantizers): ModuleList(\n",
      "                  (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                )\n",
      "              )\n",
      "              (bn): Identity()\n",
      "              (activate): CustomSiLU(\n",
      "                (sigmoid): QuantizedSigmoid(\n",
      "                  (param_quantizers): ModuleDict()\n",
      "                  (input_quantizers): ModuleList(\n",
      "                    (0): None\n",
      "                  )\n",
      "                  (output_quantizers): ModuleList(\n",
      "                    (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                  )\n",
      "                )\n",
      "                (mul): QuantizedMultiply(\n",
      "                  (param_quantizers): ModuleDict()\n",
      "                  (input_quantizers): ModuleList(\n",
      "                    (0-1): 2 x None\n",
      "                  )\n",
      "                  (output_quantizers): ModuleList(\n",
      "                    (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (conv2): Module(\n",
      "              (depthwise_conv): Module(\n",
      "                (conv): QuantizedConv2d(\n",
      "                  192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192\n",
      "                  (param_quantizers): ModuleDict(\n",
      "                    (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "                    (bias): None\n",
      "                  )\n",
      "                  (input_quantizers): ModuleList(\n",
      "                    (0): None\n",
      "                  )\n",
      "                  (output_quantizers): ModuleList(\n",
      "                    (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                  )\n",
      "                )\n",
      "                (bn): Identity()\n",
      "                (activate): CustomSiLU(\n",
      "                  (sigmoid): QuantizedSigmoid(\n",
      "                    (param_quantizers): ModuleDict()\n",
      "                    (input_quantizers): ModuleList(\n",
      "                      (0): None\n",
      "                    )\n",
      "                    (output_quantizers): ModuleList(\n",
      "                      (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (mul): QuantizedMultiply(\n",
      "                    (param_quantizers): ModuleDict()\n",
      "                    (input_quantizers): ModuleList(\n",
      "                      (0-1): 2 x None\n",
      "                    )\n",
      "                    (output_quantizers): ModuleList(\n",
      "                      (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                    )\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "              (pointwise_conv): Module(\n",
      "                (conv): QuantizedConv2d(\n",
      "                  192, 192, kernel_size=(1, 1), stride=(1, 1)\n",
      "                  (param_quantizers): ModuleDict(\n",
      "                    (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "                    (bias): None\n",
      "                  )\n",
      "                  (input_quantizers): ModuleList(\n",
      "                    (0): None\n",
      "                  )\n",
      "                  (output_quantizers): ModuleList(\n",
      "                    (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                  )\n",
      "                )\n",
      "                (bn): Identity()\n",
      "                (activate): CustomSiLU(\n",
      "                  (sigmoid): QuantizedSigmoid(\n",
      "                    (param_quantizers): ModuleDict()\n",
      "                    (input_quantizers): ModuleList(\n",
      "                      (0): None\n",
      "                    )\n",
      "                    (output_quantizers): ModuleList(\n",
      "                      (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (mul): QuantizedMultiply(\n",
      "                    (param_quantizers): ModuleDict()\n",
      "                    (input_quantizers): ModuleList(\n",
      "                      (0-1): 2 x None\n",
      "                    )\n",
      "                    (output_quantizers): ModuleList(\n",
      "                      (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "                    )\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (final_conv): Module(\n",
      "          (conv): QuantizedConv2d(\n",
      "            384, 384, kernel_size=(1, 1), stride=(1, 1)\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (bn): Identity()\n",
      "          (activate): CustomSiLU(\n",
      "            (sigmoid): QuantizedSigmoid(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0): None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "            (mul): QuantizedMultiply(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0-1): 2 x None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (module_cat_12): FakeQuantizedConcat(\n",
      "          (param_quantizers): ModuleDict()\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (out_convs): Module(\n",
      "      (0): Module(\n",
      "        (conv): QuantizedConv2d(\n",
      "          96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "        (bn): Identity()\n",
      "        (activate): CustomSiLU(\n",
      "          (sigmoid): QuantizedSigmoid(\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (mul): QuantizedMultiply(\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0-1): 2 x None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): Module(\n",
      "        (conv): QuantizedConv2d(\n",
      "          192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "        (bn): Identity()\n",
      "        (activate): CustomSiLU(\n",
      "          (sigmoid): QuantizedSigmoid(\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (mul): QuantizedMultiply(\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0-1): 2 x None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): Module(\n",
      "        (conv): QuantizedConv2d(\n",
      "          384, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "        (bn): Identity()\n",
      "        (activate): CustomSiLU(\n",
      "          (sigmoid): QuantizedSigmoid(\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (mul): QuantizedMultiply(\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0-1): 2 x None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (module_cat_5): FakeQuantizedConcat(\n",
      "      (param_quantizers): ModuleDict()\n",
      "      (input_quantizers): ModuleList(\n",
      "        (0): None\n",
      "      )\n",
      "      (output_quantizers): ModuleList(\n",
      "        (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "      )\n",
      "    )\n",
      "    (module_upsample_1): FakeQuantizedUpsample(\n",
      "      scale_factor=2.0, mode='nearest'\n",
      "      (param_quantizers): ModuleDict()\n",
      "      (input_quantizers): ModuleList(\n",
      "        (0): None\n",
      "      )\n",
      "      (output_quantizers): ModuleList(\n",
      "        (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "      )\n",
      "    )\n",
      "    (module_cat_7): FakeQuantizedConcat(\n",
      "      (param_quantizers): ModuleDict()\n",
      "      (input_quantizers): ModuleList(\n",
      "        (0): None\n",
      "      )\n",
      "      (output_quantizers): ModuleList(\n",
      "        (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "      )\n",
      "    )\n",
      "    (module_cat_9): FakeQuantizedConcat(\n",
      "      (param_quantizers): ModuleDict()\n",
      "      (input_quantizers): ModuleList(\n",
      "        (0): None\n",
      "      )\n",
      "      (output_quantizers): ModuleList(\n",
      "        (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "      )\n",
      "    )\n",
      "    (module_cat_11): FakeQuantizedConcat(\n",
      "      (param_quantizers): ModuleDict()\n",
      "      (input_quantizers): ModuleList(\n",
      "        (0): None\n",
      "      )\n",
      "      (output_quantizers): ModuleList(\n",
      "        (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (bbox_head): Module(\n",
      "    (cls_convs): Module(\n",
      "      (0): Module(\n",
      "        (0): Module(\n",
      "          (conv): QuantizedConv2d(\n",
      "            96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (bn): Identity()\n",
      "          (activate): CustomSiLU(\n",
      "            (sigmoid): QuantizedSigmoid(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0): None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "            (mul): QuantizedMultiply(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0-1): 2 x None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (module_conv_1): QuantizedConv2d(\n",
      "            96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (module_conv_2): QuantizedConv2d(\n",
      "            96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Module(\n",
      "          (conv): QuantizedConv2d(\n",
      "            96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (bn): Identity()\n",
      "          (activate): CustomSiLU(\n",
      "            (sigmoid): QuantizedSigmoid(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0): None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "            (mul): QuantizedMultiply(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0-1): 2 x None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (module_conv_1): QuantizedConv2d(\n",
      "            96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (module_conv_2): QuantizedConv2d(\n",
      "            96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): Module(\n",
      "        (0): Module(\n",
      "          (bn): Identity()\n",
      "          (activate): CustomSiLU(\n",
      "            (sigmoid): QuantizedSigmoid(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0): None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "            (mul): QuantizedMultiply(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0-1): 2 x None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Module(\n",
      "          (bn): Identity()\n",
      "          (activate): CustomSiLU(\n",
      "            (sigmoid): QuantizedSigmoid(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0): None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "            (mul): QuantizedMultiply(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0-1): 2 x None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): Module(\n",
      "        (0): Module(\n",
      "          (bn): Identity()\n",
      "          (activate): CustomSiLU(\n",
      "            (sigmoid): QuantizedSigmoid(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0): None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "            (mul): QuantizedMultiply(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0-1): 2 x None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Module(\n",
      "          (bn): Identity()\n",
      "          (activate): CustomSiLU(\n",
      "            (sigmoid): QuantizedSigmoid(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0): None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "            (mul): QuantizedMultiply(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0-1): 2 x None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (rtm_cls): Module(\n",
      "      (0): QuantizedConv2d(\n",
      "        96, 80, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (param_quantizers): ModuleDict(\n",
      "          (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "          (bias): None\n",
      "        )\n",
      "        (input_quantizers): ModuleList(\n",
      "          (0): None\n",
      "        )\n",
      "        (output_quantizers): ModuleList(\n",
      "          (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "        )\n",
      "      )\n",
      "      (1): QuantizedConv2d(\n",
      "        96, 80, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (param_quantizers): ModuleDict(\n",
      "          (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "          (bias): None\n",
      "        )\n",
      "        (input_quantizers): ModuleList(\n",
      "          (0): None\n",
      "        )\n",
      "        (output_quantizers): ModuleList(\n",
      "          (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "        )\n",
      "      )\n",
      "      (2): QuantizedConv2d(\n",
      "        96, 80, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (param_quantizers): ModuleDict(\n",
      "          (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "          (bias): None\n",
      "        )\n",
      "        (input_quantizers): ModuleList(\n",
      "          (0): None\n",
      "        )\n",
      "        (output_quantizers): ModuleList(\n",
      "          (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (reg_convs): Module(\n",
      "      (0): Module(\n",
      "        (0): Module(\n",
      "          (conv): QuantizedConv2d(\n",
      "            96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (bn): Identity()\n",
      "          (activate): CustomSiLU(\n",
      "            (sigmoid): QuantizedSigmoid(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0): None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "            (mul): QuantizedMultiply(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0-1): 2 x None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (module_conv_1): QuantizedConv2d(\n",
      "            96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (module_conv_2): QuantizedConv2d(\n",
      "            96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Module(\n",
      "          (conv): QuantizedConv2d(\n",
      "            96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (bn): Identity()\n",
      "          (activate): CustomSiLU(\n",
      "            (sigmoid): QuantizedSigmoid(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0): None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "            (mul): QuantizedMultiply(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0-1): 2 x None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (module_conv_1): QuantizedConv2d(\n",
      "            96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "          (module_conv_2): QuantizedConv2d(\n",
      "            96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): Module(\n",
      "        (0): Module(\n",
      "          (bn): Identity()\n",
      "          (activate): CustomSiLU(\n",
      "            (sigmoid): QuantizedSigmoid(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0): None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "            (mul): QuantizedMultiply(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0-1): 2 x None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Module(\n",
      "          (bn): Identity()\n",
      "          (activate): CustomSiLU(\n",
      "            (sigmoid): QuantizedSigmoid(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0): None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "            (mul): QuantizedMultiply(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0-1): 2 x None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): Module(\n",
      "        (0): Module(\n",
      "          (bn): Identity()\n",
      "          (activate): CustomSiLU(\n",
      "            (sigmoid): QuantizedSigmoid(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0): None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "            (mul): QuantizedMultiply(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0-1): 2 x None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Module(\n",
      "          (bn): Identity()\n",
      "          (activate): CustomSiLU(\n",
      "            (sigmoid): QuantizedSigmoid(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0): None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "            (mul): QuantizedMultiply(\n",
      "              (param_quantizers): ModuleDict()\n",
      "              (input_quantizers): ModuleList(\n",
      "                (0-1): 2 x None\n",
      "              )\n",
      "              (output_quantizers): ModuleList(\n",
      "                (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (rtm_reg): Module(\n",
      "      (0): QuantizedConv2d(\n",
      "        96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (param_quantizers): ModuleDict(\n",
      "          (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "          (bias): None\n",
      "        )\n",
      "        (input_quantizers): ModuleList(\n",
      "          (0): None\n",
      "        )\n",
      "        (output_quantizers): ModuleList(\n",
      "          (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "        )\n",
      "      )\n",
      "      (1): QuantizedConv2d(\n",
      "        96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (param_quantizers): ModuleDict(\n",
      "          (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "          (bias): None\n",
      "        )\n",
      "        (input_quantizers): ModuleList(\n",
      "          (0): None\n",
      "        )\n",
      "        (output_quantizers): ModuleList(\n",
      "          (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "        )\n",
      "      )\n",
      "      (2): QuantizedConv2d(\n",
      "        96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (param_quantizers): ModuleDict(\n",
      "          (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)\n",
      "          (bias): None\n",
      "        )\n",
      "        (input_quantizers): ModuleList(\n",
      "          (0): None\n",
      "        )\n",
      "        (output_quantizers): ModuleList(\n",
      "          (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (module_mul_4): QuantizedMultiply(\n",
      "      (param_quantizers): ModuleDict()\n",
      "      (input_quantizers): ModuleList(\n",
      "        (0): None\n",
      "        (1): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "      )\n",
      "      (output_quantizers): ModuleList(\n",
      "        (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "      )\n",
      "    )\n",
      "    (module_mul_5): QuantizedMultiply(\n",
      "      (param_quantizers): ModuleDict()\n",
      "      (input_quantizers): ModuleList(\n",
      "        (0): None\n",
      "        (1): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "      )\n",
      "      (output_quantizers): ModuleList(\n",
      "        (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "      )\n",
      "    )\n",
      "    (module_mul_6): QuantizedMultiply(\n",
      "      (param_quantizers): ModuleDict()\n",
      "      (input_quantizers): ModuleList(\n",
      "        (0): None\n",
      "        (1): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "      )\n",
      "      (output_quantizers): ModuleList(\n",
      "        (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, inputs : torch.Tensor, data_samples : typing_Union[typing_List[mmdet_structures_det_data_sample_DetDataSample],NoneType] = None, mode : str = 'tensor') -> typing_Union[typing_Dict[str,torch.Tensor],typing_List[mmdet_structures_det_data_sample_DetDataSample],typing_Tuple[torch.Tensor],torch.Tensor]:\n",
      "    backbone_stem_0_conv = getattr(self.backbone.stem, \"0\").conv(inputs);  inputs = None\n",
      "    backbone_stem_0_bn = getattr(self.backbone.stem, \"0\").bn(backbone_stem_0_conv);  backbone_stem_0_conv = None\n",
      "    backbone_stem_0_activate = getattr(self.backbone.stem, \"0\").activate(backbone_stem_0_bn);  backbone_stem_0_bn = None\n",
      "    backbone_stem_1_conv = getattr(self.backbone.stem, \"1\").conv(backbone_stem_0_activate);  backbone_stem_0_activate = None\n",
      "    backbone_stem_1_bn = getattr(self.backbone.stem, \"1\").bn(backbone_stem_1_conv);  backbone_stem_1_conv = None\n",
      "    backbone_stem_1_activate = getattr(self.backbone.stem, \"1\").activate(backbone_stem_1_bn);  backbone_stem_1_bn = None\n",
      "    backbone_stem_2_conv = getattr(self.backbone.stem, \"2\").conv(backbone_stem_1_activate);  backbone_stem_1_activate = None\n",
      "    backbone_stem_2_bn = getattr(self.backbone.stem, \"2\").bn(backbone_stem_2_conv);  backbone_stem_2_conv = None\n",
      "    backbone_stem_2_activate = getattr(self.backbone.stem, \"2\").activate(backbone_stem_2_bn);  backbone_stem_2_bn = None\n",
      "    backbone_stage1_0_conv = getattr(self.backbone.stage1, \"0\").conv(backbone_stem_2_activate);  backbone_stem_2_activate = None\n",
      "    backbone_stage1_0_bn = getattr(self.backbone.stage1, \"0\").bn(backbone_stage1_0_conv);  backbone_stage1_0_conv = None\n",
      "    backbone_stage1_0_activate = getattr(self.backbone.stage1, \"0\").activate(backbone_stage1_0_bn);  backbone_stage1_0_bn = None\n",
      "    backbone_stage1_1_short_conv_conv = getattr(self.backbone.stage1, \"1\").short_conv.conv(backbone_stage1_0_activate)\n",
      "    backbone_stage1_1_short_conv_bn = getattr(self.backbone.stage1, \"1\").short_conv.bn(backbone_stage1_1_short_conv_conv);  backbone_stage1_1_short_conv_conv = None\n",
      "    backbone_stage1_1_short_conv_activate = getattr(self.backbone.stage1, \"1\").short_conv.activate(backbone_stage1_1_short_conv_bn);  backbone_stage1_1_short_conv_bn = None\n",
      "    backbone_stage1_1_main_conv_conv = getattr(self.backbone.stage1, \"1\").main_conv.conv(backbone_stage1_0_activate);  backbone_stage1_0_activate = None\n",
      "    backbone_stage1_1_main_conv_bn = getattr(self.backbone.stage1, \"1\").main_conv.bn(backbone_stage1_1_main_conv_conv);  backbone_stage1_1_main_conv_conv = None\n",
      "    backbone_stage1_1_main_conv_activate = getattr(self.backbone.stage1, \"1\").main_conv.activate(backbone_stage1_1_main_conv_bn);  backbone_stage1_1_main_conv_bn = None\n",
      "    backbone_stage1_1_blocks_0_conv1_conv = getattr(getattr(self.backbone.stage1, \"1\").blocks, \"0\").conv1.conv(backbone_stage1_1_main_conv_activate)\n",
      "    backbone_stage1_1_blocks_0_conv1_bn = getattr(getattr(self.backbone.stage1, \"1\").blocks, \"0\").conv1.bn(backbone_stage1_1_blocks_0_conv1_conv);  backbone_stage1_1_blocks_0_conv1_conv = None\n",
      "    backbone_stage1_1_blocks_0_conv1_activate = getattr(getattr(self.backbone.stage1, \"1\").blocks, \"0\").conv1.activate(backbone_stage1_1_blocks_0_conv1_bn);  backbone_stage1_1_blocks_0_conv1_bn = None\n",
      "    backbone_stage1_1_blocks_0_conv2_depthwise_conv_conv = getattr(getattr(self.backbone.stage1, \"1\").blocks, \"0\").conv2.depthwise_conv.conv(backbone_stage1_1_blocks_0_conv1_activate);  backbone_stage1_1_blocks_0_conv1_activate = None\n",
      "    backbone_stage1_1_blocks_0_conv2_depthwise_conv_bn = getattr(getattr(self.backbone.stage1, \"1\").blocks, \"0\").conv2.depthwise_conv.bn(backbone_stage1_1_blocks_0_conv2_depthwise_conv_conv);  backbone_stage1_1_blocks_0_conv2_depthwise_conv_conv = None\n",
      "    backbone_stage1_1_blocks_0_conv2_depthwise_conv_activate = getattr(getattr(self.backbone.stage1, \"1\").blocks, \"0\").conv2.depthwise_conv.activate(backbone_stage1_1_blocks_0_conv2_depthwise_conv_bn);  backbone_stage1_1_blocks_0_conv2_depthwise_conv_bn = None\n",
      "    backbone_stage1_1_blocks_0_conv2_pointwise_conv_conv = getattr(getattr(self.backbone.stage1, \"1\").blocks, \"0\").conv2.pointwise_conv.conv(backbone_stage1_1_blocks_0_conv2_depthwise_conv_activate);  backbone_stage1_1_blocks_0_conv2_depthwise_conv_activate = None\n",
      "    backbone_stage1_1_blocks_0_conv2_pointwise_conv_bn = getattr(getattr(self.backbone.stage1, \"1\").blocks, \"0\").conv2.pointwise_conv.bn(backbone_stage1_1_blocks_0_conv2_pointwise_conv_conv);  backbone_stage1_1_blocks_0_conv2_pointwise_conv_conv = None\n",
      "    backbone_stage1_1_blocks_0_conv2_pointwise_conv_activate = getattr(getattr(self.backbone.stage1, \"1\").blocks, \"0\").conv2.pointwise_conv.activate(backbone_stage1_1_blocks_0_conv2_pointwise_conv_bn);  backbone_stage1_1_blocks_0_conv2_pointwise_conv_bn = None\n",
      "    backbone_stage1_1_blocks_0_module_add = getattr(getattr(self.backbone.stage1, \"1\").blocks, \"0\").module_add(backbone_stage1_1_blocks_0_conv2_pointwise_conv_activate, backbone_stage1_1_main_conv_activate);  backbone_stage1_1_blocks_0_conv2_pointwise_conv_activate = backbone_stage1_1_main_conv_activate = None\n",
      "    backbone_stage1_1_module_cat = getattr(self.backbone.stage1, \"1\").module_cat(backbone_stage1_1_blocks_0_module_add, backbone_stage1_1_short_conv_activate);  backbone_stage1_1_blocks_0_module_add = backbone_stage1_1_short_conv_activate = None\n",
      "    backbone_stage1_1_attention_global_avgpool = getattr(self.backbone.stage1, \"1\").attention.global_avgpool(backbone_stage1_1_module_cat)\n",
      "    backbone_stage1_1_attention_fc = getattr(self.backbone.stage1, \"1\").attention.fc(backbone_stage1_1_attention_global_avgpool);  backbone_stage1_1_attention_global_avgpool = None\n",
      "    backbone_stage1_1_attention_act = getattr(self.backbone.stage1, \"1\").attention.act(backbone_stage1_1_attention_fc);  backbone_stage1_1_attention_fc = None\n",
      "    backbone_stage1_1_attention_module_mul = getattr(self.backbone.stage1, \"1\").attention.module_mul(backbone_stage1_1_module_cat, backbone_stage1_1_attention_act);  backbone_stage1_1_module_cat = backbone_stage1_1_attention_act = None\n",
      "    backbone_stage1_1_final_conv_conv = getattr(self.backbone.stage1, \"1\").final_conv.conv(backbone_stage1_1_attention_module_mul);  backbone_stage1_1_attention_module_mul = None\n",
      "    backbone_stage1_1_final_conv_bn = getattr(self.backbone.stage1, \"1\").final_conv.bn(backbone_stage1_1_final_conv_conv);  backbone_stage1_1_final_conv_conv = None\n",
      "    backbone_stage1_1_final_conv_activate = getattr(self.backbone.stage1, \"1\").final_conv.activate(backbone_stage1_1_final_conv_bn);  backbone_stage1_1_final_conv_bn = None\n",
      "    backbone_stage2_0_conv = getattr(self.backbone.stage2, \"0\").conv(backbone_stage1_1_final_conv_activate);  backbone_stage1_1_final_conv_activate = None\n",
      "    backbone_stage2_0_bn = getattr(self.backbone.stage2, \"0\").bn(backbone_stage2_0_conv);  backbone_stage2_0_conv = None\n",
      "    backbone_stage2_0_activate = getattr(self.backbone.stage2, \"0\").activate(backbone_stage2_0_bn);  backbone_stage2_0_bn = None\n",
      "    backbone_stage2_1_short_conv_conv = getattr(self.backbone.stage2, \"1\").short_conv.conv(backbone_stage2_0_activate)\n",
      "    backbone_stage2_1_short_conv_bn = getattr(self.backbone.stage2, \"1\").short_conv.bn(backbone_stage2_1_short_conv_conv);  backbone_stage2_1_short_conv_conv = None\n",
      "    backbone_stage2_1_short_conv_activate = getattr(self.backbone.stage2, \"1\").short_conv.activate(backbone_stage2_1_short_conv_bn);  backbone_stage2_1_short_conv_bn = None\n",
      "    backbone_stage2_1_main_conv_conv = getattr(self.backbone.stage2, \"1\").main_conv.conv(backbone_stage2_0_activate);  backbone_stage2_0_activate = None\n",
      "    backbone_stage2_1_main_conv_bn = getattr(self.backbone.stage2, \"1\").main_conv.bn(backbone_stage2_1_main_conv_conv);  backbone_stage2_1_main_conv_conv = None\n",
      "    backbone_stage2_1_main_conv_activate = getattr(self.backbone.stage2, \"1\").main_conv.activate(backbone_stage2_1_main_conv_bn);  backbone_stage2_1_main_conv_bn = None\n",
      "    backbone_stage2_1_blocks_0_conv1_conv = getattr(getattr(self.backbone.stage2, \"1\").blocks, \"0\").conv1.conv(backbone_stage2_1_main_conv_activate)\n",
      "    backbone_stage2_1_blocks_0_conv1_bn = getattr(getattr(self.backbone.stage2, \"1\").blocks, \"0\").conv1.bn(backbone_stage2_1_blocks_0_conv1_conv);  backbone_stage2_1_blocks_0_conv1_conv = None\n",
      "    backbone_stage2_1_blocks_0_conv1_activate = getattr(getattr(self.backbone.stage2, \"1\").blocks, \"0\").conv1.activate(backbone_stage2_1_blocks_0_conv1_bn);  backbone_stage2_1_blocks_0_conv1_bn = None\n",
      "    backbone_stage2_1_blocks_0_conv2_depthwise_conv_conv = getattr(getattr(self.backbone.stage2, \"1\").blocks, \"0\").conv2.depthwise_conv.conv(backbone_stage2_1_blocks_0_conv1_activate);  backbone_stage2_1_blocks_0_conv1_activate = None\n",
      "    backbone_stage2_1_blocks_0_conv2_depthwise_conv_bn = getattr(getattr(self.backbone.stage2, \"1\").blocks, \"0\").conv2.depthwise_conv.bn(backbone_stage2_1_blocks_0_conv2_depthwise_conv_conv);  backbone_stage2_1_blocks_0_conv2_depthwise_conv_conv = None\n",
      "    backbone_stage2_1_blocks_0_conv2_depthwise_conv_activate = getattr(getattr(self.backbone.stage2, \"1\").blocks, \"0\").conv2.depthwise_conv.activate(backbone_stage2_1_blocks_0_conv2_depthwise_conv_bn);  backbone_stage2_1_blocks_0_conv2_depthwise_conv_bn = None\n",
      "    backbone_stage2_1_blocks_0_conv2_pointwise_conv_conv = getattr(getattr(self.backbone.stage2, \"1\").blocks, \"0\").conv2.pointwise_conv.conv(backbone_stage2_1_blocks_0_conv2_depthwise_conv_activate);  backbone_stage2_1_blocks_0_conv2_depthwise_conv_activate = None\n",
      "    backbone_stage2_1_blocks_0_conv2_pointwise_conv_bn = getattr(getattr(self.backbone.stage2, \"1\").blocks, \"0\").conv2.pointwise_conv.bn(backbone_stage2_1_blocks_0_conv2_pointwise_conv_conv);  backbone_stage2_1_blocks_0_conv2_pointwise_conv_conv = None\n",
      "    backbone_stage2_1_blocks_0_conv2_pointwise_conv_activate = getattr(getattr(self.backbone.stage2, \"1\").blocks, \"0\").conv2.pointwise_conv.activate(backbone_stage2_1_blocks_0_conv2_pointwise_conv_bn);  backbone_stage2_1_blocks_0_conv2_pointwise_conv_bn = None\n",
      "    backbone_stage2_1_blocks_0_module_add_1 = getattr(getattr(self.backbone.stage2, \"1\").blocks, \"0\").module_add_1(backbone_stage2_1_blocks_0_conv2_pointwise_conv_activate, backbone_stage2_1_main_conv_activate);  backbone_stage2_1_blocks_0_conv2_pointwise_conv_activate = backbone_stage2_1_main_conv_activate = None\n",
      "    backbone_stage2_1_module_cat_1 = getattr(self.backbone.stage2, \"1\").module_cat_1(backbone_stage2_1_blocks_0_module_add_1, backbone_stage2_1_short_conv_activate);  backbone_stage2_1_blocks_0_module_add_1 = backbone_stage2_1_short_conv_activate = None\n",
      "    backbone_stage2_1_attention_global_avgpool = getattr(self.backbone.stage2, \"1\").attention.global_avgpool(backbone_stage2_1_module_cat_1)\n",
      "    backbone_stage2_1_attention_fc = getattr(self.backbone.stage2, \"1\").attention.fc(backbone_stage2_1_attention_global_avgpool);  backbone_stage2_1_attention_global_avgpool = None\n",
      "    backbone_stage2_1_attention_act = getattr(self.backbone.stage2, \"1\").attention.act(backbone_stage2_1_attention_fc);  backbone_stage2_1_attention_fc = None\n",
      "    backbone_stage2_1_attention_module_mul_1 = getattr(self.backbone.stage2, \"1\").attention.module_mul_1(backbone_stage2_1_module_cat_1, backbone_stage2_1_attention_act);  backbone_stage2_1_module_cat_1 = backbone_stage2_1_attention_act = None\n",
      "    backbone_stage2_1_final_conv_conv = getattr(self.backbone.stage2, \"1\").final_conv.conv(backbone_stage2_1_attention_module_mul_1);  backbone_stage2_1_attention_module_mul_1 = None\n",
      "    backbone_stage2_1_final_conv_bn = getattr(self.backbone.stage2, \"1\").final_conv.bn(backbone_stage2_1_final_conv_conv);  backbone_stage2_1_final_conv_conv = None\n",
      "    backbone_stage2_1_final_conv_activate = getattr(self.backbone.stage2, \"1\").final_conv.activate(backbone_stage2_1_final_conv_bn);  backbone_stage2_1_final_conv_bn = None\n",
      "    backbone_stage3_0_conv = getattr(self.backbone.stage3, \"0\").conv(backbone_stage2_1_final_conv_activate)\n",
      "    backbone_stage3_0_bn = getattr(self.backbone.stage3, \"0\").bn(backbone_stage3_0_conv);  backbone_stage3_0_conv = None\n",
      "    backbone_stage3_0_activate = getattr(self.backbone.stage3, \"0\").activate(backbone_stage3_0_bn);  backbone_stage3_0_bn = None\n",
      "    backbone_stage3_1_short_conv_conv = getattr(self.backbone.stage3, \"1\").short_conv.conv(backbone_stage3_0_activate)\n",
      "    backbone_stage3_1_short_conv_bn = getattr(self.backbone.stage3, \"1\").short_conv.bn(backbone_stage3_1_short_conv_conv);  backbone_stage3_1_short_conv_conv = None\n",
      "    backbone_stage3_1_short_conv_activate = getattr(self.backbone.stage3, \"1\").short_conv.activate(backbone_stage3_1_short_conv_bn);  backbone_stage3_1_short_conv_bn = None\n",
      "    backbone_stage3_1_main_conv_conv = getattr(self.backbone.stage3, \"1\").main_conv.conv(backbone_stage3_0_activate);  backbone_stage3_0_activate = None\n",
      "    backbone_stage3_1_main_conv_bn = getattr(self.backbone.stage3, \"1\").main_conv.bn(backbone_stage3_1_main_conv_conv);  backbone_stage3_1_main_conv_conv = None\n",
      "    backbone_stage3_1_main_conv_activate = getattr(self.backbone.stage3, \"1\").main_conv.activate(backbone_stage3_1_main_conv_bn);  backbone_stage3_1_main_conv_bn = None\n",
      "    backbone_stage3_1_blocks_0_conv1_conv = getattr(getattr(self.backbone.stage3, \"1\").blocks, \"0\").conv1.conv(backbone_stage3_1_main_conv_activate)\n",
      "    backbone_stage3_1_blocks_0_conv1_bn = getattr(getattr(self.backbone.stage3, \"1\").blocks, \"0\").conv1.bn(backbone_stage3_1_blocks_0_conv1_conv);  backbone_stage3_1_blocks_0_conv1_conv = None\n",
      "    backbone_stage3_1_blocks_0_conv1_activate = getattr(getattr(self.backbone.stage3, \"1\").blocks, \"0\").conv1.activate(backbone_stage3_1_blocks_0_conv1_bn);  backbone_stage3_1_blocks_0_conv1_bn = None\n",
      "    backbone_stage3_1_blocks_0_conv2_depthwise_conv_conv = getattr(getattr(self.backbone.stage3, \"1\").blocks, \"0\").conv2.depthwise_conv.conv(backbone_stage3_1_blocks_0_conv1_activate);  backbone_stage3_1_blocks_0_conv1_activate = None\n",
      "    backbone_stage3_1_blocks_0_conv2_depthwise_conv_bn = getattr(getattr(self.backbone.stage3, \"1\").blocks, \"0\").conv2.depthwise_conv.bn(backbone_stage3_1_blocks_0_conv2_depthwise_conv_conv);  backbone_stage3_1_blocks_0_conv2_depthwise_conv_conv = None\n",
      "    backbone_stage3_1_blocks_0_conv2_depthwise_conv_activate = getattr(getattr(self.backbone.stage3, \"1\").blocks, \"0\").conv2.depthwise_conv.activate(backbone_stage3_1_blocks_0_conv2_depthwise_conv_bn);  backbone_stage3_1_blocks_0_conv2_depthwise_conv_bn = None\n",
      "    backbone_stage3_1_blocks_0_conv2_pointwise_conv_conv = getattr(getattr(self.backbone.stage3, \"1\").blocks, \"0\").conv2.pointwise_conv.conv(backbone_stage3_1_blocks_0_conv2_depthwise_conv_activate);  backbone_stage3_1_blocks_0_conv2_depthwise_conv_activate = None\n",
      "    backbone_stage3_1_blocks_0_conv2_pointwise_conv_bn = getattr(getattr(self.backbone.stage3, \"1\").blocks, \"0\").conv2.pointwise_conv.bn(backbone_stage3_1_blocks_0_conv2_pointwise_conv_conv);  backbone_stage3_1_blocks_0_conv2_pointwise_conv_conv = None\n",
      "    backbone_stage3_1_blocks_0_conv2_pointwise_conv_activate = getattr(getattr(self.backbone.stage3, \"1\").blocks, \"0\").conv2.pointwise_conv.activate(backbone_stage3_1_blocks_0_conv2_pointwise_conv_bn);  backbone_stage3_1_blocks_0_conv2_pointwise_conv_bn = None\n",
      "    backbone_stage3_1_blocks_0_module_add_2 = getattr(getattr(self.backbone.stage3, \"1\").blocks, \"0\").module_add_2(backbone_stage3_1_blocks_0_conv2_pointwise_conv_activate, backbone_stage3_1_main_conv_activate);  backbone_stage3_1_blocks_0_conv2_pointwise_conv_activate = backbone_stage3_1_main_conv_activate = None\n",
      "    backbone_stage3_1_module_cat_2 = getattr(self.backbone.stage3, \"1\").module_cat_2(backbone_stage3_1_blocks_0_module_add_2, backbone_stage3_1_short_conv_activate);  backbone_stage3_1_blocks_0_module_add_2 = backbone_stage3_1_short_conv_activate = None\n",
      "    backbone_stage3_1_attention_global_avgpool = getattr(self.backbone.stage3, \"1\").attention.global_avgpool(backbone_stage3_1_module_cat_2)\n",
      "    backbone_stage3_1_attention_fc = getattr(self.backbone.stage3, \"1\").attention.fc(backbone_stage3_1_attention_global_avgpool);  backbone_stage3_1_attention_global_avgpool = None\n",
      "    backbone_stage3_1_attention_act = getattr(self.backbone.stage3, \"1\").attention.act(backbone_stage3_1_attention_fc);  backbone_stage3_1_attention_fc = None\n",
      "    backbone_stage3_1_attention_module_mul_2 = getattr(self.backbone.stage3, \"1\").attention.module_mul_2(backbone_stage3_1_module_cat_2, backbone_stage3_1_attention_act);  backbone_stage3_1_module_cat_2 = backbone_stage3_1_attention_act = None\n",
      "    backbone_stage3_1_final_conv_conv = getattr(self.backbone.stage3, \"1\").final_conv.conv(backbone_stage3_1_attention_module_mul_2);  backbone_stage3_1_attention_module_mul_2 = None\n",
      "    backbone_stage3_1_final_conv_bn = getattr(self.backbone.stage3, \"1\").final_conv.bn(backbone_stage3_1_final_conv_conv);  backbone_stage3_1_final_conv_conv = None\n",
      "    backbone_stage3_1_final_conv_activate = getattr(self.backbone.stage3, \"1\").final_conv.activate(backbone_stage3_1_final_conv_bn);  backbone_stage3_1_final_conv_bn = None\n",
      "    backbone_stage4_0_conv = getattr(self.backbone.stage4, \"0\").conv(backbone_stage3_1_final_conv_activate)\n",
      "    backbone_stage4_0_bn = getattr(self.backbone.stage4, \"0\").bn(backbone_stage4_0_conv);  backbone_stage4_0_conv = None\n",
      "    backbone_stage4_0_activate = getattr(self.backbone.stage4, \"0\").activate(backbone_stage4_0_bn);  backbone_stage4_0_bn = None\n",
      "    backbone_stage4_1_conv1_conv = getattr(self.backbone.stage4, \"1\").conv1.conv(backbone_stage4_0_activate);  backbone_stage4_0_activate = None\n",
      "    backbone_stage4_1_conv1_bn = getattr(self.backbone.stage4, \"1\").conv1.bn(backbone_stage4_1_conv1_conv);  backbone_stage4_1_conv1_conv = None\n",
      "    backbone_stage4_1_conv1_activate = getattr(self.backbone.stage4, \"1\").conv1.activate(backbone_stage4_1_conv1_bn);  backbone_stage4_1_conv1_bn = None\n",
      "    backbone_stage4_1_poolings_0 = getattr(getattr(self.backbone.stage4, \"1\").poolings, \"0\")(backbone_stage4_1_conv1_activate)\n",
      "    backbone_stage4_1_poolings_1 = getattr(getattr(self.backbone.stage4, \"1\").poolings, \"1\")(backbone_stage4_1_conv1_activate)\n",
      "    backbone_stage4_1_poolings_2 = getattr(getattr(self.backbone.stage4, \"1\").poolings, \"2\")(backbone_stage4_1_conv1_activate)\n",
      "    backbone_stage4_1_module_cat_3 = getattr(self.backbone.stage4, \"1\").module_cat_3(backbone_stage4_1_conv1_activate, backbone_stage4_1_poolings_0, backbone_stage4_1_poolings_1, backbone_stage4_1_poolings_2);  backbone_stage4_1_conv1_activate = backbone_stage4_1_poolings_0 = backbone_stage4_1_poolings_1 = backbone_stage4_1_poolings_2 = None\n",
      "    backbone_stage4_1_conv2_conv = getattr(self.backbone.stage4, \"1\").conv2.conv(backbone_stage4_1_module_cat_3);  backbone_stage4_1_module_cat_3 = None\n",
      "    backbone_stage4_1_conv2_bn = getattr(self.backbone.stage4, \"1\").conv2.bn(backbone_stage4_1_conv2_conv);  backbone_stage4_1_conv2_conv = None\n",
      "    backbone_stage4_1_conv2_activate = getattr(self.backbone.stage4, \"1\").conv2.activate(backbone_stage4_1_conv2_bn);  backbone_stage4_1_conv2_bn = None\n",
      "    backbone_stage4_2_short_conv_conv = getattr(self.backbone.stage4, \"2\").short_conv.conv(backbone_stage4_1_conv2_activate)\n",
      "    backbone_stage4_2_short_conv_bn = getattr(self.backbone.stage4, \"2\").short_conv.bn(backbone_stage4_2_short_conv_conv);  backbone_stage4_2_short_conv_conv = None\n",
      "    backbone_stage4_2_short_conv_activate = getattr(self.backbone.stage4, \"2\").short_conv.activate(backbone_stage4_2_short_conv_bn);  backbone_stage4_2_short_conv_bn = None\n",
      "    backbone_stage4_2_main_conv_conv = getattr(self.backbone.stage4, \"2\").main_conv.conv(backbone_stage4_1_conv2_activate);  backbone_stage4_1_conv2_activate = None\n",
      "    backbone_stage4_2_main_conv_bn = getattr(self.backbone.stage4, \"2\").main_conv.bn(backbone_stage4_2_main_conv_conv);  backbone_stage4_2_main_conv_conv = None\n",
      "    backbone_stage4_2_main_conv_activate = getattr(self.backbone.stage4, \"2\").main_conv.activate(backbone_stage4_2_main_conv_bn);  backbone_stage4_2_main_conv_bn = None\n",
      "    backbone_stage4_2_blocks_0_conv1_conv = getattr(getattr(self.backbone.stage4, \"2\").blocks, \"0\").conv1.conv(backbone_stage4_2_main_conv_activate);  backbone_stage4_2_main_conv_activate = None\n",
      "    backbone_stage4_2_blocks_0_conv1_bn = getattr(getattr(self.backbone.stage4, \"2\").blocks, \"0\").conv1.bn(backbone_stage4_2_blocks_0_conv1_conv);  backbone_stage4_2_blocks_0_conv1_conv = None\n",
      "    backbone_stage4_2_blocks_0_conv1_activate = getattr(getattr(self.backbone.stage4, \"2\").blocks, \"0\").conv1.activate(backbone_stage4_2_blocks_0_conv1_bn);  backbone_stage4_2_blocks_0_conv1_bn = None\n",
      "    backbone_stage4_2_blocks_0_conv2_depthwise_conv_conv = getattr(getattr(self.backbone.stage4, \"2\").blocks, \"0\").conv2.depthwise_conv.conv(backbone_stage4_2_blocks_0_conv1_activate);  backbone_stage4_2_blocks_0_conv1_activate = None\n",
      "    backbone_stage4_2_blocks_0_conv2_depthwise_conv_bn = getattr(getattr(self.backbone.stage4, \"2\").blocks, \"0\").conv2.depthwise_conv.bn(backbone_stage4_2_blocks_0_conv2_depthwise_conv_conv);  backbone_stage4_2_blocks_0_conv2_depthwise_conv_conv = None\n",
      "    backbone_stage4_2_blocks_0_conv2_depthwise_conv_activate = getattr(getattr(self.backbone.stage4, \"2\").blocks, \"0\").conv2.depthwise_conv.activate(backbone_stage4_2_blocks_0_conv2_depthwise_conv_bn);  backbone_stage4_2_blocks_0_conv2_depthwise_conv_bn = None\n",
      "    backbone_stage4_2_blocks_0_conv2_pointwise_conv_conv = getattr(getattr(self.backbone.stage4, \"2\").blocks, \"0\").conv2.pointwise_conv.conv(backbone_stage4_2_blocks_0_conv2_depthwise_conv_activate);  backbone_stage4_2_blocks_0_conv2_depthwise_conv_activate = None\n",
      "    backbone_stage4_2_blocks_0_conv2_pointwise_conv_bn = getattr(getattr(self.backbone.stage4, \"2\").blocks, \"0\").conv2.pointwise_conv.bn(backbone_stage4_2_blocks_0_conv2_pointwise_conv_conv);  backbone_stage4_2_blocks_0_conv2_pointwise_conv_conv = None\n",
      "    backbone_stage4_2_blocks_0_conv2_pointwise_conv_activate = getattr(getattr(self.backbone.stage4, \"2\").blocks, \"0\").conv2.pointwise_conv.activate(backbone_stage4_2_blocks_0_conv2_pointwise_conv_bn);  backbone_stage4_2_blocks_0_conv2_pointwise_conv_bn = None\n",
      "    backbone_stage4_2_module_cat_4 = getattr(self.backbone.stage4, \"2\").module_cat_4(backbone_stage4_2_blocks_0_conv2_pointwise_conv_activate, backbone_stage4_2_short_conv_activate);  backbone_stage4_2_blocks_0_conv2_pointwise_conv_activate = backbone_stage4_2_short_conv_activate = None\n",
      "    backbone_stage4_2_attention_global_avgpool = getattr(self.backbone.stage4, \"2\").attention.global_avgpool(backbone_stage4_2_module_cat_4)\n",
      "    backbone_stage4_2_attention_fc = getattr(self.backbone.stage4, \"2\").attention.fc(backbone_stage4_2_attention_global_avgpool);  backbone_stage4_2_attention_global_avgpool = None\n",
      "    backbone_stage4_2_attention_act = getattr(self.backbone.stage4, \"2\").attention.act(backbone_stage4_2_attention_fc);  backbone_stage4_2_attention_fc = None\n",
      "    backbone_stage4_2_attention_module_mul_3 = getattr(self.backbone.stage4, \"2\").attention.module_mul_3(backbone_stage4_2_module_cat_4, backbone_stage4_2_attention_act);  backbone_stage4_2_module_cat_4 = backbone_stage4_2_attention_act = None\n",
      "    backbone_stage4_2_final_conv_conv = getattr(self.backbone.stage4, \"2\").final_conv.conv(backbone_stage4_2_attention_module_mul_3);  backbone_stage4_2_attention_module_mul_3 = None\n",
      "    backbone_stage4_2_final_conv_bn = getattr(self.backbone.stage4, \"2\").final_conv.bn(backbone_stage4_2_final_conv_conv);  backbone_stage4_2_final_conv_conv = None\n",
      "    backbone_stage4_2_final_conv_activate = getattr(self.backbone.stage4, \"2\").final_conv.activate(backbone_stage4_2_final_conv_bn);  backbone_stage4_2_final_conv_bn = None\n",
      "    neck_reduce_layers_0_conv = getattr(self.neck.reduce_layers, \"0\").conv(backbone_stage4_2_final_conv_activate);  backbone_stage4_2_final_conv_activate = None\n",
      "    neck_reduce_layers_0_bn = getattr(self.neck.reduce_layers, \"0\").bn(neck_reduce_layers_0_conv);  neck_reduce_layers_0_conv = None\n",
      "    neck_reduce_layers_0_activate = getattr(self.neck.reduce_layers, \"0\").activate(neck_reduce_layers_0_bn);  neck_reduce_layers_0_bn = None\n",
      "    neck_upsample = self.neck.upsample(neck_reduce_layers_0_activate)\n",
      "    neck_module_cat_5 = self.neck.module_cat_5(neck_upsample, backbone_stage3_1_final_conv_activate);  neck_upsample = backbone_stage3_1_final_conv_activate = None\n",
      "    neck_top_down_blocks_0_short_conv_conv = getattr(self.neck.top_down_blocks, \"0\").short_conv.conv(neck_module_cat_5)\n",
      "    neck_top_down_blocks_0_short_conv_bn = getattr(self.neck.top_down_blocks, \"0\").short_conv.bn(neck_top_down_blocks_0_short_conv_conv);  neck_top_down_blocks_0_short_conv_conv = None\n",
      "    neck_top_down_blocks_0_short_conv_activate = getattr(self.neck.top_down_blocks, \"0\").short_conv.activate(neck_top_down_blocks_0_short_conv_bn);  neck_top_down_blocks_0_short_conv_bn = None\n",
      "    neck_top_down_blocks_0_main_conv_conv = getattr(self.neck.top_down_blocks, \"0\").main_conv.conv(neck_module_cat_5);  neck_module_cat_5 = None\n",
      "    neck_top_down_blocks_0_main_conv_bn = getattr(self.neck.top_down_blocks, \"0\").main_conv.bn(neck_top_down_blocks_0_main_conv_conv);  neck_top_down_blocks_0_main_conv_conv = None\n",
      "    neck_top_down_blocks_0_main_conv_activate = getattr(self.neck.top_down_blocks, \"0\").main_conv.activate(neck_top_down_blocks_0_main_conv_bn);  neck_top_down_blocks_0_main_conv_bn = None\n",
      "    neck_top_down_blocks_0_blocks_0_conv1_conv = getattr(getattr(self.neck.top_down_blocks, \"0\").blocks, \"0\").conv1.conv(neck_top_down_blocks_0_main_conv_activate);  neck_top_down_blocks_0_main_conv_activate = None\n",
      "    neck_top_down_blocks_0_blocks_0_conv1_bn = getattr(getattr(self.neck.top_down_blocks, \"0\").blocks, \"0\").conv1.bn(neck_top_down_blocks_0_blocks_0_conv1_conv);  neck_top_down_blocks_0_blocks_0_conv1_conv = None\n",
      "    neck_top_down_blocks_0_blocks_0_conv1_activate = getattr(getattr(self.neck.top_down_blocks, \"0\").blocks, \"0\").conv1.activate(neck_top_down_blocks_0_blocks_0_conv1_bn);  neck_top_down_blocks_0_blocks_0_conv1_bn = None\n",
      "    neck_top_down_blocks_0_blocks_0_conv2_depthwise_conv_conv = getattr(getattr(self.neck.top_down_blocks, \"0\").blocks, \"0\").conv2.depthwise_conv.conv(neck_top_down_blocks_0_blocks_0_conv1_activate);  neck_top_down_blocks_0_blocks_0_conv1_activate = None\n",
      "    neck_top_down_blocks_0_blocks_0_conv2_depthwise_conv_bn = getattr(getattr(self.neck.top_down_blocks, \"0\").blocks, \"0\").conv2.depthwise_conv.bn(neck_top_down_blocks_0_blocks_0_conv2_depthwise_conv_conv);  neck_top_down_blocks_0_blocks_0_conv2_depthwise_conv_conv = None\n",
      "    neck_top_down_blocks_0_blocks_0_conv2_depthwise_conv_activate = getattr(getattr(self.neck.top_down_blocks, \"0\").blocks, \"0\").conv2.depthwise_conv.activate(neck_top_down_blocks_0_blocks_0_conv2_depthwise_conv_bn);  neck_top_down_blocks_0_blocks_0_conv2_depthwise_conv_bn = None\n",
      "    neck_top_down_blocks_0_blocks_0_conv2_pointwise_conv_conv = getattr(getattr(self.neck.top_down_blocks, \"0\").blocks, \"0\").conv2.pointwise_conv.conv(neck_top_down_blocks_0_blocks_0_conv2_depthwise_conv_activate);  neck_top_down_blocks_0_blocks_0_conv2_depthwise_conv_activate = None\n",
      "    neck_top_down_blocks_0_blocks_0_conv2_pointwise_conv_bn = getattr(getattr(self.neck.top_down_blocks, \"0\").blocks, \"0\").conv2.pointwise_conv.bn(neck_top_down_blocks_0_blocks_0_conv2_pointwise_conv_conv);  neck_top_down_blocks_0_blocks_0_conv2_pointwise_conv_conv = None\n",
      "    neck_top_down_blocks_0_blocks_0_conv2_pointwise_conv_activate = getattr(getattr(self.neck.top_down_blocks, \"0\").blocks, \"0\").conv2.pointwise_conv.activate(neck_top_down_blocks_0_blocks_0_conv2_pointwise_conv_bn);  neck_top_down_blocks_0_blocks_0_conv2_pointwise_conv_bn = None\n",
      "    neck_top_down_blocks_0_module_cat_6 = getattr(self.neck.top_down_blocks, \"0\").module_cat_6(neck_top_down_blocks_0_blocks_0_conv2_pointwise_conv_activate, neck_top_down_blocks_0_short_conv_activate);  neck_top_down_blocks_0_blocks_0_conv2_pointwise_conv_activate = neck_top_down_blocks_0_short_conv_activate = None\n",
      "    neck_top_down_blocks_0_final_conv_conv = getattr(self.neck.top_down_blocks, \"0\").final_conv.conv(neck_top_down_blocks_0_module_cat_6);  neck_top_down_blocks_0_module_cat_6 = None\n",
      "    neck_top_down_blocks_0_final_conv_bn = getattr(self.neck.top_down_blocks, \"0\").final_conv.bn(neck_top_down_blocks_0_final_conv_conv);  neck_top_down_blocks_0_final_conv_conv = None\n",
      "    neck_top_down_blocks_0_final_conv_activate = getattr(self.neck.top_down_blocks, \"0\").final_conv.activate(neck_top_down_blocks_0_final_conv_bn);  neck_top_down_blocks_0_final_conv_bn = None\n",
      "    neck_reduce_layers_1_conv = getattr(self.neck.reduce_layers, \"1\").conv(neck_top_down_blocks_0_final_conv_activate);  neck_top_down_blocks_0_final_conv_activate = None\n",
      "    neck_reduce_layers_1_bn = getattr(self.neck.reduce_layers, \"1\").bn(neck_reduce_layers_1_conv);  neck_reduce_layers_1_conv = None\n",
      "    neck_reduce_layers_1_activate = getattr(self.neck.reduce_layers, \"1\").activate(neck_reduce_layers_1_bn);  neck_reduce_layers_1_bn = None\n",
      "    neck_module_upsample_1 = self.neck.module_upsample_1(neck_reduce_layers_1_activate)\n",
      "    neck_module_cat_7 = self.neck.module_cat_7(neck_module_upsample_1, backbone_stage2_1_final_conv_activate);  neck_module_upsample_1 = backbone_stage2_1_final_conv_activate = None\n",
      "    neck_top_down_blocks_1_short_conv_conv = getattr(self.neck.top_down_blocks, \"1\").short_conv.conv(neck_module_cat_7)\n",
      "    neck_top_down_blocks_1_short_conv_bn = getattr(self.neck.top_down_blocks, \"1\").short_conv.bn(neck_top_down_blocks_1_short_conv_conv);  neck_top_down_blocks_1_short_conv_conv = None\n",
      "    neck_top_down_blocks_1_short_conv_activate = getattr(self.neck.top_down_blocks, \"1\").short_conv.activate(neck_top_down_blocks_1_short_conv_bn);  neck_top_down_blocks_1_short_conv_bn = None\n",
      "    neck_top_down_blocks_1_main_conv_conv = getattr(self.neck.top_down_blocks, \"1\").main_conv.conv(neck_module_cat_7);  neck_module_cat_7 = None\n",
      "    neck_top_down_blocks_1_main_conv_bn = getattr(self.neck.top_down_blocks, \"1\").main_conv.bn(neck_top_down_blocks_1_main_conv_conv);  neck_top_down_blocks_1_main_conv_conv = None\n",
      "    neck_top_down_blocks_1_main_conv_activate = getattr(self.neck.top_down_blocks, \"1\").main_conv.activate(neck_top_down_blocks_1_main_conv_bn);  neck_top_down_blocks_1_main_conv_bn = None\n",
      "    neck_top_down_blocks_1_blocks_0_conv1_conv = getattr(getattr(self.neck.top_down_blocks, \"1\").blocks, \"0\").conv1.conv(neck_top_down_blocks_1_main_conv_activate);  neck_top_down_blocks_1_main_conv_activate = None\n",
      "    neck_top_down_blocks_1_blocks_0_conv1_bn = getattr(getattr(self.neck.top_down_blocks, \"1\").blocks, \"0\").conv1.bn(neck_top_down_blocks_1_blocks_0_conv1_conv);  neck_top_down_blocks_1_blocks_0_conv1_conv = None\n",
      "    neck_top_down_blocks_1_blocks_0_conv1_activate = getattr(getattr(self.neck.top_down_blocks, \"1\").blocks, \"0\").conv1.activate(neck_top_down_blocks_1_blocks_0_conv1_bn);  neck_top_down_blocks_1_blocks_0_conv1_bn = None\n",
      "    neck_top_down_blocks_1_blocks_0_conv2_depthwise_conv_conv = getattr(getattr(self.neck.top_down_blocks, \"1\").blocks, \"0\").conv2.depthwise_conv.conv(neck_top_down_blocks_1_blocks_0_conv1_activate);  neck_top_down_blocks_1_blocks_0_conv1_activate = None\n",
      "    neck_top_down_blocks_1_blocks_0_conv2_depthwise_conv_bn = getattr(getattr(self.neck.top_down_blocks, \"1\").blocks, \"0\").conv2.depthwise_conv.bn(neck_top_down_blocks_1_blocks_0_conv2_depthwise_conv_conv);  neck_top_down_blocks_1_blocks_0_conv2_depthwise_conv_conv = None\n",
      "    neck_top_down_blocks_1_blocks_0_conv2_depthwise_conv_activate = getattr(getattr(self.neck.top_down_blocks, \"1\").blocks, \"0\").conv2.depthwise_conv.activate(neck_top_down_blocks_1_blocks_0_conv2_depthwise_conv_bn);  neck_top_down_blocks_1_blocks_0_conv2_depthwise_conv_bn = None\n",
      "    neck_top_down_blocks_1_blocks_0_conv2_pointwise_conv_conv = getattr(getattr(self.neck.top_down_blocks, \"1\").blocks, \"0\").conv2.pointwise_conv.conv(neck_top_down_blocks_1_blocks_0_conv2_depthwise_conv_activate);  neck_top_down_blocks_1_blocks_0_conv2_depthwise_conv_activate = None\n",
      "    neck_top_down_blocks_1_blocks_0_conv2_pointwise_conv_bn = getattr(getattr(self.neck.top_down_blocks, \"1\").blocks, \"0\").conv2.pointwise_conv.bn(neck_top_down_blocks_1_blocks_0_conv2_pointwise_conv_conv);  neck_top_down_blocks_1_blocks_0_conv2_pointwise_conv_conv = None\n",
      "    neck_top_down_blocks_1_blocks_0_conv2_pointwise_conv_activate = getattr(getattr(self.neck.top_down_blocks, \"1\").blocks, \"0\").conv2.pointwise_conv.activate(neck_top_down_blocks_1_blocks_0_conv2_pointwise_conv_bn);  neck_top_down_blocks_1_blocks_0_conv2_pointwise_conv_bn = None\n",
      "    neck_top_down_blocks_1_module_cat_8 = getattr(self.neck.top_down_blocks, \"1\").module_cat_8(neck_top_down_blocks_1_blocks_0_conv2_pointwise_conv_activate, neck_top_down_blocks_1_short_conv_activate);  neck_top_down_blocks_1_blocks_0_conv2_pointwise_conv_activate = neck_top_down_blocks_1_short_conv_activate = None\n",
      "    neck_top_down_blocks_1_final_conv_conv = getattr(self.neck.top_down_blocks, \"1\").final_conv.conv(neck_top_down_blocks_1_module_cat_8);  neck_top_down_blocks_1_module_cat_8 = None\n",
      "    neck_top_down_blocks_1_final_conv_bn = getattr(self.neck.top_down_blocks, \"1\").final_conv.bn(neck_top_down_blocks_1_final_conv_conv);  neck_top_down_blocks_1_final_conv_conv = None\n",
      "    neck_top_down_blocks_1_final_conv_activate = getattr(self.neck.top_down_blocks, \"1\").final_conv.activate(neck_top_down_blocks_1_final_conv_bn);  neck_top_down_blocks_1_final_conv_bn = None\n",
      "    neck_downsamples_0_conv = getattr(self.neck.downsamples, \"0\").conv(neck_top_down_blocks_1_final_conv_activate)\n",
      "    neck_downsamples_0_bn = getattr(self.neck.downsamples, \"0\").bn(neck_downsamples_0_conv);  neck_downsamples_0_conv = None\n",
      "    neck_downsamples_0_activate = getattr(self.neck.downsamples, \"0\").activate(neck_downsamples_0_bn);  neck_downsamples_0_bn = None\n",
      "    neck_module_cat_9 = self.neck.module_cat_9(neck_downsamples_0_activate, neck_reduce_layers_1_activate);  neck_downsamples_0_activate = neck_reduce_layers_1_activate = None\n",
      "    neck_bottom_up_blocks_0_short_conv_conv = getattr(self.neck.bottom_up_blocks, \"0\").short_conv.conv(neck_module_cat_9)\n",
      "    neck_bottom_up_blocks_0_short_conv_bn = getattr(self.neck.bottom_up_blocks, \"0\").short_conv.bn(neck_bottom_up_blocks_0_short_conv_conv);  neck_bottom_up_blocks_0_short_conv_conv = None\n",
      "    neck_bottom_up_blocks_0_short_conv_activate = getattr(self.neck.bottom_up_blocks, \"0\").short_conv.activate(neck_bottom_up_blocks_0_short_conv_bn);  neck_bottom_up_blocks_0_short_conv_bn = None\n",
      "    neck_bottom_up_blocks_0_main_conv_conv = getattr(self.neck.bottom_up_blocks, \"0\").main_conv.conv(neck_module_cat_9);  neck_module_cat_9 = None\n",
      "    neck_bottom_up_blocks_0_main_conv_bn = getattr(self.neck.bottom_up_blocks, \"0\").main_conv.bn(neck_bottom_up_blocks_0_main_conv_conv);  neck_bottom_up_blocks_0_main_conv_conv = None\n",
      "    neck_bottom_up_blocks_0_main_conv_activate = getattr(self.neck.bottom_up_blocks, \"0\").main_conv.activate(neck_bottom_up_blocks_0_main_conv_bn);  neck_bottom_up_blocks_0_main_conv_bn = None\n",
      "    neck_bottom_up_blocks_0_blocks_0_conv1_conv = getattr(getattr(self.neck.bottom_up_blocks, \"0\").blocks, \"0\").conv1.conv(neck_bottom_up_blocks_0_main_conv_activate);  neck_bottom_up_blocks_0_main_conv_activate = None\n",
      "    neck_bottom_up_blocks_0_blocks_0_conv1_bn = getattr(getattr(self.neck.bottom_up_blocks, \"0\").blocks, \"0\").conv1.bn(neck_bottom_up_blocks_0_blocks_0_conv1_conv);  neck_bottom_up_blocks_0_blocks_0_conv1_conv = None\n",
      "    neck_bottom_up_blocks_0_blocks_0_conv1_activate = getattr(getattr(self.neck.bottom_up_blocks, \"0\").blocks, \"0\").conv1.activate(neck_bottom_up_blocks_0_blocks_0_conv1_bn);  neck_bottom_up_blocks_0_blocks_0_conv1_bn = None\n",
      "    neck_bottom_up_blocks_0_blocks_0_conv2_depthwise_conv_conv = getattr(getattr(self.neck.bottom_up_blocks, \"0\").blocks, \"0\").conv2.depthwise_conv.conv(neck_bottom_up_blocks_0_blocks_0_conv1_activate);  neck_bottom_up_blocks_0_blocks_0_conv1_activate = None\n",
      "    neck_bottom_up_blocks_0_blocks_0_conv2_depthwise_conv_bn = getattr(getattr(self.neck.bottom_up_blocks, \"0\").blocks, \"0\").conv2.depthwise_conv.bn(neck_bottom_up_blocks_0_blocks_0_conv2_depthwise_conv_conv);  neck_bottom_up_blocks_0_blocks_0_conv2_depthwise_conv_conv = None\n",
      "    neck_bottom_up_blocks_0_blocks_0_conv2_depthwise_conv_activate = getattr(getattr(self.neck.bottom_up_blocks, \"0\").blocks, \"0\").conv2.depthwise_conv.activate(neck_bottom_up_blocks_0_blocks_0_conv2_depthwise_conv_bn);  neck_bottom_up_blocks_0_blocks_0_conv2_depthwise_conv_bn = None\n",
      "    neck_bottom_up_blocks_0_blocks_0_conv2_pointwise_conv_conv = getattr(getattr(self.neck.bottom_up_blocks, \"0\").blocks, \"0\").conv2.pointwise_conv.conv(neck_bottom_up_blocks_0_blocks_0_conv2_depthwise_conv_activate);  neck_bottom_up_blocks_0_blocks_0_conv2_depthwise_conv_activate = None\n",
      "    neck_bottom_up_blocks_0_blocks_0_conv2_pointwise_conv_bn = getattr(getattr(self.neck.bottom_up_blocks, \"0\").blocks, \"0\").conv2.pointwise_conv.bn(neck_bottom_up_blocks_0_blocks_0_conv2_pointwise_conv_conv);  neck_bottom_up_blocks_0_blocks_0_conv2_pointwise_conv_conv = None\n",
      "    neck_bottom_up_blocks_0_blocks_0_conv2_pointwise_conv_activate = getattr(getattr(self.neck.bottom_up_blocks, \"0\").blocks, \"0\").conv2.pointwise_conv.activate(neck_bottom_up_blocks_0_blocks_0_conv2_pointwise_conv_bn);  neck_bottom_up_blocks_0_blocks_0_conv2_pointwise_conv_bn = None\n",
      "    neck_bottom_up_blocks_0_module_cat_10 = getattr(self.neck.bottom_up_blocks, \"0\").module_cat_10(neck_bottom_up_blocks_0_blocks_0_conv2_pointwise_conv_activate, neck_bottom_up_blocks_0_short_conv_activate);  neck_bottom_up_blocks_0_blocks_0_conv2_pointwise_conv_activate = neck_bottom_up_blocks_0_short_conv_activate = None\n",
      "    neck_bottom_up_blocks_0_final_conv_conv = getattr(self.neck.bottom_up_blocks, \"0\").final_conv.conv(neck_bottom_up_blocks_0_module_cat_10);  neck_bottom_up_blocks_0_module_cat_10 = None\n",
      "    neck_bottom_up_blocks_0_final_conv_bn = getattr(self.neck.bottom_up_blocks, \"0\").final_conv.bn(neck_bottom_up_blocks_0_final_conv_conv);  neck_bottom_up_blocks_0_final_conv_conv = None\n",
      "    neck_bottom_up_blocks_0_final_conv_activate = getattr(self.neck.bottom_up_blocks, \"0\").final_conv.activate(neck_bottom_up_blocks_0_final_conv_bn);  neck_bottom_up_blocks_0_final_conv_bn = None\n",
      "    neck_downsamples_1_conv = getattr(self.neck.downsamples, \"1\").conv(neck_bottom_up_blocks_0_final_conv_activate)\n",
      "    neck_downsamples_1_bn = getattr(self.neck.downsamples, \"1\").bn(neck_downsamples_1_conv);  neck_downsamples_1_conv = None\n",
      "    neck_downsamples_1_activate = getattr(self.neck.downsamples, \"1\").activate(neck_downsamples_1_bn);  neck_downsamples_1_bn = None\n",
      "    neck_module_cat_11 = self.neck.module_cat_11(neck_downsamples_1_activate, neck_reduce_layers_0_activate);  neck_downsamples_1_activate = neck_reduce_layers_0_activate = None\n",
      "    neck_bottom_up_blocks_1_short_conv_conv = getattr(self.neck.bottom_up_blocks, \"1\").short_conv.conv(neck_module_cat_11)\n",
      "    neck_bottom_up_blocks_1_short_conv_bn = getattr(self.neck.bottom_up_blocks, \"1\").short_conv.bn(neck_bottom_up_blocks_1_short_conv_conv);  neck_bottom_up_blocks_1_short_conv_conv = None\n",
      "    neck_bottom_up_blocks_1_short_conv_activate = getattr(self.neck.bottom_up_blocks, \"1\").short_conv.activate(neck_bottom_up_blocks_1_short_conv_bn);  neck_bottom_up_blocks_1_short_conv_bn = None\n",
      "    neck_bottom_up_blocks_1_main_conv_conv = getattr(self.neck.bottom_up_blocks, \"1\").main_conv.conv(neck_module_cat_11);  neck_module_cat_11 = None\n",
      "    neck_bottom_up_blocks_1_main_conv_bn = getattr(self.neck.bottom_up_blocks, \"1\").main_conv.bn(neck_bottom_up_blocks_1_main_conv_conv);  neck_bottom_up_blocks_1_main_conv_conv = None\n",
      "    neck_bottom_up_blocks_1_main_conv_activate = getattr(self.neck.bottom_up_blocks, \"1\").main_conv.activate(neck_bottom_up_blocks_1_main_conv_bn);  neck_bottom_up_blocks_1_main_conv_bn = None\n",
      "    neck_bottom_up_blocks_1_blocks_0_conv1_conv = getattr(getattr(self.neck.bottom_up_blocks, \"1\").blocks, \"0\").conv1.conv(neck_bottom_up_blocks_1_main_conv_activate);  neck_bottom_up_blocks_1_main_conv_activate = None\n",
      "    neck_bottom_up_blocks_1_blocks_0_conv1_bn = getattr(getattr(self.neck.bottom_up_blocks, \"1\").blocks, \"0\").conv1.bn(neck_bottom_up_blocks_1_blocks_0_conv1_conv);  neck_bottom_up_blocks_1_blocks_0_conv1_conv = None\n",
      "    neck_bottom_up_blocks_1_blocks_0_conv1_activate = getattr(getattr(self.neck.bottom_up_blocks, \"1\").blocks, \"0\").conv1.activate(neck_bottom_up_blocks_1_blocks_0_conv1_bn);  neck_bottom_up_blocks_1_blocks_0_conv1_bn = None\n",
      "    neck_bottom_up_blocks_1_blocks_0_conv2_depthwise_conv_conv = getattr(getattr(self.neck.bottom_up_blocks, \"1\").blocks, \"0\").conv2.depthwise_conv.conv(neck_bottom_up_blocks_1_blocks_0_conv1_activate);  neck_bottom_up_blocks_1_blocks_0_conv1_activate = None\n",
      "    neck_bottom_up_blocks_1_blocks_0_conv2_depthwise_conv_bn = getattr(getattr(self.neck.bottom_up_blocks, \"1\").blocks, \"0\").conv2.depthwise_conv.bn(neck_bottom_up_blocks_1_blocks_0_conv2_depthwise_conv_conv);  neck_bottom_up_blocks_1_blocks_0_conv2_depthwise_conv_conv = None\n",
      "    neck_bottom_up_blocks_1_blocks_0_conv2_depthwise_conv_activate = getattr(getattr(self.neck.bottom_up_blocks, \"1\").blocks, \"0\").conv2.depthwise_conv.activate(neck_bottom_up_blocks_1_blocks_0_conv2_depthwise_conv_bn);  neck_bottom_up_blocks_1_blocks_0_conv2_depthwise_conv_bn = None\n",
      "    neck_bottom_up_blocks_1_blocks_0_conv2_pointwise_conv_conv = getattr(getattr(self.neck.bottom_up_blocks, \"1\").blocks, \"0\").conv2.pointwise_conv.conv(neck_bottom_up_blocks_1_blocks_0_conv2_depthwise_conv_activate);  neck_bottom_up_blocks_1_blocks_0_conv2_depthwise_conv_activate = None\n",
      "    neck_bottom_up_blocks_1_blocks_0_conv2_pointwise_conv_bn = getattr(getattr(self.neck.bottom_up_blocks, \"1\").blocks, \"0\").conv2.pointwise_conv.bn(neck_bottom_up_blocks_1_blocks_0_conv2_pointwise_conv_conv);  neck_bottom_up_blocks_1_blocks_0_conv2_pointwise_conv_conv = None\n",
      "    neck_bottom_up_blocks_1_blocks_0_conv2_pointwise_conv_activate = getattr(getattr(self.neck.bottom_up_blocks, \"1\").blocks, \"0\").conv2.pointwise_conv.activate(neck_bottom_up_blocks_1_blocks_0_conv2_pointwise_conv_bn);  neck_bottom_up_blocks_1_blocks_0_conv2_pointwise_conv_bn = None\n",
      "    neck_bottom_up_blocks_1_module_cat_12 = getattr(self.neck.bottom_up_blocks, \"1\").module_cat_12(neck_bottom_up_blocks_1_blocks_0_conv2_pointwise_conv_activate, neck_bottom_up_blocks_1_short_conv_activate);  neck_bottom_up_blocks_1_blocks_0_conv2_pointwise_conv_activate = neck_bottom_up_blocks_1_short_conv_activate = None\n",
      "    neck_bottom_up_blocks_1_final_conv_conv = getattr(self.neck.bottom_up_blocks, \"1\").final_conv.conv(neck_bottom_up_blocks_1_module_cat_12);  neck_bottom_up_blocks_1_module_cat_12 = None\n",
      "    neck_bottom_up_blocks_1_final_conv_bn = getattr(self.neck.bottom_up_blocks, \"1\").final_conv.bn(neck_bottom_up_blocks_1_final_conv_conv);  neck_bottom_up_blocks_1_final_conv_conv = None\n",
      "    neck_bottom_up_blocks_1_final_conv_activate = getattr(self.neck.bottom_up_blocks, \"1\").final_conv.activate(neck_bottom_up_blocks_1_final_conv_bn);  neck_bottom_up_blocks_1_final_conv_bn = None\n",
      "    neck_out_convs_0_conv = getattr(self.neck.out_convs, \"0\").conv(neck_top_down_blocks_1_final_conv_activate);  neck_top_down_blocks_1_final_conv_activate = None\n",
      "    neck_out_convs_0_bn = getattr(self.neck.out_convs, \"0\").bn(neck_out_convs_0_conv);  neck_out_convs_0_conv = None\n",
      "    neck_out_convs_0_activate = getattr(self.neck.out_convs, \"0\").activate(neck_out_convs_0_bn);  neck_out_convs_0_bn = None\n",
      "    neck_out_convs_1_conv = getattr(self.neck.out_convs, \"1\").conv(neck_bottom_up_blocks_0_final_conv_activate);  neck_bottom_up_blocks_0_final_conv_activate = None\n",
      "    neck_out_convs_1_bn = getattr(self.neck.out_convs, \"1\").bn(neck_out_convs_1_conv);  neck_out_convs_1_conv = None\n",
      "    neck_out_convs_1_activate = getattr(self.neck.out_convs, \"1\").activate(neck_out_convs_1_bn);  neck_out_convs_1_bn = None\n",
      "    neck_out_convs_2_conv = getattr(self.neck.out_convs, \"2\").conv(neck_bottom_up_blocks_1_final_conv_activate);  neck_bottom_up_blocks_1_final_conv_activate = None\n",
      "    neck_out_convs_2_bn = getattr(self.neck.out_convs, \"2\").bn(neck_out_convs_2_conv);  neck_out_convs_2_conv = None\n",
      "    neck_out_convs_2_activate = getattr(self.neck.out_convs, \"2\").activate(neck_out_convs_2_bn);  neck_out_convs_2_bn = None\n",
      "    bbox_head_cls_convs_0_0_conv = getattr(getattr(self.bbox_head.cls_convs, \"0\"), \"0\").conv(neck_out_convs_0_activate)\n",
      "    bbox_head_cls_convs_0_0_bn = getattr(getattr(self.bbox_head.cls_convs, \"0\"), \"0\").bn(bbox_head_cls_convs_0_0_conv);  bbox_head_cls_convs_0_0_conv = None\n",
      "    bbox_head_cls_convs_0_0_activate = getattr(getattr(self.bbox_head.cls_convs, \"0\"), \"0\").activate(bbox_head_cls_convs_0_0_bn);  bbox_head_cls_convs_0_0_bn = None\n",
      "    bbox_head_cls_convs_0_1_conv = getattr(getattr(self.bbox_head.cls_convs, \"0\"), \"1\").conv(bbox_head_cls_convs_0_0_activate);  bbox_head_cls_convs_0_0_activate = None\n",
      "    bbox_head_cls_convs_0_1_bn = getattr(getattr(self.bbox_head.cls_convs, \"0\"), \"1\").bn(bbox_head_cls_convs_0_1_conv);  bbox_head_cls_convs_0_1_conv = None\n",
      "    bbox_head_cls_convs_0_1_activate = getattr(getattr(self.bbox_head.cls_convs, \"0\"), \"1\").activate(bbox_head_cls_convs_0_1_bn);  bbox_head_cls_convs_0_1_bn = None\n",
      "    bbox_head_rtm_cls_0 = getattr(self.bbox_head.rtm_cls, \"0\")(bbox_head_cls_convs_0_1_activate);  bbox_head_cls_convs_0_1_activate = None\n",
      "    bbox_head_reg_convs_0_0_conv = getattr(getattr(self.bbox_head.reg_convs, \"0\"), \"0\").conv(neck_out_convs_0_activate);  neck_out_convs_0_activate = None\n",
      "    bbox_head_reg_convs_0_0_bn = getattr(getattr(self.bbox_head.reg_convs, \"0\"), \"0\").bn(bbox_head_reg_convs_0_0_conv);  bbox_head_reg_convs_0_0_conv = None\n",
      "    bbox_head_reg_convs_0_0_activate = getattr(getattr(self.bbox_head.reg_convs, \"0\"), \"0\").activate(bbox_head_reg_convs_0_0_bn);  bbox_head_reg_convs_0_0_bn = None\n",
      "    bbox_head_reg_convs_0_1_conv = getattr(getattr(self.bbox_head.reg_convs, \"0\"), \"1\").conv(bbox_head_reg_convs_0_0_activate);  bbox_head_reg_convs_0_0_activate = None\n",
      "    bbox_head_reg_convs_0_1_bn = getattr(getattr(self.bbox_head.reg_convs, \"0\"), \"1\").bn(bbox_head_reg_convs_0_1_conv);  bbox_head_reg_convs_0_1_conv = None\n",
      "    bbox_head_reg_convs_0_1_activate = getattr(getattr(self.bbox_head.reg_convs, \"0\"), \"1\").activate(bbox_head_reg_convs_0_1_bn);  bbox_head_reg_convs_0_1_bn = None\n",
      "    bbox_head_rtm_reg_0 = getattr(self.bbox_head.rtm_reg, \"0\")(bbox_head_reg_convs_0_1_activate);  bbox_head_reg_convs_0_1_activate = None\n",
      "    bbox_head_module_mul_4 = self.bbox_head.module_mul_4(bbox_head_rtm_reg_0, 8);  bbox_head_rtm_reg_0 = None\n",
      "    bbox_head_cls_convs_0_0_module_conv_1 = getattr(getattr(self.bbox_head.cls_convs, \"0\"), \"0\").module_conv_1(neck_out_convs_1_activate)\n",
      "    bbox_head_cls_convs_1_0_bn = getattr(getattr(self.bbox_head.cls_convs, \"1\"), \"0\").bn(bbox_head_cls_convs_0_0_module_conv_1);  bbox_head_cls_convs_0_0_module_conv_1 = None\n",
      "    bbox_head_cls_convs_1_0_activate = getattr(getattr(self.bbox_head.cls_convs, \"1\"), \"0\").activate(bbox_head_cls_convs_1_0_bn);  bbox_head_cls_convs_1_0_bn = None\n",
      "    bbox_head_cls_convs_0_1_module_conv_1 = getattr(getattr(self.bbox_head.cls_convs, \"0\"), \"1\").module_conv_1(bbox_head_cls_convs_1_0_activate);  bbox_head_cls_convs_1_0_activate = None\n",
      "    bbox_head_cls_convs_1_1_bn = getattr(getattr(self.bbox_head.cls_convs, \"1\"), \"1\").bn(bbox_head_cls_convs_0_1_module_conv_1);  bbox_head_cls_convs_0_1_module_conv_1 = None\n",
      "    bbox_head_cls_convs_1_1_activate = getattr(getattr(self.bbox_head.cls_convs, \"1\"), \"1\").activate(bbox_head_cls_convs_1_1_bn);  bbox_head_cls_convs_1_1_bn = None\n",
      "    bbox_head_rtm_cls_1 = getattr(self.bbox_head.rtm_cls, \"1\")(bbox_head_cls_convs_1_1_activate);  bbox_head_cls_convs_1_1_activate = None\n",
      "    bbox_head_reg_convs_0_0_module_conv_1 = getattr(getattr(self.bbox_head.reg_convs, \"0\"), \"0\").module_conv_1(neck_out_convs_1_activate);  neck_out_convs_1_activate = None\n",
      "    bbox_head_reg_convs_1_0_bn = getattr(getattr(self.bbox_head.reg_convs, \"1\"), \"0\").bn(bbox_head_reg_convs_0_0_module_conv_1);  bbox_head_reg_convs_0_0_module_conv_1 = None\n",
      "    bbox_head_reg_convs_1_0_activate = getattr(getattr(self.bbox_head.reg_convs, \"1\"), \"0\").activate(bbox_head_reg_convs_1_0_bn);  bbox_head_reg_convs_1_0_bn = None\n",
      "    bbox_head_reg_convs_0_1_module_conv_1 = getattr(getattr(self.bbox_head.reg_convs, \"0\"), \"1\").module_conv_1(bbox_head_reg_convs_1_0_activate);  bbox_head_reg_convs_1_0_activate = None\n",
      "    bbox_head_reg_convs_1_1_bn = getattr(getattr(self.bbox_head.reg_convs, \"1\"), \"1\").bn(bbox_head_reg_convs_0_1_module_conv_1);  bbox_head_reg_convs_0_1_module_conv_1 = None\n",
      "    bbox_head_reg_convs_1_1_activate = getattr(getattr(self.bbox_head.reg_convs, \"1\"), \"1\").activate(bbox_head_reg_convs_1_1_bn);  bbox_head_reg_convs_1_1_bn = None\n",
      "    bbox_head_rtm_reg_1 = getattr(self.bbox_head.rtm_reg, \"1\")(bbox_head_reg_convs_1_1_activate);  bbox_head_reg_convs_1_1_activate = None\n",
      "    bbox_head_module_mul_5 = self.bbox_head.module_mul_5(bbox_head_rtm_reg_1, 16);  bbox_head_rtm_reg_1 = None\n",
      "    bbox_head_cls_convs_0_0_module_conv_2 = getattr(getattr(self.bbox_head.cls_convs, \"0\"), \"0\").module_conv_2(neck_out_convs_2_activate)\n",
      "    bbox_head_cls_convs_2_0_bn = getattr(getattr(self.bbox_head.cls_convs, \"2\"), \"0\").bn(bbox_head_cls_convs_0_0_module_conv_2);  bbox_head_cls_convs_0_0_module_conv_2 = None\n",
      "    bbox_head_cls_convs_2_0_activate = getattr(getattr(self.bbox_head.cls_convs, \"2\"), \"0\").activate(bbox_head_cls_convs_2_0_bn);  bbox_head_cls_convs_2_0_bn = None\n",
      "    bbox_head_cls_convs_0_1_module_conv_2 = getattr(getattr(self.bbox_head.cls_convs, \"0\"), \"1\").module_conv_2(bbox_head_cls_convs_2_0_activate);  bbox_head_cls_convs_2_0_activate = None\n",
      "    bbox_head_cls_convs_2_1_bn = getattr(getattr(self.bbox_head.cls_convs, \"2\"), \"1\").bn(bbox_head_cls_convs_0_1_module_conv_2);  bbox_head_cls_convs_0_1_module_conv_2 = None\n",
      "    bbox_head_cls_convs_2_1_activate = getattr(getattr(self.bbox_head.cls_convs, \"2\"), \"1\").activate(bbox_head_cls_convs_2_1_bn);  bbox_head_cls_convs_2_1_bn = None\n",
      "    bbox_head_rtm_cls_2 = getattr(self.bbox_head.rtm_cls, \"2\")(bbox_head_cls_convs_2_1_activate);  bbox_head_cls_convs_2_1_activate = None\n",
      "    bbox_head_reg_convs_0_0_module_conv_2 = getattr(getattr(self.bbox_head.reg_convs, \"0\"), \"0\").module_conv_2(neck_out_convs_2_activate);  neck_out_convs_2_activate = None\n",
      "    bbox_head_reg_convs_2_0_bn = getattr(getattr(self.bbox_head.reg_convs, \"2\"), \"0\").bn(bbox_head_reg_convs_0_0_module_conv_2);  bbox_head_reg_convs_0_0_module_conv_2 = None\n",
      "    bbox_head_reg_convs_2_0_activate = getattr(getattr(self.bbox_head.reg_convs, \"2\"), \"0\").activate(bbox_head_reg_convs_2_0_bn);  bbox_head_reg_convs_2_0_bn = None\n",
      "    bbox_head_reg_convs_0_1_module_conv_2 = getattr(getattr(self.bbox_head.reg_convs, \"0\"), \"1\").module_conv_2(bbox_head_reg_convs_2_0_activate);  bbox_head_reg_convs_2_0_activate = None\n",
      "    bbox_head_reg_convs_2_1_bn = getattr(getattr(self.bbox_head.reg_convs, \"2\"), \"1\").bn(bbox_head_reg_convs_0_1_module_conv_2);  bbox_head_reg_convs_0_1_module_conv_2 = None\n",
      "    bbox_head_reg_convs_2_1_activate = getattr(getattr(self.bbox_head.reg_convs, \"2\"), \"1\").activate(bbox_head_reg_convs_2_1_bn);  bbox_head_reg_convs_2_1_bn = None\n",
      "    bbox_head_rtm_reg_2 = getattr(self.bbox_head.rtm_reg, \"2\")(bbox_head_reg_convs_2_1_activate);  bbox_head_reg_convs_2_1_activate = None\n",
      "    bbox_head_module_mul_6 = self.bbox_head.module_mul_6(bbox_head_rtm_reg_2, 32);  bbox_head_rtm_reg_2 = None\n",
      "    return ((bbox_head_rtm_cls_0, bbox_head_rtm_cls_1, bbox_head_rtm_cls_2), (bbox_head_module_mul_4, bbox_head_module_mul_5, bbox_head_module_mul_6))\n",
      "    \n",
      "# To see more debug info, please use `graph_module.print_readable()`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(str(quant_sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [05:22<00:00, 20.18s/it]\n"
     ]
    }
   ],
   "source": [
    "### else compute encodings\n",
    "quant_sim.compute_encodings(pass_calibration_data, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-04 12:37:43,026 - Quant - WARNING - Exporting encodings to yaml will be deprecated in a future release. Ensure that your code can work with the exported files ending in \".encodings\" which are saved using json format. For the time being, if yaml export is needed, set aimet_common.utils.SAVE_TO_YAML to True.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1973] Warning: The shape inference of aimet_torch::CustomMarker type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-04 12:37:51,009 - Utils - INFO - successfully created onnx model with 274/279 node names updated\n",
      "2024-09-04 12:37:51,568 - Quant - INFO - Layers excluded from quantization: []\n",
      "2024-09-04 12:37:51,619 - Quant - WARNING - Exporting encodings to yaml will be deprecated in a future release. Ensure that your code can work with the exported files ending in \".encodings\" which are saved using json format. For the time being, if yaml export is needed, set aimet_common.utils.SAVE_TO_YAML to True.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_156794/714565966.py\", line 15, in <module>\n",
      "    quant_sim.export(path=output_dir,\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/aimet_torch/v2/quantsim/quantsim.py\", line 171, in export\n",
      "    return super().export(path, filename_prefix, dummy_input, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/aimet_torch/quantsim.py\", line 553, in export\n",
      "    QuantizationSimModel.save_model_with_embedded_quantization_nodes(self.model, path, filename_prefix, dummy_input,\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/aimet_torch/quantsim.py\", line 2054, in save_model_with_embedded_quantization_nodes\n",
      "    OnnxSaver._export_model_to_onnx(quant_sim_model, dummy_input, model_path, is_conditional, onnx_export_args) # pylint: disable=protected-access\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/aimet_torch/onnx_utils.py\", line 1510, in _export_model_to_onnx\n",
      "    torch.onnx.export(model, dummy_input, temp_file, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py\", line 516, in export\n",
      "    _export(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py\", line 1613, in _export\n",
      "    graph, params_dict, torch_out = _model_to_graph(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py\", line 1135, in _model_to_graph\n",
      "    graph, params, torch_out, module = _create_jit_graph(model, args)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py\", line 1011, in _create_jit_graph\n",
      "    graph, torch_out = _trace_and_get_graph_from_model(model, args)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py\", line 907, in _trace_and_get_graph_from_model\n",
      "    orig_state_dict_keys = torch.jit._unique_state_dict(model).keys()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/jit/_trace.py\", line 81, in _unique_state_dict\n",
      "    filtered_dict[k] = v.detach()\n",
      "AttributeError: 'dict' object has no attribute 'detach'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import traceback\n",
    "import shutil\n",
    "dummy_input = torch.rand(1, 3, 640, 640)\n",
    "output_dir = f\"/teamspace/studios/this_studio/aimet/exported_models/bn_folded_fp16_encodings\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "quant_sim.export(path=output_dir,\n",
    "            filename_prefix=\"rtm_det\",\n",
    "            dummy_input=dummy_input.cpu())\n",
    "\n",
    "output_dir = f\"/teamspace/studios/this_studio/aimet/exported_models/bn_folded_fp16_embdedded\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "try:\n",
    "    quant_sim.export(path=output_dir,\n",
    "                filename_prefix=\"rtm_det\",\n",
    "                dummy_input=dummy_input.cuda(),\n",
    "                use_embedded_encodings=True,\n",
    "                export_to_torchscript=False)\n",
    "except:\n",
    "    shutil.rmtree(output_dir, ignore_errors=True)\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphModule(\n",
       "  (backbone): Module(\n",
       "    (stem): Module(\n",
       "      (0): Module(\n",
       "        (conv): Conv2d(3, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (activate): CustomSiLU(\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul): Multiply()\n",
       "        )\n",
       "      )\n",
       "      (1): Module(\n",
       "        (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (activate): CustomSiLU(\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul): Multiply()\n",
       "        )\n",
       "      )\n",
       "      (2): Module(\n",
       "        (conv): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (activate): CustomSiLU(\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul): Multiply()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (stage1): Module(\n",
       "      (0): Module(\n",
       "        (conv): Conv2d(24, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (activate): CustomSiLU(\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul): Multiply()\n",
       "        )\n",
       "      )\n",
       "      (1): Module(\n",
       "        (short_conv): Module(\n",
       "          (conv): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (main_conv): Module(\n",
       "          (conv): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (blocks): Module(\n",
       "          (0): Module(\n",
       "            (conv1): Module(\n",
       "              (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (activate): CustomSiLU(\n",
       "                (sigmoid): Sigmoid()\n",
       "                (mul): Multiply()\n",
       "              )\n",
       "            )\n",
       "            (conv2): Module(\n",
       "              (depthwise_conv): Module(\n",
       "                (conv): Conv2d(24, 24, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=24)\n",
       "                (bn): Identity()\n",
       "                (activate): CustomSiLU(\n",
       "                  (sigmoid): Sigmoid()\n",
       "                  (mul): Multiply()\n",
       "                )\n",
       "              )\n",
       "              (pointwise_conv): Module(\n",
       "                (conv): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (bn): Identity()\n",
       "                (activate): CustomSiLU(\n",
       "                  (sigmoid): Sigmoid()\n",
       "                  (mul): Multiply()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (module_add): Add()\n",
       "          )\n",
       "        )\n",
       "        (attention): Module(\n",
       "          (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): Hardsigmoid()\n",
       "          (module_mul): Multiply()\n",
       "        )\n",
       "        (final_conv): Module(\n",
       "          (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (module_cat): Concat()\n",
       "      )\n",
       "    )\n",
       "    (stage2): Module(\n",
       "      (0): Module(\n",
       "        (conv): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (activate): CustomSiLU(\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul): Multiply()\n",
       "        )\n",
       "      )\n",
       "      (1): Module(\n",
       "        (short_conv): Module(\n",
       "          (conv): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (main_conv): Module(\n",
       "          (conv): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (blocks): Module(\n",
       "          (0): Module(\n",
       "            (conv1): Module(\n",
       "              (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (activate): CustomSiLU(\n",
       "                (sigmoid): Sigmoid()\n",
       "                (mul): Multiply()\n",
       "              )\n",
       "            )\n",
       "            (conv2): Module(\n",
       "              (depthwise_conv): Module(\n",
       "                (conv): Conv2d(48, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=48)\n",
       "                (bn): Identity()\n",
       "                (activate): CustomSiLU(\n",
       "                  (sigmoid): Sigmoid()\n",
       "                  (mul): Multiply()\n",
       "                )\n",
       "              )\n",
       "              (pointwise_conv): Module(\n",
       "                (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (bn): Identity()\n",
       "                (activate): CustomSiLU(\n",
       "                  (sigmoid): Sigmoid()\n",
       "                  (mul): Multiply()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (module_add_1): Add()\n",
       "          )\n",
       "        )\n",
       "        (attention): Module(\n",
       "          (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): Hardsigmoid()\n",
       "          (module_mul_1): Multiply()\n",
       "        )\n",
       "        (final_conv): Module(\n",
       "          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (module_cat_1): Concat()\n",
       "      )\n",
       "    )\n",
       "    (stage3): Module(\n",
       "      (0): Module(\n",
       "        (conv): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (activate): CustomSiLU(\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul): Multiply()\n",
       "        )\n",
       "      )\n",
       "      (1): Module(\n",
       "        (short_conv): Module(\n",
       "          (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (main_conv): Module(\n",
       "          (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (blocks): Module(\n",
       "          (0): Module(\n",
       "            (conv1): Module(\n",
       "              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (activate): CustomSiLU(\n",
       "                (sigmoid): Sigmoid()\n",
       "                (mul): Multiply()\n",
       "              )\n",
       "            )\n",
       "            (conv2): Module(\n",
       "              (depthwise_conv): Module(\n",
       "                (conv): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96)\n",
       "                (bn): Identity()\n",
       "                (activate): CustomSiLU(\n",
       "                  (sigmoid): Sigmoid()\n",
       "                  (mul): Multiply()\n",
       "                )\n",
       "              )\n",
       "              (pointwise_conv): Module(\n",
       "                (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (bn): Identity()\n",
       "                (activate): CustomSiLU(\n",
       "                  (sigmoid): Sigmoid()\n",
       "                  (mul): Multiply()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (module_add_2): Add()\n",
       "          )\n",
       "        )\n",
       "        (attention): Module(\n",
       "          (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): Hardsigmoid()\n",
       "          (module_mul_2): Multiply()\n",
       "        )\n",
       "        (final_conv): Module(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (module_cat_2): Concat()\n",
       "      )\n",
       "    )\n",
       "    (stage4): Module(\n",
       "      (0): Module(\n",
       "        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (activate): CustomSiLU(\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul): Multiply()\n",
       "        )\n",
       "      )\n",
       "      (1): Module(\n",
       "        (conv1): Module(\n",
       "          (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (poolings): Module(\n",
       "          (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "          (1): MaxPool2d(kernel_size=9, stride=1, padding=4, dilation=1, ceil_mode=False)\n",
       "          (2): MaxPool2d(kernel_size=13, stride=1, padding=6, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (conv2): Module(\n",
       "          (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (module_cat_3): Concat()\n",
       "      )\n",
       "      (2): Module(\n",
       "        (short_conv): Module(\n",
       "          (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (main_conv): Module(\n",
       "          (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (blocks): Module(\n",
       "          (0): Module(\n",
       "            (conv1): Module(\n",
       "              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (activate): CustomSiLU(\n",
       "                (sigmoid): Sigmoid()\n",
       "                (mul): Multiply()\n",
       "              )\n",
       "            )\n",
       "            (conv2): Module(\n",
       "              (depthwise_conv): Module(\n",
       "                (conv): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192)\n",
       "                (bn): Identity()\n",
       "                (activate): CustomSiLU(\n",
       "                  (sigmoid): Sigmoid()\n",
       "                  (mul): Multiply()\n",
       "                )\n",
       "              )\n",
       "              (pointwise_conv): Module(\n",
       "                (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (bn): Identity()\n",
       "                (activate): CustomSiLU(\n",
       "                  (sigmoid): Sigmoid()\n",
       "                  (mul): Multiply()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (attention): Module(\n",
       "          (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): Hardsigmoid()\n",
       "          (module_mul_3): Multiply()\n",
       "        )\n",
       "        (final_conv): Module(\n",
       "          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (module_cat_4): Concat()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (neck): Module(\n",
       "    (reduce_layers): Module(\n",
       "      (0): Module(\n",
       "        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (activate): CustomSiLU(\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul): Multiply()\n",
       "        )\n",
       "      )\n",
       "      (1): Module(\n",
       "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (activate): CustomSiLU(\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul): Multiply()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (upsample): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (top_down_blocks): Module(\n",
       "      (0): Module(\n",
       "        (short_conv): Module(\n",
       "          (conv): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (main_conv): Module(\n",
       "          (conv): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (blocks): Module(\n",
       "          (0): Module(\n",
       "            (conv1): Module(\n",
       "              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (activate): CustomSiLU(\n",
       "                (sigmoid): Sigmoid()\n",
       "                (mul): Multiply()\n",
       "              )\n",
       "            )\n",
       "            (conv2): Module(\n",
       "              (depthwise_conv): Module(\n",
       "                (conv): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96)\n",
       "                (bn): Identity()\n",
       "                (activate): CustomSiLU(\n",
       "                  (sigmoid): Sigmoid()\n",
       "                  (mul): Multiply()\n",
       "                )\n",
       "              )\n",
       "              (pointwise_conv): Module(\n",
       "                (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (bn): Identity()\n",
       "                (activate): CustomSiLU(\n",
       "                  (sigmoid): Sigmoid()\n",
       "                  (mul): Multiply()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (final_conv): Module(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (module_cat_6): Concat()\n",
       "      )\n",
       "      (1): Module(\n",
       "        (short_conv): Module(\n",
       "          (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (main_conv): Module(\n",
       "          (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (blocks): Module(\n",
       "          (0): Module(\n",
       "            (conv1): Module(\n",
       "              (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (activate): CustomSiLU(\n",
       "                (sigmoid): Sigmoid()\n",
       "                (mul): Multiply()\n",
       "              )\n",
       "            )\n",
       "            (conv2): Module(\n",
       "              (depthwise_conv): Module(\n",
       "                (conv): Conv2d(48, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=48)\n",
       "                (bn): Identity()\n",
       "                (activate): CustomSiLU(\n",
       "                  (sigmoid): Sigmoid()\n",
       "                  (mul): Multiply()\n",
       "                )\n",
       "              )\n",
       "              (pointwise_conv): Module(\n",
       "                (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (bn): Identity()\n",
       "                (activate): CustomSiLU(\n",
       "                  (sigmoid): Sigmoid()\n",
       "                  (mul): Multiply()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (final_conv): Module(\n",
       "          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (module_cat_8): Concat()\n",
       "      )\n",
       "    )\n",
       "    (downsamples): Module(\n",
       "      (0): Module(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (activate): CustomSiLU(\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul): Multiply()\n",
       "        )\n",
       "      )\n",
       "      (1): Module(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (activate): CustomSiLU(\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul): Multiply()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bottom_up_blocks): Module(\n",
       "      (0): Module(\n",
       "        (short_conv): Module(\n",
       "          (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (main_conv): Module(\n",
       "          (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (blocks): Module(\n",
       "          (0): Module(\n",
       "            (conv1): Module(\n",
       "              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (activate): CustomSiLU(\n",
       "                (sigmoid): Sigmoid()\n",
       "                (mul): Multiply()\n",
       "              )\n",
       "            )\n",
       "            (conv2): Module(\n",
       "              (depthwise_conv): Module(\n",
       "                (conv): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96)\n",
       "                (bn): Identity()\n",
       "                (activate): CustomSiLU(\n",
       "                  (sigmoid): Sigmoid()\n",
       "                  (mul): Multiply()\n",
       "                )\n",
       "              )\n",
       "              (pointwise_conv): Module(\n",
       "                (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (bn): Identity()\n",
       "                (activate): CustomSiLU(\n",
       "                  (sigmoid): Sigmoid()\n",
       "                  (mul): Multiply()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (final_conv): Module(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (module_cat_10): Concat()\n",
       "      )\n",
       "      (1): Module(\n",
       "        (short_conv): Module(\n",
       "          (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (main_conv): Module(\n",
       "          (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (blocks): Module(\n",
       "          (0): Module(\n",
       "            (conv1): Module(\n",
       "              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (activate): CustomSiLU(\n",
       "                (sigmoid): Sigmoid()\n",
       "                (mul): Multiply()\n",
       "              )\n",
       "            )\n",
       "            (conv2): Module(\n",
       "              (depthwise_conv): Module(\n",
       "                (conv): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192)\n",
       "                (bn): Identity()\n",
       "                (activate): CustomSiLU(\n",
       "                  (sigmoid): Sigmoid()\n",
       "                  (mul): Multiply()\n",
       "                )\n",
       "              )\n",
       "              (pointwise_conv): Module(\n",
       "                (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (bn): Identity()\n",
       "                (activate): CustomSiLU(\n",
       "                  (sigmoid): Sigmoid()\n",
       "                  (mul): Multiply()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (final_conv): Module(\n",
       "          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (module_cat_12): Concat()\n",
       "      )\n",
       "    )\n",
       "    (out_convs): Module(\n",
       "      (0): Module(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (activate): CustomSiLU(\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul): Multiply()\n",
       "        )\n",
       "      )\n",
       "      (1): Module(\n",
       "        (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (activate): CustomSiLU(\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul): Multiply()\n",
       "        )\n",
       "      )\n",
       "      (2): Module(\n",
       "        (conv): Conv2d(384, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (activate): CustomSiLU(\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul): Multiply()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (module_cat_5): Concat()\n",
       "    (module_upsample_1): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (module_cat_7): Concat()\n",
       "    (module_cat_9): Concat()\n",
       "    (module_cat_11): Concat()\n",
       "  )\n",
       "  (bbox_head): Module(\n",
       "    (cls_convs): Module(\n",
       "      (0): Module(\n",
       "        (0): Module(\n",
       "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "          (module_conv_1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (module_conv_2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (1): Module(\n",
       "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "          (module_conv_1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (module_conv_2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (1): Module(\n",
       "        (0): Module(\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (1): Module(\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): Module(\n",
       "        (0): Module(\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (1): Module(\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (rtm_cls): Module(\n",
       "      (0): Conv2d(96, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(96, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): Conv2d(96, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (reg_convs): Module(\n",
       "      (0): Module(\n",
       "        (0): Module(\n",
       "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "          (module_conv_1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (module_conv_2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (1): Module(\n",
       "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "          (module_conv_1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (module_conv_2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (1): Module(\n",
       "        (0): Module(\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (1): Module(\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): Module(\n",
       "        (0): Module(\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (1): Module(\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (rtm_reg): Module(\n",
       "      (0): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (module_mul_4): Multiply()\n",
       "    (module_mul_5): Multiply()\n",
       "    (module_mul_6): Multiply()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.eval()\n",
    "m.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-04 13:25:41,785 - ModelPreparer - INFO - Functional         : Adding new module for node: {backbone.stage1.1.blocks.0.module_add} \n",
      "2024-09-04 13:25:41,786 - ModelPreparer - INFO - Functional         : Adding new module for node: {backbone.stage1.1.module_cat} \n",
      "2024-09-04 13:25:41,786 - ModelPreparer - INFO - Functional         : Adding new module for node: {backbone.stage1.1.attention.module_mul} \n",
      "2024-09-04 13:25:41,787 - ModelPreparer - INFO - Functional         : Adding new module for node: {backbone.stage2.1.blocks.0.module_add_1} \n",
      "2024-09-04 13:25:41,788 - ModelPreparer - INFO - Functional         : Adding new module for node: {backbone.stage2.1.module_cat_1} \n",
      "2024-09-04 13:25:41,789 - ModelPreparer - INFO - Functional         : Adding new module for node: {backbone.stage2.1.attention.module_mul_1} \n",
      "2024-09-04 13:25:41,790 - ModelPreparer - INFO - Functional         : Adding new module for node: {backbone.stage3.1.blocks.0.module_add_2} \n",
      "2024-09-04 13:25:41,790 - ModelPreparer - INFO - Functional         : Adding new module for node: {backbone.stage3.1.module_cat_2} \n",
      "2024-09-04 13:25:41,791 - ModelPreparer - INFO - Functional         : Adding new module for node: {backbone.stage3.1.attention.module_mul_2} \n",
      "2024-09-04 13:25:41,792 - ModelPreparer - INFO - Functional         : Adding new module for node: {backbone.stage4.1.module_cat_3} \n",
      "2024-09-04 13:25:41,792 - ModelPreparer - INFO - Functional         : Adding new module for node: {backbone.stage4.2.module_cat_4} \n",
      "2024-09-04 13:25:41,793 - ModelPreparer - INFO - Functional         : Adding new module for node: {backbone.stage4.2.attention.module_mul_3} \n",
      "2024-09-04 13:25:41,794 - ModelPreparer - INFO - Functional         : Adding new module for node: {neck.module_cat_5} \n",
      "2024-09-04 13:25:41,795 - ModelPreparer - INFO - Functional         : Adding new module for node: {neck.top_down_blocks.0.module_cat_6} \n",
      "2024-09-04 13:25:41,796 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {neck.module_upsample_1} \n",
      "2024-09-04 13:25:41,796 - ModelPreparer - INFO - Functional         : Adding new module for node: {neck.module_cat_7} \n",
      "2024-09-04 13:25:41,797 - ModelPreparer - INFO - Functional         : Adding new module for node: {neck.top_down_blocks.1.module_cat_8} \n",
      "2024-09-04 13:25:41,798 - ModelPreparer - INFO - Functional         : Adding new module for node: {neck.module_cat_9} \n",
      "2024-09-04 13:25:41,798 - ModelPreparer - INFO - Functional         : Adding new module for node: {neck.bottom_up_blocks.0.module_cat_10} \n",
      "2024-09-04 13:25:41,799 - ModelPreparer - INFO - Functional         : Adding new module for node: {neck.module_cat_11} \n",
      "2024-09-04 13:25:41,800 - ModelPreparer - INFO - Functional         : Adding new module for node: {neck.bottom_up_blocks.1.module_cat_12} \n",
      "2024-09-04 13:25:41,802 - ModelPreparer - INFO - Functional         : Adding new module for node: {bbox_head.module_mul_4} \n",
      "2024-09-04 13:25:41,803 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {bbox_head.cls_convs.0.0.module_conv_1} \n",
      "2024-09-04 13:25:41,804 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {bbox_head.cls_convs.0.1.module_conv_1} \n",
      "2024-09-04 13:25:41,805 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {bbox_head.reg_convs.0.0.module_conv_1} \n",
      "2024-09-04 13:25:41,806 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {bbox_head.reg_convs.0.1.module_conv_1} \n",
      "2024-09-04 13:25:41,807 - ModelPreparer - INFO - Functional         : Adding new module for node: {bbox_head.module_mul_5} \n",
      "2024-09-04 13:25:41,808 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {bbox_head.cls_convs.0.0.module_conv_2} \n",
      "2024-09-04 13:25:41,809 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {bbox_head.cls_convs.0.1.module_conv_2} \n",
      "2024-09-04 13:25:41,810 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {bbox_head.reg_convs.0.0.module_conv_2} \n",
      "2024-09-04 13:25:41,811 - ModelPreparer - INFO - Reused/Duplicate   : Adding new module for node: {bbox_head.reg_convs.0.1.module_conv_2} \n",
      "2024-09-04 13:25:41,812 - ModelPreparer - INFO - Functional         : Adding new module for node: {bbox_head.module_mul_6} \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-04 13:25:47,374 - BatchNormFolding - INFO - 0 BatchNorms' weights got converted\n",
      "76\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GraphModule(\n",
       "  (backbone): Module(\n",
       "    (stem): Module(\n",
       "      (0): Module(\n",
       "        (conv): Conv2d(3, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (activate): CustomSiLU(\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul): Multiply()\n",
       "        )\n",
       "      )\n",
       "      (1): Module(\n",
       "        (conv): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (activate): CustomSiLU(\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul): Multiply()\n",
       "        )\n",
       "      )\n",
       "      (2): Module(\n",
       "        (conv): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (activate): CustomSiLU(\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul): Multiply()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (stage1): Module(\n",
       "      (0): Module(\n",
       "        (conv): Conv2d(24, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (activate): CustomSiLU(\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul): Multiply()\n",
       "        )\n",
       "      )\n",
       "      (1): Module(\n",
       "        (short_conv): Module(\n",
       "          (conv): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (main_conv): Module(\n",
       "          (conv): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (blocks): Module(\n",
       "          (0): Module(\n",
       "            (conv1): Module(\n",
       "              (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (activate): CustomSiLU(\n",
       "                (sigmoid): Sigmoid()\n",
       "                (mul): Multiply()\n",
       "              )\n",
       "            )\n",
       "            (conv2): Module(\n",
       "              (depthwise_conv): Module(\n",
       "                (conv): Conv2d(24, 24, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=24)\n",
       "                (bn): Identity()\n",
       "                (activate): CustomSiLU(\n",
       "                  (sigmoid): Sigmoid()\n",
       "                  (mul): Multiply()\n",
       "                )\n",
       "              )\n",
       "              (pointwise_conv): Module(\n",
       "                (conv): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (bn): Identity()\n",
       "                (activate): CustomSiLU(\n",
       "                  (sigmoid): Sigmoid()\n",
       "                  (mul): Multiply()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (module_add): Add()\n",
       "          )\n",
       "        )\n",
       "        (attention): Module(\n",
       "          (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): Hardsigmoid()\n",
       "          (module_mul): Multiply()\n",
       "        )\n",
       "        (final_conv): Module(\n",
       "          (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (module_cat): Concat()\n",
       "      )\n",
       "    )\n",
       "    (stage2): Module(\n",
       "      (0): Module(\n",
       "        (conv): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (activate): CustomSiLU(\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul): Multiply()\n",
       "        )\n",
       "      )\n",
       "      (1): Module(\n",
       "        (short_conv): Module(\n",
       "          (conv): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (main_conv): Module(\n",
       "          (conv): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (blocks): Module(\n",
       "          (0): Module(\n",
       "            (conv1): Module(\n",
       "              (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (activate): CustomSiLU(\n",
       "                (sigmoid): Sigmoid()\n",
       "                (mul): Multiply()\n",
       "              )\n",
       "            )\n",
       "            (conv2): Module(\n",
       "              (depthwise_conv): Module(\n",
       "                (conv): Conv2d(48, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=48)\n",
       "                (bn): Identity()\n",
       "                (activate): CustomSiLU(\n",
       "                  (sigmoid): Sigmoid()\n",
       "                  (mul): Multiply()\n",
       "                )\n",
       "              )\n",
       "              (pointwise_conv): Module(\n",
       "                (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (bn): Identity()\n",
       "                (activate): CustomSiLU(\n",
       "                  (sigmoid): Sigmoid()\n",
       "                  (mul): Multiply()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (module_add_1): Add()\n",
       "          )\n",
       "        )\n",
       "        (attention): Module(\n",
       "          (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): Hardsigmoid()\n",
       "          (module_mul_1): Multiply()\n",
       "        )\n",
       "        (final_conv): Module(\n",
       "          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (module_cat_1): Concat()\n",
       "      )\n",
       "    )\n",
       "    (stage3): Module(\n",
       "      (0): Module(\n",
       "        (conv): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (activate): CustomSiLU(\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul): Multiply()\n",
       "        )\n",
       "      )\n",
       "      (1): Module(\n",
       "        (short_conv): Module(\n",
       "          (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (main_conv): Module(\n",
       "          (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (blocks): Module(\n",
       "          (0): Module(\n",
       "            (conv1): Module(\n",
       "              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (activate): CustomSiLU(\n",
       "                (sigmoid): Sigmoid()\n",
       "                (mul): Multiply()\n",
       "              )\n",
       "            )\n",
       "            (conv2): Module(\n",
       "              (depthwise_conv): Module(\n",
       "                (conv): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96)\n",
       "                (bn): Identity()\n",
       "                (activate): CustomSiLU(\n",
       "                  (sigmoid): Sigmoid()\n",
       "                  (mul): Multiply()\n",
       "                )\n",
       "              )\n",
       "              (pointwise_conv): Module(\n",
       "                (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (bn): Identity()\n",
       "                (activate): CustomSiLU(\n",
       "                  (sigmoid): Sigmoid()\n",
       "                  (mul): Multiply()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (module_add_2): Add()\n",
       "          )\n",
       "        )\n",
       "        (attention): Module(\n",
       "          (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): Hardsigmoid()\n",
       "          (module_mul_2): Multiply()\n",
       "        )\n",
       "        (final_conv): Module(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (module_cat_2): Concat()\n",
       "      )\n",
       "    )\n",
       "    (stage4): Module(\n",
       "      (0): Module(\n",
       "        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (activate): CustomSiLU(\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul): Multiply()\n",
       "        )\n",
       "      )\n",
       "      (1): Module(\n",
       "        (conv1): Module(\n",
       "          (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (poolings): Module(\n",
       "          (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "          (1): MaxPool2d(kernel_size=9, stride=1, padding=4, dilation=1, ceil_mode=False)\n",
       "          (2): MaxPool2d(kernel_size=13, stride=1, padding=6, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (conv2): Module(\n",
       "          (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (module_cat_3): Concat()\n",
       "      )\n",
       "      (2): Module(\n",
       "        (short_conv): Module(\n",
       "          (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (main_conv): Module(\n",
       "          (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (blocks): Module(\n",
       "          (0): Module(\n",
       "            (conv1): Module(\n",
       "              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (activate): CustomSiLU(\n",
       "                (sigmoid): Sigmoid()\n",
       "                (mul): Multiply()\n",
       "              )\n",
       "            )\n",
       "            (conv2): Module(\n",
       "              (depthwise_conv): Module(\n",
       "                (conv): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192)\n",
       "                (bn): Identity()\n",
       "                (activate): CustomSiLU(\n",
       "                  (sigmoid): Sigmoid()\n",
       "                  (mul): Multiply()\n",
       "                )\n",
       "              )\n",
       "              (pointwise_conv): Module(\n",
       "                (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (bn): Identity()\n",
       "                (activate): CustomSiLU(\n",
       "                  (sigmoid): Sigmoid()\n",
       "                  (mul): Multiply()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (attention): Module(\n",
       "          (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): Hardsigmoid()\n",
       "          (module_mul_3): Multiply()\n",
       "        )\n",
       "        (final_conv): Module(\n",
       "          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (module_cat_4): Concat()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (neck): Module(\n",
       "    (reduce_layers): Module(\n",
       "      (0): Module(\n",
       "        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (activate): CustomSiLU(\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul): Multiply()\n",
       "        )\n",
       "      )\n",
       "      (1): Module(\n",
       "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (activate): CustomSiLU(\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul): Multiply()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (upsample): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (top_down_blocks): Module(\n",
       "      (0): Module(\n",
       "        (short_conv): Module(\n",
       "          (conv): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (main_conv): Module(\n",
       "          (conv): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (blocks): Module(\n",
       "          (0): Module(\n",
       "            (conv1): Module(\n",
       "              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (activate): CustomSiLU(\n",
       "                (sigmoid): Sigmoid()\n",
       "                (mul): Multiply()\n",
       "              )\n",
       "            )\n",
       "            (conv2): Module(\n",
       "              (depthwise_conv): Module(\n",
       "                (conv): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96)\n",
       "                (bn): Identity()\n",
       "                (activate): CustomSiLU(\n",
       "                  (sigmoid): Sigmoid()\n",
       "                  (mul): Multiply()\n",
       "                )\n",
       "              )\n",
       "              (pointwise_conv): Module(\n",
       "                (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (bn): Identity()\n",
       "                (activate): CustomSiLU(\n",
       "                  (sigmoid): Sigmoid()\n",
       "                  (mul): Multiply()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (final_conv): Module(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (module_cat_6): Concat()\n",
       "      )\n",
       "      (1): Module(\n",
       "        (short_conv): Module(\n",
       "          (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (main_conv): Module(\n",
       "          (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (blocks): Module(\n",
       "          (0): Module(\n",
       "            (conv1): Module(\n",
       "              (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (activate): CustomSiLU(\n",
       "                (sigmoid): Sigmoid()\n",
       "                (mul): Multiply()\n",
       "              )\n",
       "            )\n",
       "            (conv2): Module(\n",
       "              (depthwise_conv): Module(\n",
       "                (conv): Conv2d(48, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=48)\n",
       "                (bn): Identity()\n",
       "                (activate): CustomSiLU(\n",
       "                  (sigmoid): Sigmoid()\n",
       "                  (mul): Multiply()\n",
       "                )\n",
       "              )\n",
       "              (pointwise_conv): Module(\n",
       "                (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (bn): Identity()\n",
       "                (activate): CustomSiLU(\n",
       "                  (sigmoid): Sigmoid()\n",
       "                  (mul): Multiply()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (final_conv): Module(\n",
       "          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (module_cat_8): Concat()\n",
       "      )\n",
       "    )\n",
       "    (downsamples): Module(\n",
       "      (0): Module(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (activate): CustomSiLU(\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul): Multiply()\n",
       "        )\n",
       "      )\n",
       "      (1): Module(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (activate): CustomSiLU(\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul): Multiply()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bottom_up_blocks): Module(\n",
       "      (0): Module(\n",
       "        (short_conv): Module(\n",
       "          (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (main_conv): Module(\n",
       "          (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (blocks): Module(\n",
       "          (0): Module(\n",
       "            (conv1): Module(\n",
       "              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (activate): CustomSiLU(\n",
       "                (sigmoid): Sigmoid()\n",
       "                (mul): Multiply()\n",
       "              )\n",
       "            )\n",
       "            (conv2): Module(\n",
       "              (depthwise_conv): Module(\n",
       "                (conv): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96)\n",
       "                (bn): Identity()\n",
       "                (activate): CustomSiLU(\n",
       "                  (sigmoid): Sigmoid()\n",
       "                  (mul): Multiply()\n",
       "                )\n",
       "              )\n",
       "              (pointwise_conv): Module(\n",
       "                (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (bn): Identity()\n",
       "                (activate): CustomSiLU(\n",
       "                  (sigmoid): Sigmoid()\n",
       "                  (mul): Multiply()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (final_conv): Module(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (module_cat_10): Concat()\n",
       "      )\n",
       "      (1): Module(\n",
       "        (short_conv): Module(\n",
       "          (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (main_conv): Module(\n",
       "          (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (blocks): Module(\n",
       "          (0): Module(\n",
       "            (conv1): Module(\n",
       "              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn): Identity()\n",
       "              (activate): CustomSiLU(\n",
       "                (sigmoid): Sigmoid()\n",
       "                (mul): Multiply()\n",
       "              )\n",
       "            )\n",
       "            (conv2): Module(\n",
       "              (depthwise_conv): Module(\n",
       "                (conv): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192)\n",
       "                (bn): Identity()\n",
       "                (activate): CustomSiLU(\n",
       "                  (sigmoid): Sigmoid()\n",
       "                  (mul): Multiply()\n",
       "                )\n",
       "              )\n",
       "              (pointwise_conv): Module(\n",
       "                (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (bn): Identity()\n",
       "                (activate): CustomSiLU(\n",
       "                  (sigmoid): Sigmoid()\n",
       "                  (mul): Multiply()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (final_conv): Module(\n",
       "          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (module_cat_12): Concat()\n",
       "      )\n",
       "    )\n",
       "    (out_convs): Module(\n",
       "      (0): Module(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (activate): CustomSiLU(\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul): Multiply()\n",
       "        )\n",
       "      )\n",
       "      (1): Module(\n",
       "        (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (activate): CustomSiLU(\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul): Multiply()\n",
       "        )\n",
       "      )\n",
       "      (2): Module(\n",
       "        (conv): Conv2d(384, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (activate): CustomSiLU(\n",
       "          (sigmoid): Sigmoid()\n",
       "          (mul): Multiply()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (module_cat_5): Concat()\n",
       "    (module_upsample_1): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (module_cat_7): Concat()\n",
       "    (module_cat_9): Concat()\n",
       "    (module_cat_11): Concat()\n",
       "  )\n",
       "  (bbox_head): Module(\n",
       "    (cls_convs): Module(\n",
       "      (0): Module(\n",
       "        (0): Module(\n",
       "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "          (module_conv_1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (module_conv_2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (1): Module(\n",
       "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "          (module_conv_1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (module_conv_2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (1): Module(\n",
       "        (0): Module(\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (1): Module(\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): Module(\n",
       "        (0): Module(\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (1): Module(\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (rtm_cls): Module(\n",
       "      (0): Conv2d(96, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(96, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): Conv2d(96, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (reg_convs): Module(\n",
       "      (0): Module(\n",
       "        (0): Module(\n",
       "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "          (module_conv_1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (module_conv_2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (1): Module(\n",
       "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "          (module_conv_1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (module_conv_2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (1): Module(\n",
       "        (0): Module(\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (1): Module(\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): Module(\n",
       "        (0): Module(\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "        (1): Module(\n",
       "          (bn): Identity()\n",
       "          (activate): CustomSiLU(\n",
       "            (sigmoid): Sigmoid()\n",
       "            (mul): Multiply()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (rtm_reg): Module(\n",
       "      (0): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (module_mul_4): Multiply()\n",
       "    (module_mul_5): Multiply()\n",
       "    (module_mul_6): Multiply()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from aimet_torch.v2.quantsim import QuantizationSimModel\n",
    "from aimet_common.defs import QuantScheme, QuantizationDataType\n",
    "from aimet_torch.model_preparer import prepare_model\n",
    "from aimet_torch.batch_norm_fold import fold_all_batch_norms\n",
    "\n",
    "m_replaced = replace_rtm_bn(model)\n",
    "m = prepare_model(m_replaced)\n",
    "bn_pairs = fold_all_batch_norms(m, input_shapes=(1, 3, 640, 640))\n",
    "print(len(bn_pairs))\n",
    "m_replaced.eval()\n",
    "m.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "conv_module = nn.Sequential(*list(dict(m_replaced.named_modules())['backbone.stem.0'].children()))[:-1]\n",
    "conv_module.eval()\n",
    "print(conv_module)\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = conv_module.cuda()(dummy_input.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (1): Identity()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "conv_module_bn = nn.Sequential(*list(dict(m.named_modules())['backbone.stem.0'].children()))[:-1]\n",
    "conv_module_bn.eval()\n",
    "print(conv_module_bn)\n",
    "\n",
    "with torch.no_grad():\n",
    "    bn_output = conv_module_bn.cuda()(dummy_input.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False, device='cuda:0')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if 2 matrices are equal\n",
    "(out == bn_output).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[4.3141, 4.4292, 4.5622,  ..., 4.5342, 4.5249, 4.6823],\n",
       "          [4.4157, 4.5130, 4.4154,  ..., 4.3527, 4.4362, 4.5275],\n",
       "          [4.4246, 4.5103, 4.2153,  ..., 4.4685, 4.3702, 4.0950],\n",
       "          ...,\n",
       "          [4.3897, 4.2957, 4.2415,  ..., 4.4987, 4.3232, 4.4769],\n",
       "          [4.1684, 4.2861, 4.4192,  ..., 4.4097, 4.4444, 4.5010],\n",
       "          [4.5005, 4.3415, 4.3780,  ..., 4.1872, 4.4633, 4.2803]],\n",
       "\n",
       "         [[2.6428, 2.6722, 2.7447,  ..., 2.6616, 2.6650, 2.6964],\n",
       "          [2.6542, 2.6823, 2.6110,  ..., 2.6378, 2.6144, 2.6767],\n",
       "          [2.6883, 2.6874, 2.5713,  ..., 2.6770, 2.6748, 2.5529],\n",
       "          ...,\n",
       "          [2.6759, 2.6374, 2.6226,  ..., 2.6757, 2.7020, 2.7490],\n",
       "          [2.5737, 2.6223, 2.6866,  ..., 2.6789, 2.6208, 2.6766],\n",
       "          [2.7340, 2.5968, 2.6172,  ..., 2.5728, 2.6419, 2.6026]],\n",
       "\n",
       "         [[0.7581, 1.1461, 0.9555,  ..., 2.0014, 1.1080, 0.9551],\n",
       "          [1.3004, 1.9084, 0.3630,  ..., 1.2525, 0.9352, 1.3551],\n",
       "          [2.1100, 2.1703, 2.5564,  ..., 2.3027, 1.7752, 2.5194],\n",
       "          ...,\n",
       "          [1.8655, 1.9093, 3.4666,  ..., 2.3898, 2.8202, 2.5902],\n",
       "          [2.1042, 2.2000, 1.7428,  ..., 2.0471, 0.8328, 1.1701],\n",
       "          [2.2136, 0.3178, 0.7179,  ..., 0.5606, 1.3698, 0.7453]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[7.4544, 6.5271, 5.7766,  ..., 4.5084, 6.3149, 5.6795],\n",
       "          [6.6254, 4.0703, 7.2253,  ..., 5.3213, 6.5576, 5.6504],\n",
       "          [4.9957, 5.2038, 3.1199,  ..., 4.2441, 3.6080, 3.0180],\n",
       "          ...,\n",
       "          [5.0291, 4.3267, 2.5795,  ..., 2.0295, 4.1441, 3.3001],\n",
       "          [4.9093, 3.9361, 6.6399,  ..., 3.3910, 7.1276, 6.4612],\n",
       "          [4.3545, 6.9990, 6.9496,  ..., 6.0277, 5.4358, 5.1144]],\n",
       "\n",
       "         [[6.6395, 7.1410, 7.2380,  ..., 8.1230, 7.8852, 9.0325],\n",
       "          [7.4098, 8.3227, 7.6853,  ..., 8.2583, 7.5753, 8.3951],\n",
       "          [6.5982, 8.0183, 7.3229,  ..., 7.4944, 6.9523, 7.7348],\n",
       "          ...,\n",
       "          [6.4342, 7.6584, 6.6270,  ..., 7.3646, 6.2901, 7.2305],\n",
       "          [6.7623, 7.0693, 6.1456,  ..., 8.4290, 7.9138, 7.2285],\n",
       "          [6.9489, 7.9471, 7.3687,  ..., 7.1600, 8.4930, 7.8877]],\n",
       "\n",
       "         [[4.9746, 6.3190, 6.3265,  ..., 7.0968, 6.3354, 6.4233],\n",
       "          [4.5868, 6.0979, 6.5196,  ..., 6.5572, 6.4851, 5.8424],\n",
       "          [4.3377, 6.3379, 7.0562,  ..., 6.3177, 6.3983, 6.8815],\n",
       "          ...,\n",
       "          [4.3834, 6.4006, 6.2556,  ..., 5.7240, 6.5248, 6.4327],\n",
       "          [4.7797, 6.1710, 5.7559,  ..., 5.4665, 6.7386, 5.7400],\n",
       "          [4.3231, 6.6247, 6.0681,  ..., 6.8968, 5.3538, 6.4571]]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calc diff between 2 matrices\n",
    "(out - bn_output).abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
